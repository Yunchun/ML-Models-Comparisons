{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Chess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_id</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_id</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>moves</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TZJHLljE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>15+2</td>\n",
       "      <td>bourgris</td>\n",
       "      <td>1500</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1191</td>\n",
       "      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n",
       "      <td>D10</td>\n",
       "      <td>Slav Defense: Exchange Variation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1NXvwaE</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+10</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1322</td>\n",
       "      <td>skinnerua</td>\n",
       "      <td>1261</td>\n",
       "      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n",
       "      <td>B00</td>\n",
       "      <td>Nimzowitsch Defense: Kennedy Variation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mIICvQHh</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>5+10</td>\n",
       "      <td>ischia</td>\n",
       "      <td>1496</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1500</td>\n",
       "      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n",
       "      <td>C20</td>\n",
       "      <td>King's Pawn Game: Leonardis Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kWKvrqYL</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>20+0</td>\n",
       "      <td>daniamurashov</td>\n",
       "      <td>1439</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1454</td>\n",
       "      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n",
       "      <td>D02</td>\n",
       "      <td>Queen's Pawn Game: Zukertort Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9tXo1AUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>30+3</td>\n",
       "      <td>nik221107</td>\n",
       "      <td>1523</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1469</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
       "0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n",
       "1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n",
       "2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n",
       "3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n",
       "4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n",
       "\n",
       "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
       "0           15+2       bourgris          1500          a-00          1191   \n",
       "1           5+10           a-00          1322     skinnerua          1261   \n",
       "2           5+10         ischia          1496          a-00          1500   \n",
       "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
       "4           30+3      nik221107          1523  adivanov2009          1469   \n",
       "\n",
       "                                               moves opening_eco  \\\n",
       "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
       "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
       "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
       "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
       "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
       "\n",
       "                             opening_name  opening_ply  \n",
       "0        Slav Defense: Exchange Variation            5  \n",
       "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
       "2   King's Pawn Game: Leonardis Variation            3  \n",
       "3  Queen's Pawn Game: Zukertort Variation            3  \n",
       "4                        Philidor Defense            5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasnaek/chess\n",
    "chess_df = pd.read_csv('Data/games.csv')\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_ply</th>\n",
       "      <th>winner_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.722528</td>\n",
       "      <td>0.722501</td>\n",
       "      <td>-1.413916</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>-0.331779</td>\n",
       "      <td>-1.366951</td>\n",
       "      <td>D10</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.719721</td>\n",
       "      <td>0.719694</td>\n",
       "      <td>-1.324552</td>\n",
       "      <td>resign</td>\n",
       "      <td>-0.942931</td>\n",
       "      <td>-1.126431</td>\n",
       "      <td>B00</td>\n",
       "      <td>-0.292076</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.719721</td>\n",
       "      <td>0.719694</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>mate</td>\n",
       "      <td>-0.345513</td>\n",
       "      <td>-0.305227</td>\n",
       "      <td>C20</td>\n",
       "      <td>-0.649582</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.719020</td>\n",
       "      <td>0.718992</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>mate</td>\n",
       "      <td>-0.541219</td>\n",
       "      <td>-0.463283</td>\n",
       "      <td>D02</td>\n",
       "      <td>-0.649582</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.716213</td>\n",
       "      <td>0.716185</td>\n",
       "      <td>1.028698</td>\n",
       "      <td>mate</td>\n",
       "      <td>-0.252810</td>\n",
       "      <td>-0.411743</td>\n",
       "      <td>C41</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated  created_at  last_move_at     turns victory_status  white_rating  \\\n",
       "0  False    0.722528      0.722501 -1.413916      outoftime     -0.331779   \n",
       "1   True    0.719721      0.719694 -1.324552         resign     -0.942931   \n",
       "2   True    0.719721      0.719694  0.015907           mate     -0.345513   \n",
       "3   True    0.719020      0.718992  0.015907           mate     -0.541219   \n",
       "4   True    0.716213      0.716185  1.028698           mate     -0.252810   \n",
       "\n",
       "   black_rating opening_eco  opening_ply  winner_white  \n",
       "0     -1.366951         D10     0.065431          True  \n",
       "1     -1.126431         B00    -0.292076         False  \n",
       "2     -0.305227         C20    -0.649582          True  \n",
       "3     -0.463283         D02    -0.649582          True  \n",
       "4     -0.411743         C41     0.065431          True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_num_cols = ['created_at', 'last_move_at', 'turns', 'white_rating', 'black_rating', 'opening_ply']\n",
    "for num_col in chess_num_cols:\n",
    "    chess_df[num_col] = (chess_df[num_col] - chess_df[num_col].mean()) /chess_df[num_col].std()\n",
    "\n",
    "chess_df['winner_white'] = chess_df['winner'] == 'white'\n",
    "chess_df = chess_df[['rated', 'created_at', 'last_move_at', 'turns', 'victory_status',\n",
    "                     'white_rating', 'black_rating', 'opening_eco', 'opening_ply', 'winner_white']]\n",
    "\n",
    "# max_openings = 30\n",
    "# popular_opennings = chess_df['opening_eco'].value_counts()[:max_openings].index.tolist()\n",
    "# def replace_opening(x):\n",
    "#     if (x in popular_opennings):\n",
    "#         return x\n",
    "#     else:\n",
    "#         return 'other'\n",
    "\n",
    "# chess_df['opening_eco'] = chess_df['opening_eco'].apply(replace_opening)\n",
    "\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_df_X = chess_df.drop(columns=['winner_white'])\n",
    "chess_df_y = chess_df['winner_white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_X_cat_col = ['rated', 'victory_status', 'opening_eco']\n",
    "chess_X = pd.get_dummies(columns=chess_X_cat_col, data=chess_df_X)\n",
    "\n",
    "chess_y = chess_df_y.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10057\n",
       "1    10001\n",
       "Name: winner_white, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Mushrooms Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class: edible(e), poisonous(p)\n",
    "\n",
    "cap-shape: bell(b), conical(c), convex(x), flat(f), knobbed(k), sunken(s)\n",
    "\n",
    "cap-surface: fibrous(f), grooves(g), scaly(y), smooth(s)\n",
    "\n",
    "cap-color: brown(n), buff(b), cinnamon(c), gray(g), green(r), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "bruises: bruises(t), no(f)\n",
    "\n",
    "odor: almond(a), anise(l), creosote(c), fishy(y), foul(f), musty(m), none(n), pungent(p), spicy(s)\n",
    "\n",
    "gill-attachment: attached(a), descending(d), free(f), notched(n)\n",
    "\n",
    "gill-spacing: close(c), crowded(w), distant(d)\n",
    "\n",
    "gill-size: broad(b), narrow(n)\n",
    "\n",
    "gill-color: black(k), brown(n), buff(b), chocolate(h), gray(g), green(r), orange(o), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-shape: enlarging(e), tapering(t)\n",
    "\n",
    "stalk-root: bulbous(b), club(c), cup(u), equal(e), rhizomorphs(z), rooted(r), missing(?)\n",
    "\n",
    "stalk-surface-above-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-surface-below-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-color-above-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-color-below-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "veil-type: partial(p), universal(u)\n",
    "\n",
    "veil-color: brown(n), orange(o), white(w), yellow(y)\n",
    "\n",
    "ring-number: none(n), one(o), two(t)\n",
    "\n",
    "ring-type: cobwebby(c), evanescent(e), flaring(f), large(l), none(n), pendant(p), sheathing(s), zone(z)\n",
    "\n",
    "spore-print-color: black(k), brown(n), buff(b), chocolate(h), green(r), orange(o), purple(u), white(w), yellow(y)\n",
    "\n",
    "population: abundant(a), clustered(c), numerous(n), scattered(s), several(v), solitary(y)\n",
    "\n",
    "habitat: grasses(g), leaves(l), meadows(m), paths(p), urban(u), waste(w), woods(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/uciml/mushroom-classification\n",
    "shrooms = pd.read_csv('Data/mushrooms.csv')\n",
    "shrooms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_df_X = shrooms.drop(columns=['class'])\n",
    "shrooms_df_y = shrooms['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_X = pd.get_dummies(data=shrooms_df_X)\n",
    "shrooms_y = shrooms_df_y.replace({'e': 0, 'p': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4208\n",
       "1    3916\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrooms_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Cardio Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieved from the kaggle site https://www.kaggle.com/sulianova/cardiovascular-disease-dataset, this cardio dataset has 70000 samples and 12 variables, which were collected at the moment of medical examination. It contains a target variable that indicates the presence or absence of cardiovascular disease, as well as 11 features that might be associated with the presence of cardiovascular disease, such as age, gender, and blood pressure. There are 3 types of 11 input features:\n",
    "- objective feature: factual information\n",
    "- examination feature: results of medical examination\n",
    "- subjective feature: information given by the patient\n",
    "\n",
    "A more detailed description of 11 features are shown below:\n",
    "\n",
    "- age: objective feature, int (days)\n",
    "- height: objective feature, int (cm)\n",
    "- weight: objective feature, float (kg)\n",
    "- gender: objective feature, categorical code, 1: male, 2:female\n",
    "- ap_hi: systolic blood pressure, examination feature, int\n",
    "- ap_lo: diastolic blood pressure, examination feature, int\n",
    "- cholesterol: examination feature, categorical code, 1: normal, 2: above normal, 3: well above normal\n",
    "- gluc: glucose, examination feature, categorical code, 1: normal, 2: above normal, 3: well above normal\n",
    "- smoke: subjective feature, binary, 0: do not smoke, 1: smoke\n",
    "- alco: alcohol intake, subjective feature, binary, 0: do not drink alcohol, 1: drink alcohol\n",
    "- active: physical activity, subjective feature, binary, 0: not physically active, 1: physically active\n",
    "\n",
    "A detailed description of the target variable is shown below: \n",
    "\n",
    "- cardio: presence or absence of cardiovascular disease, binary, 0: disease not present, 1: disease present\n",
    "\n",
    "For this dataset, we want use those 11 input features and apply machine learning algorithms to predict whether a person has cardiovascular disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the cardio dataset\n",
    "cardio = pd.read_csv('data/cardio.csv', delimiter = ';')\n",
    "cardio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "age            0\n",
       "gender         0\n",
       "height         0\n",
       "weight         0\n",
       "ap_hi          0\n",
       "ap_lo          0\n",
       "cholesterol    0\n",
       "gluc           0\n",
       "smoke          0\n",
       "alco           0\n",
       "active         0\n",
       "cardio         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing values in cardio dataset\n",
    "cardio.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary column \"id\"\n",
    "cardio = cardio.drop(columns = ['id'])\n",
    "# convert age in days to age in years\n",
    "cardio['age'] = cardio['age'].apply(lambda x: int(x/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding categorical input features stored in cate_cols\n",
    "cardio_cate_cols = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "cardio = pd.get_dummies(columns = cardio_cate_cols, data = cardio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numerical attributes to 0 mean 1 std\n",
    "cardio_num_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "for num_col in cardio_num_cols:\n",
    "    cardio[num_col] = (cardio[num_col] - cardio[num_col].mean()) / cardio[num_col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cardio</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>cholesterol_1</th>\n",
       "      <th>cholesterol_2</th>\n",
       "      <th>cholesterol_3</th>\n",
       "      <th>gluc_1</th>\n",
       "      <th>gluc_2</th>\n",
       "      <th>gluc_3</th>\n",
       "      <th>smoke_0</th>\n",
       "      <th>smoke_1</th>\n",
       "      <th>alco_0</th>\n",
       "      <th>alco_1</th>\n",
       "      <th>active_0</th>\n",
       "      <th>active_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419797</td>\n",
       "      <td>0.443449</td>\n",
       "      <td>-0.847867</td>\n",
       "      <td>-0.122181</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319108</td>\n",
       "      <td>-1.018161</td>\n",
       "      <td>0.749826</td>\n",
       "      <td>0.072610</td>\n",
       "      <td>-0.035180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.272016</td>\n",
       "      <td>0.078046</td>\n",
       "      <td>-0.708937</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>-0.141296</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.715359</td>\n",
       "      <td>0.565250</td>\n",
       "      <td>0.541431</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.863140</td>\n",
       "      <td>-1.018161</td>\n",
       "      <td>-1.264657</td>\n",
       "      <td>-0.187111</td>\n",
       "      <td>-0.194354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    height    weight     ap_hi     ap_lo  cardio  gender_1  \\\n",
       "0 -0.419797  0.443449 -0.847867 -0.122181 -0.088238       0         0   \n",
       "1  0.319108 -1.018161  0.749826  0.072610 -0.035180       1         1   \n",
       "2 -0.272016  0.078046 -0.708937  0.007679 -0.141296       1         1   \n",
       "3 -0.715359  0.565250  0.541431  0.137540  0.017878       1         0   \n",
       "4 -0.863140 -1.018161 -1.264657 -0.187111 -0.194354       0         1   \n",
       "\n",
       "   gender_2  cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  \\\n",
       "0         1              1              0              0       1       0   \n",
       "1         0              0              0              1       1       0   \n",
       "2         0              0              0              1       1       0   \n",
       "3         1              1              0              0       1       0   \n",
       "4         0              1              0              0       1       0   \n",
       "\n",
       "   gluc_3  smoke_0  smoke_1  alco_0  alco_1  active_0  active_1  \n",
       "0       0        1        0       1       0         0         1  \n",
       "1       0        1        0       1       0         0         1  \n",
       "2       0        1        0       1       0         1         0  \n",
       "3       0        1        0       1       0         0         1  \n",
       "4       0        1        0       1       0         1         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look at cleaned dataset\n",
    "cardio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5003\n",
       "1    0.4997\n",
       "Name: cardio, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50.03% negative labels, 49.97% positive labels\n",
    "cardio['cardio'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the cardio dataset into input features and labels \n",
    "cardio_X = cardio.drop(columns=['cardio']) # input features\n",
    "cardio_y = cardio['cardio'] # true lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Rain Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieved from the kaggle site https://www.kaggle.com/jsphyg/weather-dataset-rattle-package, this Rain in Australia dataset contains about 10 years of daily weather observations from many locations across Australia. There are 145460 samples and 23 variables in this dataset. It contains a target variable that indicates whether it rained the next day, as well as 22 features that might be associated with the target variable, such as minimum temperature, maximum temperature, rainfall of the day.\n",
    "\n",
    "A more detailed description of 22 features are shown below:\n",
    "\n",
    "- Date: the date of observation\n",
    "- Location: the common name of the location of the weather station\n",
    "- MinTemp: the minimum temperature in degrees celsius\n",
    "- MaxTemp: the maximum temperature in degrees celsius\n",
    "- Rainfall: the amount of rainfall recorded for the day in mm\n",
    "- Evaporation: the so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
    "- Sunshine: the number of hours of bright sunshine in the day\n",
    "- WindGustDir: the direction of the strongest wind gust in the 24 hours to midnight\n",
    "- WindGustSpeed: the speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "- WindDir9am: direction of the wind at 9am\n",
    "- WindDir3pm: direction of the wind at 3pm\n",
    "- WindSpeed9am: wind speed (km/hr) averaged over 10 minutes prior to 9am\n",
    "- WindSpeed3pm: wind speed (km/hr) averaged over 10 minutes prior to 3pm\n",
    "- Humidity9am: humidity (percent) at 9am\n",
    "- Humidity3pm: humidity (percent) at 3pm\n",
    "- Pressure9am: atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "- Pressure3pm: atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "- Cloud9am: fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast\n",
    "- Cloud3pm: fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n",
    "- Temp9am: temperature (degrees C) at 9am\n",
    "- Temp3pm: temperature (degrees C) at 3pm\n",
    "- RainToday: whether the precipitation (mm) in the 24 hours to 9am exceeded 1mm, Yes: the precipitation exceeded 1mm, No: it did not exceed 1mm\n",
    "\n",
    "A detailed description of the target variable is shown below: \n",
    "\n",
    "- RainTomorrow: whether amount of next day rain exceeded 1mm, Yes: next day precipitation exceeded 1mm, No: it did not exceed 1mm\n",
    "\n",
    "For this dataset, we want use those 22 input features and apply machine learning algorithms to predict whether it rained the next day or not.\n",
    "\n",
    "Data source: http://www.bom.gov.au/climate/dwo/ and http://www.bom.gov.au/climate/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Australian rain dataset\n",
    "aus = pd.read_csv('Data/weatherAUS.csv')\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the number of missing values in each column\n",
    "aus.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in categorical columns with the mode \n",
    "aus_cate_cols = aus.dtypes.index[aus.dtypes == \"object\"].tolist()\n",
    "for cate_col in aus_cate_cols:\n",
    "    aus[cate_col] = aus[cate_col].fillna(aus[cate_col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in numerical columns with the mean\n",
    "aus_num_cols = aus.dtypes.index[aus.dtypes == \"float64\"].tolist()\n",
    "for num_col in aus_num_cols:\n",
    "    aus[num_col] = aus[num_col].fillna(aus[num_col].mean())\n",
    "    # scale numerical attributes to 0 mean 1 std\n",
    "    aus[num_col] = (aus[num_col] - aus[num_col].mean()) / aus[num_col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "Location         0\n",
       "MinTemp          0\n",
       "MaxTemp          0\n",
       "Rainfall         0\n",
       "Evaporation      0\n",
       "Sunshine         0\n",
       "WindGustDir      0\n",
       "WindGustSpeed    0\n",
       "WindDir9am       0\n",
       "WindDir3pm       0\n",
       "WindSpeed9am     0\n",
       "WindSpeed3pm     0\n",
       "Humidity9am      0\n",
       "Humidity3pm      0\n",
       "Pressure9am      0\n",
       "Pressure3pm      0\n",
       "Cloud9am         0\n",
       "Cloud3pm         0\n",
       "Temp9am          0\n",
       "Temp3pm          0\n",
       "RainToday        0\n",
       "RainTomorrow     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all missing values are filled\n",
    "aus.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the date of each observation into year, month, and day\n",
    "splitted_date = aus['Date'].str.split('-')\n",
    "\n",
    "# create 'Year', 'Month', 'Day' columns using splitted results of the date\n",
    "aus['Year'] = splitted_date.str[0].astype(int)\n",
    "aus['Month'] = splitted_date.str[1].astype(int)\n",
    "aus['Day'] = splitted_date.str[2].astype(int)\n",
    "\n",
    "# drop original 'Date' column\n",
    "aus = aus.drop(columns = ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 0 and 1 to indicate whether it rained or not\n",
    "# 0: it rained, 1: it did not rain\n",
    "aus['RainToday'] = aus['RainToday'].replace({'No': 0, 'Yes': 1})\n",
    "aus['RainTomorrow'] = aus['RainTomorrow'].replace({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189446</td>\n",
       "      <td>-0.045336</td>\n",
       "      <td>-0.210071</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>0.612321</td>\n",
       "      <td>0.112394</td>\n",
       "      <td>-1.442960</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.753098</td>\n",
       "      <td>0.265042</td>\n",
       "      <td>-0.281649</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>-1.133434</td>\n",
       "      <td>0.382873</td>\n",
       "      <td>-1.319604</td>\n",
       "      <td>-1.296413</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110901</td>\n",
       "      <td>0.349691</td>\n",
       "      <td>-0.281649</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>0.454692</td>\n",
       "      <td>0.559366</td>\n",
       "      <td>0.841768</td>\n",
       "      <td>-1.637826</td>\n",
       "      <td>-1.052167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.470335</td>\n",
       "      <td>0.674177</td>\n",
       "      <td>-0.281649</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>-1.222360</td>\n",
       "      <td>-0.343461</td>\n",
       "      <td>-1.108537</td>\n",
       "      <td>-1.266567</td>\n",
       "      <td>-1.736055</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.833518</td>\n",
       "      <td>1.280826</td>\n",
       "      <td>-0.162353</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>0.073544</td>\n",
       "      <td>-0.794874</td>\n",
       "      <td>0.153425</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>-0.905620</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MinTemp   MaxTemp  Rainfall   Evaporation      Sunshine  WindGustSpeed  \\\n",
       "0  0.189446 -0.045336 -0.210071 -1.737284e-12 -1.385234e-12       0.302233   \n",
       "1 -0.753098  0.265042 -0.281649 -1.737284e-12 -1.385234e-12       0.302233   \n",
       "2  0.110901  0.349691 -0.281649 -1.737284e-12 -1.385234e-12       0.454692   \n",
       "3 -0.470335  0.674177 -0.281649 -1.737284e-12 -1.385234e-12      -1.222360   \n",
       "4  0.833518  1.280826 -0.162353 -1.737284e-12 -1.385234e-12       0.073544   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW  \\\n",
       "0      0.672219      0.612321     0.112394    -1.442960  ...               0   \n",
       "1     -1.133434      0.382873    -1.319604    -1.296413  ...               0   \n",
       "2      0.559366      0.841768    -1.637826    -1.052167  ...               0   \n",
       "3     -0.343461     -1.108537    -1.266567    -1.736055  ...               0   \n",
       "4     -0.794874      0.153425     0.695801    -0.905620  ...               0   \n",
       "\n",
       "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n",
       "0              0             0              0               0               0   \n",
       "1              0             0              0               0               0   \n",
       "2              0             0              0               0               0   \n",
       "3              0             0              0               0               0   \n",
       "4              1             0              0               0               0   \n",
       "\n",
       "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0              0             0               1               0  \n",
       "1              0             0               0               1  \n",
       "2              0             0               0               1  \n",
       "3              0             0               0               0  \n",
       "4              0             0               0               0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding all categorical columns\n",
    "cate_cols = aus.dtypes.index[aus.dtypes == \"object\"].tolist()\n",
    "aus = pd.get_dummies(columns = cate_cols, data = aus)\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.780854\n",
       "1    0.219146\n",
       "Name: RainTomorrow, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 78.0854% negative labels, 21.9146% positive labels\n",
    "aus['RainTomorrow'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the rain dataset into input features and labels \n",
    "aus_X = aus.drop(columns=['RainTomorrow']) # input features\n",
    "aus_y = aus['RainTomorrow'] # true lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean BnB Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is from https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv, and contains data from AirBnB listing and metrics in New York City, New York for the year 2019. There are 47900 unique values in this dataset, in which we will be using different features to predict whether an AirBnB pricing is expensive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the AirBnb dataset\n",
    "airbnb = pd.read_csv('data/AB_NYC_2019.csv')\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be looking at these features of the AirBnB for our predictive model\n",
    "airbnb = airbnb[['neighbourhood_group','latitude','longitude','room_type', 'price',\n",
    "                       'minimum_nights','number_of_reviews','availability_365']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The price median will be the threshold for our expensive classifier\n",
    "airbnb['price'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>is_expensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>355</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>194</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group  latitude  longitude        room_type  price  \\\n",
       "0            Brooklyn  40.64749  -73.97237     Private room    149   \n",
       "1           Manhattan  40.75362  -73.98377  Entire home/apt    225   \n",
       "2           Manhattan  40.80902  -73.94190     Private room    150   \n",
       "3            Brooklyn  40.68514  -73.95976  Entire home/apt     89   \n",
       "4           Manhattan  40.79851  -73.94399  Entire home/apt     80   \n",
       "\n",
       "   minimum_nights  number_of_reviews  availability_365  is_expensive  \n",
       "0               1                  9               365          True  \n",
       "1               1                 45               355          True  \n",
       "2               3                  0               365          True  \n",
       "3               1                270               194         False  \n",
       "4              10                  9                 0         False  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new column with prices greater than the median as True, lesser than as False\n",
    "airbnb = airbnb.assign(\n",
    "    is_expensive = airbnb.get('price') > 106.0\n",
    ")\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into input features and labels\n",
    "airbnb_df_X = airbnb.drop(columns=['is_expensive'])\n",
    "airbnb_df_y = airbnb['is_expensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for the categorical columns\n",
    "airbnb_X_cat_col = ['neighbourhood_group', 'room_type']\n",
    "airbnb_X = pd.get_dummies(columns=airbnb_X_cat_col, data=airbnb_df_X)\n",
    "\n",
    "airbnb_y = airbnb_df_y.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Olympic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is from https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results?select=athlete_events.csv, and includes historic data of all participants from the Olympic Games, from Athens 1896 to Rio 2016. There are 271116 unique values/observations. We want to see whether or not we can predict a gold medalist just by participant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gunnar Nielsen Aaby</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1920 Summer</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Edgar Lindenau Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900 Summer</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      Name Sex   Age  Height  Weight            Team  \\\n",
       "0   1                 A Dijiang   M  24.0   180.0    80.0           China   \n",
       "1   2                  A Lamusi   M  23.0   170.0    60.0           China   \n",
       "2   3       Gunnar Nielsen Aaby   M  24.0     NaN     NaN         Denmark   \n",
       "3   4      Edgar Lindenau Aabye   M  34.0     NaN     NaN  Denmark/Sweden   \n",
       "4   5  Christine Jacoba Aaftink   F  21.0   185.0    82.0     Netherlands   \n",
       "\n",
       "   NOC        Games  Year  Season       City          Sport  \\\n",
       "0  CHN  1992 Summer  1992  Summer  Barcelona     Basketball   \n",
       "1  CHN  2012 Summer  2012  Summer     London           Judo   \n",
       "2  DEN  1920 Summer  1920  Summer  Antwerpen       Football   \n",
       "3  DEN  1900 Summer  1900  Summer      Paris     Tug-Of-War   \n",
       "4  NED  1988 Winter  1988  Winter    Calgary  Speed Skating   \n",
       "\n",
       "                              Event Medal  \n",
       "0       Basketball Men's Basketball   NaN  \n",
       "1      Judo Men's Extra-Lightweight   NaN  \n",
       "2           Football Men's Football   NaN  \n",
       "3       Tug-Of-War Men's Tug-Of-War  Gold  \n",
       "4  Speed Skating Women's 500 metres   NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Olympic dataset\n",
    "olympic = pd.read_csv('data/athlete_events.csv')\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Judo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Football</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight  NOC          Sport Medal\n",
       "0   M  24.0   180.0    80.0  CHN     Basketball   NaN\n",
       "1   M  23.0   170.0    60.0  CHN           Judo   NaN\n",
       "2   M  24.0     NaN     NaN  DEN       Football   NaN\n",
       "3   M  34.0     NaN     NaN  DEN     Tug-Of-War  Gold\n",
       "4   F  21.0   185.0    82.0  NED  Speed Skating   NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the features we will be looking at for our classifier\n",
    "olympic = olympic[['Sex', 'Age','Height','Weight','NOC','Sport','Medal']]\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271116, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some NaN values in this dataset, so we want to remove those\n",
    "olympic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Judo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight  NOC          Sport Medal\n",
       "0   M  24.0   180.0    80.0  CHN     Basketball   NaN\n",
       "1   M  23.0   170.0    60.0  CHN           Judo   NaN\n",
       "4   F  21.0   185.0    82.0  NED  Speed Skating   NaN\n",
       "5   F  21.0   185.0    82.0  NED  Speed Skating   NaN\n",
       "6   F  25.0   185.0    82.0  NED  Speed Skating   NaN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This removes the NaN values from the numerical columns\n",
    "olympic = olympic[olympic['Height'].notna()]\n",
    "olympic = olympic[olympic['Weight'].notna()]\n",
    "olympic = olympic[olympic['Age'].notna()]\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206165, 7)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After that cleaning, we are left with 206165 participants to work with\n",
    "olympic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Medal</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Judo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight  NOC          Sport Medal   Gold\n",
       "0   M  24.0   180.0    80.0  CHN     Basketball   NaN  False\n",
       "1   M  23.0   170.0    60.0  CHN           Judo   NaN  False\n",
       "4   F  21.0   185.0    82.0  NED  Speed Skating   NaN  False\n",
       "5   F  21.0   185.0    82.0  NED  Speed Skating   NaN  False\n",
       "6   F  25.0   185.0    82.0  NED  Speed Skating   NaN  False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to make a column to see if the participant is a Gold Medalist\n",
    "olympic['Gold'] = olympic['Medal']=='Gold'\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Judo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight  NOC          Sport   Gold\n",
       "0   M  24.0   180.0    80.0  CHN     Basketball  False\n",
       "1   M  23.0   170.0    60.0  CHN           Judo  False\n",
       "4   F  21.0   185.0    82.0  NED  Speed Skating  False\n",
       "5   F  21.0   185.0    82.0  NED  Speed Skating  False\n",
       "6   F  25.0   185.0    82.0  NED  Speed Skating  False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We no longer need the Medal column\n",
    "olympic = olympic.drop(columns=['Medal'])\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the olympic dataset into input features and labels\n",
    "olympic_df_X = olympic.drop(columns=['Gold'])\n",
    "olympic_df_y = olympic['Gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode all the categorical columns\n",
    "olympic_X_cat_col = ['Sex','NOC','Sport']\n",
    "olympic_X = pd.get_dummies(columns=olympic_X_cat_col, data=olympic_df_X)\n",
    "olympic_y = olympic_df_y.replace({True: 0, False: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "\n",
    "tree_params = [\n",
    "    {\n",
    "        'max_depth': [2,3,4,5,7,10,13,15,18,None], \n",
    "        'min_samples_split':[2,3,5,7,10,15,20],\n",
    "        'min_samples_leaf':[2,3,5,7,10,15,20]\n",
    "    }\n",
    "]\n",
    "\n",
    "log_reg_params = [        \n",
    "    {\n",
    "        'solver': ['lbfgs'],\n",
    "        'max_iter': [5000],\n",
    "        'penalty': ['l2'],\n",
    "        'C': 10**np.arange(-4, 5, 1, dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'solver': ['saga'],\n",
    "        'max_iter': [5000],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': 10**np.arange(-4, 5, 1, dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'solver': ['saga', 'lbfgs'],\n",
    "        'max_iter': [5000],\n",
    "        'penalty': ['none']\n",
    "    }\n",
    "]\n",
    "\n",
    "perceptron_params = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "    }\n",
    "]\n",
    "\n",
    "svc_params = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'degree': [2, 3],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "        'gamma': [0.001,0.01,0.1,1,2]\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_params = [\n",
    "    {\n",
    "        'n_neighbors': np.arange(1, 106, 4),\n",
    "        'metric': [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "forest_params = [\n",
    "    {\n",
    "        'n_estimators': [1024],\n",
    "        'min_samples_split': [1, 2, 4, 6, 8, 12, 16, 20]\n",
    "    }\n",
    "]\n",
    "\n",
    "# models that do not include SVM classifier\n",
    "models_without_svm = {\n",
    "    'tree': (DecisionTreeClassifier(), tree_params),\n",
    "    'log_reg': (LogisticRegression(), log_reg_params),\n",
    "    'perceptron': (Perceptron(), perceptron_params),\n",
    "    'knn': (KNeighborsClassifier(), knn_params),\n",
    "    'forest': (RandomForestClassifier(), forest_params)\n",
    "}\n",
    "\n",
    "# SVM model\n",
    "models_only_svm = {\n",
    "    'svm': (SVC(), svc_params)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform 7 trials using each of 6 algorithms on one dataset\n",
    "def perform_trials(dataset_name, models, data_X, data_y):\n",
    "    results_columns = ['dataset', 'model', 'trial',\n",
    "                       'train_accuracy', 'train_precision',\n",
    "                       'train_recall', 'train_specificity',\n",
    "                       'train_f1', 'train_roc_auc', \n",
    "                       'train_log_loss', 'test_accuracy',\n",
    "                       'test_precision', 'test_recall',\n",
    "                       'test_specificity', 'test_f1',\n",
    "                       'test_roc_auc', 'test_log_loss']\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score),\n",
    "        'specificity': make_scorer(recall_score, pos_label=0),\n",
    "        'f1': make_scorer(f1_score),\n",
    "        'roc_auc': make_scorer(roc_auc_score),\n",
    "        'log_loss': make_scorer(log_loss)\n",
    "    }\n",
    "    \n",
    "    num_trials = 7\n",
    "    \n",
    "    data_results = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "    for model_name in models.keys():\n",
    "        model = models[model_name][0]        \n",
    "        model_params_grid = models[model_name][1]\n",
    "        model_results = pd.DataFrame(columns=results_columns)\n",
    "        \n",
    "        # perform 7 trials using each model on the dataset\n",
    "        for trial_count in range(num_trials):\n",
    "            # pick 5000 samples with replacement to be in the training set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, \n",
    "                                                                train_size=5000, \n",
    "                                                                random_state=trial_count)\n",
    "            \n",
    "            # grid search with 5 k-folds\n",
    "            search = GridSearchCV(model, model_params_grid, cv=5, verbose=3,\n",
    "                                  n_jobs=-1, refit=False, scoring=scoring)\n",
    "            \n",
    "            # fit grid search model with training set\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # store 7 metrics calculated in one trial\n",
    "            model_result = {\n",
    "                'dataset': dataset_name,\n",
    "                'model': model_name,\n",
    "                'trial': trial_count + 1\n",
    "            }\n",
    "            \n",
    "            for score_name in scoring.keys():\n",
    "                # find the best parameters that make model achieves best score of the metric\n",
    "                best_params = search.cv_results_['params'][np.argmin(search.cv_results_['rank_test_' + score_name])]\n",
    "                # use best parameters to create the optimal model for the metric\n",
    "                best_model = clone(model).set_params(**best_params)\n",
    "                # train the optimal model\n",
    "                best_model.fit(X_train, y_train)\n",
    "                \n",
    "                # compute metrics\n",
    "                train_score = scoring[score_name](best_model, X_train, y_train)\n",
    "                test_score = scoring[score_name](best_model, X_test, y_test)\n",
    "\n",
    "                # append scores\n",
    "                model_result['train_' + score_name] = train_score\n",
    "                model_result['test_' + score_name] = test_score\n",
    "            \n",
    "            # append scores of one trial to the model_results dataframe\n",
    "            model_results = model_results.append(model_result, ignore_index=True)\n",
    "        \n",
    "        # append model_results to data_results\n",
    "        data_results = data_results.append(model_results, ignore_index=True)\n",
    "        \n",
    "        # store scores averaged over 7 trials\n",
    "        avg_result = {\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'trial': 'avg',\n",
    "            \n",
    "            'train_accuracy': model_results.train_accuracy.mean(),\n",
    "            'train_precision': model_results.train_precision.mean(),\n",
    "            'train_recall': model_results.train_recall.mean(),\n",
    "            'train_specificity': model_results.train_specificity.mean(),\n",
    "            'train_f1': model_results.train_f1.mean(),\n",
    "            'train_roc_auc': model_results.train_roc_auc.mean(),\n",
    "            'train_log_loss': model_results.train_log_loss.mean(),\n",
    "            \n",
    "            'test_accuracy': model_results.test_accuracy.mean(),\n",
    "            'test_precision': model_results.test_precision.mean(),\n",
    "            'test_recall': model_results.test_recall.mean(),\n",
    "            'test_specificity': model_results.test_specificity.mean(),\n",
    "            'test_f1': model_results.test_f1.mean(),\n",
    "            'test_roc_auc': model_results.test_roc_auc.mean(),\n",
    "            'test_log_loss': model_results.test_log_loss.mean()\n",
    "        }\n",
    "        \n",
    "        # append avg_result to the data_results dataframe\n",
    "        data_results = data_results.append(avg_result, ignore_index=True)\n",
    "    \n",
    "    return data_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chess Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   56.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   50.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   51.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   51.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   52.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   51.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   52.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    3.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.704400</td>\n",
       "      <td>0.590343</td>\n",
       "      <td>0.898863</td>\n",
       "      <td>0.481875</td>\n",
       "      <td>0.701170</td>\n",
       "      <td>0.705238</td>\n",
       "      <td>1.454112e+01</td>\n",
       "      <td>0.651879</td>\n",
       "      <td>0.589677</td>\n",
       "      <td>0.883804</td>\n",
       "      <td>0.474531</td>\n",
       "      <td>0.688981</td>\n",
       "      <td>0.651822</td>\n",
       "      <td>14.645670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.714619</td>\n",
       "      <td>0.813580</td>\n",
       "      <td>0.724014</td>\n",
       "      <td>0.667326</td>\n",
       "      <td>0.689536</td>\n",
       "      <td>1.497608e+01</td>\n",
       "      <td>0.646899</td>\n",
       "      <td>0.629489</td>\n",
       "      <td>0.805511</td>\n",
       "      <td>0.613305</td>\n",
       "      <td>0.662325</td>\n",
       "      <td>0.646779</td>\n",
       "      <td>15.150056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.672395</td>\n",
       "      <td>0.855542</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.680783</td>\n",
       "      <td>0.683637</td>\n",
       "      <td>1.504514e+01</td>\n",
       "      <td>0.649489</td>\n",
       "      <td>0.648336</td>\n",
       "      <td>0.856172</td>\n",
       "      <td>0.867125</td>\n",
       "      <td>0.679647</td>\n",
       "      <td>0.649786</td>\n",
       "      <td>15.264734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.669520</td>\n",
       "      <td>0.661712</td>\n",
       "      <td>0.646356</td>\n",
       "      <td>0.647755</td>\n",
       "      <td>0.654725</td>\n",
       "      <td>1.407817e+01</td>\n",
       "      <td>0.637402</td>\n",
       "      <td>0.635860</td>\n",
       "      <td>0.661608</td>\n",
       "      <td>0.598993</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.637577</td>\n",
       "      <td>14.833637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>0.753927</td>\n",
       "      <td>0.870791</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.714998</td>\n",
       "      <td>0.672038</td>\n",
       "      <td>1.407134e+01</td>\n",
       "      <td>0.648360</td>\n",
       "      <td>0.632281</td>\n",
       "      <td>0.849604</td>\n",
       "      <td>0.646696</td>\n",
       "      <td>0.689892</td>\n",
       "      <td>0.649447</td>\n",
       "      <td>14.654800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>0.677400</td>\n",
       "      <td>0.750210</td>\n",
       "      <td>0.624051</td>\n",
       "      <td>0.913897</td>\n",
       "      <td>0.638594</td>\n",
       "      <td>0.677477</td>\n",
       "      <td>1.406440e+01</td>\n",
       "      <td>0.646500</td>\n",
       "      <td>0.641770</td>\n",
       "      <td>0.613897</td>\n",
       "      <td>0.662434</td>\n",
       "      <td>0.624941</td>\n",
       "      <td>0.646235</td>\n",
       "      <td>14.498792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>0.696400</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.922830</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.696180</td>\n",
       "      <td>0.696712</td>\n",
       "      <td>1.515565e+01</td>\n",
       "      <td>0.648094</td>\n",
       "      <td>0.661217</td>\n",
       "      <td>0.910954</td>\n",
       "      <td>0.901127</td>\n",
       "      <td>0.689502</td>\n",
       "      <td>0.647578</td>\n",
       "      <td>15.604190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chess</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.682971</td>\n",
       "      <td>0.691703</td>\n",
       "      <td>0.806767</td>\n",
       "      <td>0.788923</td>\n",
       "      <td>0.678115</td>\n",
       "      <td>0.682766</td>\n",
       "      <td>1.456170e+01</td>\n",
       "      <td>0.646946</td>\n",
       "      <td>0.634090</td>\n",
       "      <td>0.797364</td>\n",
       "      <td>0.680602</td>\n",
       "      <td>0.666919</td>\n",
       "      <td>0.647032</td>\n",
       "      <td>14.950268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668400</td>\n",
       "      <td>0.731148</td>\n",
       "      <td>0.682372</td>\n",
       "      <td>0.903073</td>\n",
       "      <td>0.669589</td>\n",
       "      <td>0.668609</td>\n",
       "      <td>1.700689e+01</td>\n",
       "      <td>0.670873</td>\n",
       "      <td>0.748957</td>\n",
       "      <td>0.687492</td>\n",
       "      <td>0.903977</td>\n",
       "      <td>0.676544</td>\n",
       "      <td>0.670851</td>\n",
       "      <td>17.292325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685800</td>\n",
       "      <td>0.678740</td>\n",
       "      <td>0.689835</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.677318</td>\n",
       "      <td>0.685835</td>\n",
       "      <td>1.719340e+01</td>\n",
       "      <td>0.669279</td>\n",
       "      <td>0.662474</td>\n",
       "      <td>0.694888</td>\n",
       "      <td>0.740392</td>\n",
       "      <td>0.678012</td>\n",
       "      <td>0.669314</td>\n",
       "      <td>17.230395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.715086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684281</td>\n",
       "      <td>0.681611</td>\n",
       "      <td>1.726248e+01</td>\n",
       "      <td>0.666755</td>\n",
       "      <td>0.659531</td>\n",
       "      <td>0.718875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686394</td>\n",
       "      <td>0.666881</td>\n",
       "      <td>17.207458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.671294</td>\n",
       "      <td>0.720771</td>\n",
       "      <td>0.735962</td>\n",
       "      <td>0.690930</td>\n",
       "      <td>0.679183</td>\n",
       "      <td>1.719340e+01</td>\n",
       "      <td>0.667486</td>\n",
       "      <td>0.661655</td>\n",
       "      <td>0.728168</td>\n",
       "      <td>0.722635</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.667622</td>\n",
       "      <td>17.230395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.686800</td>\n",
       "      <td>0.676051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620196</td>\n",
       "      <td>0.707836</td>\n",
       "      <td>0.685565</td>\n",
       "      <td>1.689676e+01</td>\n",
       "      <td>0.669611</td>\n",
       "      <td>0.651137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632374</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>0.670100</td>\n",
       "      <td>17.457877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>6</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.666026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651982</td>\n",
       "      <td>0.683689</td>\n",
       "      <td>0.684967</td>\n",
       "      <td>1.729011e+01</td>\n",
       "      <td>0.666954</td>\n",
       "      <td>0.657465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.650397</td>\n",
       "      <td>0.682560</td>\n",
       "      <td>0.667056</td>\n",
       "      <td>17.198283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>0.676882</td>\n",
       "      <td>0.708601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683598</td>\n",
       "      <td>0.673767</td>\n",
       "      <td>1.718650e+01</td>\n",
       "      <td>0.666290</td>\n",
       "      <td>0.672467</td>\n",
       "      <td>0.708106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679221</td>\n",
       "      <td>0.666379</td>\n",
       "      <td>17.232689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chess</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.680029</td>\n",
       "      <td>0.680973</td>\n",
       "      <td>0.645238</td>\n",
       "      <td>0.809641</td>\n",
       "      <td>0.685320</td>\n",
       "      <td>0.679934</td>\n",
       "      <td>1.714708e+01</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.673384</td>\n",
       "      <td>0.648218</td>\n",
       "      <td>0.807111</td>\n",
       "      <td>0.681479</td>\n",
       "      <td>0.668315</td>\n",
       "      <td>17.264203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.516467</td>\n",
       "      <td>0.460601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.657848</td>\n",
       "      <td>0.619149</td>\n",
       "      <td>1.699339e+01</td>\n",
       "      <td>0.606654</td>\n",
       "      <td>0.524088</td>\n",
       "      <td>0.460008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651404</td>\n",
       "      <td>0.606485</td>\n",
       "      <td>17.122903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.648400</td>\n",
       "      <td>0.635718</td>\n",
       "      <td>0.942949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683758</td>\n",
       "      <td>0.648919</td>\n",
       "      <td>1.734578e+01</td>\n",
       "      <td>0.626179</td>\n",
       "      <td>0.631893</td>\n",
       "      <td>0.937966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684410</td>\n",
       "      <td>0.626438</td>\n",
       "      <td>17.308782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>0.570401</td>\n",
       "      <td>0.763505</td>\n",
       "      <td>0.376250</td>\n",
       "      <td>0.680942</td>\n",
       "      <td>0.590256</td>\n",
       "      <td>1.726248e+01</td>\n",
       "      <td>0.581751</td>\n",
       "      <td>0.561655</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>0.377051</td>\n",
       "      <td>0.651469</td>\n",
       "      <td>0.582284</td>\n",
       "      <td>17.207458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.618485</td>\n",
       "      <td>0.775412</td>\n",
       "      <td>0.562724</td>\n",
       "      <td>0.656463</td>\n",
       "      <td>0.596786</td>\n",
       "      <td>1.719340e+01</td>\n",
       "      <td>0.574113</td>\n",
       "      <td>0.590904</td>\n",
       "      <td>0.762380</td>\n",
       "      <td>0.518420</td>\n",
       "      <td>0.641070</td>\n",
       "      <td>0.574538</td>\n",
       "      <td>17.230395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.621400</td>\n",
       "      <td>0.600240</td>\n",
       "      <td>0.455364</td>\n",
       "      <td>0.455437</td>\n",
       "      <td>0.710595</td>\n",
       "      <td>0.615030</td>\n",
       "      <td>1.689676e+01</td>\n",
       "      <td>0.598486</td>\n",
       "      <td>0.564134</td>\n",
       "      <td>0.439909</td>\n",
       "      <td>0.432532</td>\n",
       "      <td>0.684842</td>\n",
       "      <td>0.601541</td>\n",
       "      <td>17.457877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>6</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>0.674409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661193</td>\n",
       "      <td>0.654319</td>\n",
       "      <td>0.673601</td>\n",
       "      <td>1.729011e+01</td>\n",
       "      <td>0.648426</td>\n",
       "      <td>0.648558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653307</td>\n",
       "      <td>0.641523</td>\n",
       "      <td>0.648398</td>\n",
       "      <td>17.198283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>7</td>\n",
       "      <td>0.647800</td>\n",
       "      <td>0.552376</td>\n",
       "      <td>0.605707</td>\n",
       "      <td>0.367834</td>\n",
       "      <td>0.631204</td>\n",
       "      <td>0.647599</td>\n",
       "      <td>1.506600e+01</td>\n",
       "      <td>0.635343</td>\n",
       "      <td>0.540465</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>0.368191</td>\n",
       "      <td>0.619552</td>\n",
       "      <td>0.635258</td>\n",
       "      <td>15.088255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chess</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.627800</td>\n",
       "      <td>0.595442</td>\n",
       "      <td>0.571934</td>\n",
       "      <td>0.489063</td>\n",
       "      <td>0.667875</td>\n",
       "      <td>0.627334</td>\n",
       "      <td>1.686399e+01</td>\n",
       "      <td>0.610136</td>\n",
       "      <td>0.580242</td>\n",
       "      <td>0.560967</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>0.653467</td>\n",
       "      <td>0.610706</td>\n",
       "      <td>16.944850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.664800</td>\n",
       "      <td>0.648302</td>\n",
       "      <td>0.690089</td>\n",
       "      <td>0.632782</td>\n",
       "      <td>0.670844</td>\n",
       "      <td>0.665294</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.626112</td>\n",
       "      <td>0.619927</td>\n",
       "      <td>0.667463</td>\n",
       "      <td>0.597686</td>\n",
       "      <td>0.641658</td>\n",
       "      <td>0.626075</td>\n",
       "      <td>14.517096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.661350</td>\n",
       "      <td>0.705504</td>\n",
       "      <td>0.749502</td>\n",
       "      <td>0.676425</td>\n",
       "      <td>0.664182</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.625847</td>\n",
       "      <td>0.610573</td>\n",
       "      <td>0.665335</td>\n",
       "      <td>0.596475</td>\n",
       "      <td>0.639539</td>\n",
       "      <td>0.625936</td>\n",
       "      <td>14.473513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.645750</td>\n",
       "      <td>0.722689</td>\n",
       "      <td>0.611755</td>\n",
       "      <td>0.675573</td>\n",
       "      <td>0.660019</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.624054</td>\n",
       "      <td>0.610864</td>\n",
       "      <td>0.702879</td>\n",
       "      <td>0.572393</td>\n",
       "      <td>0.641822</td>\n",
       "      <td>0.624240</td>\n",
       "      <td>14.312955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.664800</td>\n",
       "      <td>0.649014</td>\n",
       "      <td>0.734833</td>\n",
       "      <td>0.678614</td>\n",
       "      <td>0.679042</td>\n",
       "      <td>0.665024</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.628304</td>\n",
       "      <td>0.610831</td>\n",
       "      <td>0.719915</td>\n",
       "      <td>0.588126</td>\n",
       "      <td>0.658028</td>\n",
       "      <td>0.628462</td>\n",
       "      <td>14.207446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.642882</td>\n",
       "      <td>0.764683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686850</td>\n",
       "      <td>0.654819</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.627308</td>\n",
       "      <td>0.605375</td>\n",
       "      <td>0.739224</td>\n",
       "      <td>0.581527</td>\n",
       "      <td>0.652594</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>14.395535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.668600</td>\n",
       "      <td>0.661605</td>\n",
       "      <td>0.748702</td>\n",
       "      <td>0.625150</td>\n",
       "      <td>0.689756</td>\n",
       "      <td>0.668512</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.629234</td>\n",
       "      <td>0.610261</td>\n",
       "      <td>0.731262</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>0.663436</td>\n",
       "      <td>0.629592</td>\n",
       "      <td>14.558387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.667400</td>\n",
       "      <td>0.687429</td>\n",
       "      <td>0.741961</td>\n",
       "      <td>0.751592</td>\n",
       "      <td>0.685608</td>\n",
       "      <td>0.667708</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.630695</td>\n",
       "      <td>0.614189</td>\n",
       "      <td>0.713297</td>\n",
       "      <td>0.592313</td>\n",
       "      <td>0.657062</td>\n",
       "      <td>0.630820</td>\n",
       "      <td>14.462048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>chess</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.663743</td>\n",
       "      <td>0.656619</td>\n",
       "      <td>0.729780</td>\n",
       "      <td>0.721342</td>\n",
       "      <td>0.680586</td>\n",
       "      <td>0.663651</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.627365</td>\n",
       "      <td>0.611717</td>\n",
       "      <td>0.705625</td>\n",
       "      <td>0.584346</td>\n",
       "      <td>0.650591</td>\n",
       "      <td>0.627614</td>\n",
       "      <td>14.418140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951800</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.992689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950707</td>\n",
       "      <td>0.951440</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.663767</td>\n",
       "      <td>0.659082</td>\n",
       "      <td>0.671972</td>\n",
       "      <td>0.647028</td>\n",
       "      <td>0.670536</td>\n",
       "      <td>0.662618</td>\n",
       "      <td>11.808191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.997185</td>\n",
       "      <td>0.996384</td>\n",
       "      <td>0.943847</td>\n",
       "      <td>0.996386</td>\n",
       "      <td>0.996798</td>\n",
       "      <td>6.976932e-01</td>\n",
       "      <td>0.660048</td>\n",
       "      <td>0.654878</td>\n",
       "      <td>0.673190</td>\n",
       "      <td>0.643917</td>\n",
       "      <td>0.665924</td>\n",
       "      <td>0.659605</td>\n",
       "      <td>11.617813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974400</td>\n",
       "      <td>0.973339</td>\n",
       "      <td>0.966787</td>\n",
       "      <td>0.978409</td>\n",
       "      <td>0.961692</td>\n",
       "      <td>0.976200</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.661974</td>\n",
       "      <td>0.654613</td>\n",
       "      <td>0.687550</td>\n",
       "      <td>0.642933</td>\n",
       "      <td>0.667972</td>\n",
       "      <td>0.662706</td>\n",
       "      <td>11.718739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.944600</td>\n",
       "      <td>0.942040</td>\n",
       "      <td>0.950984</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.946968</td>\n",
       "      <td>0.947608</td>\n",
       "      <td>1.174331e-01</td>\n",
       "      <td>0.663235</td>\n",
       "      <td>0.649400</td>\n",
       "      <td>0.700479</td>\n",
       "      <td>0.625364</td>\n",
       "      <td>0.674811</td>\n",
       "      <td>0.663985</td>\n",
       "      <td>11.633878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.991200</td>\n",
       "      <td>0.991369</td>\n",
       "      <td>0.959280</td>\n",
       "      <td>0.989779</td>\n",
       "      <td>0.989828</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.668947</td>\n",
       "      <td>0.650372</td>\n",
       "      <td>0.723379</td>\n",
       "      <td>0.623046</td>\n",
       "      <td>0.681122</td>\n",
       "      <td>0.669468</td>\n",
       "      <td>11.597180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>6</td>\n",
       "      <td>0.959200</td>\n",
       "      <td>0.950787</td>\n",
       "      <td>0.966440</td>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.956591</td>\n",
       "      <td>0.959191</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.666490</td>\n",
       "      <td>0.655017</td>\n",
       "      <td>0.700720</td>\n",
       "      <td>0.634259</td>\n",
       "      <td>0.675179</td>\n",
       "      <td>0.668354</td>\n",
       "      <td>11.663694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973600</td>\n",
       "      <td>0.968974</td>\n",
       "      <td>0.977894</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.974185</td>\n",
       "      <td>0.975222</td>\n",
       "      <td>6.907915e-03</td>\n",
       "      <td>0.657790</td>\n",
       "      <td>0.650032</td>\n",
       "      <td>0.684680</td>\n",
       "      <td>0.636315</td>\n",
       "      <td>0.667187</td>\n",
       "      <td>0.658437</td>\n",
       "      <td>11.808197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>chess</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.970257</td>\n",
       "      <td>0.967194</td>\n",
       "      <td>0.972923</td>\n",
       "      <td>0.982427</td>\n",
       "      <td>0.968051</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>1.174335e-01</td>\n",
       "      <td>0.663179</td>\n",
       "      <td>0.653342</td>\n",
       "      <td>0.691710</td>\n",
       "      <td>0.636123</td>\n",
       "      <td>0.671819</td>\n",
       "      <td>0.663596</td>\n",
       "      <td>11.692527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0    chess        tree     1        0.704400         0.590343      0.898863   \n",
       "1    chess        tree     2        0.689800         0.714619      0.813580   \n",
       "2    chess        tree     3        0.683600         0.672395      0.855542   \n",
       "3    chess        tree     4        0.655000         0.669520      0.661712   \n",
       "4    chess        tree     5        0.674200         0.753927      0.870791   \n",
       "5    chess        tree     6        0.677400         0.750210      0.624051   \n",
       "6    chess        tree     7        0.696400         0.690909      0.922830   \n",
       "7    chess        tree   avg        0.682971         0.691703      0.806767   \n",
       "8    chess     log_reg     1        0.668400         0.731148      0.682372   \n",
       "9    chess     log_reg     2        0.685800         0.678740      0.689835   \n",
       "10   chess     log_reg     3        0.681600         0.666667      0.715086   \n",
       "11   chess     log_reg     4        0.679000         0.671294      0.720771   \n",
       "12   chess     log_reg     5        0.686800         0.676051      0.000000   \n",
       "13   chess     log_reg     6        0.685000         0.666026      1.000000   \n",
       "14   chess     log_reg     7        0.673600         0.676882      0.708601   \n",
       "15   chess     log_reg   avg        0.680029         0.680973      0.645238   \n",
       "16   chess  perceptron     1        0.617200         0.516467      0.460601   \n",
       "17   chess  perceptron     2        0.648400         0.635718      0.942949   \n",
       "18   chess  perceptron     3        0.590200         0.570401      0.763505   \n",
       "19   chess  perceptron     4        0.596000         0.618485      0.775412   \n",
       "20   chess  perceptron     5        0.621400         0.600240      0.455364   \n",
       "21   chess  perceptron     6        0.673600         0.674409      0.000000   \n",
       "22   chess  perceptron     7        0.647800         0.552376      0.605707   \n",
       "23   chess  perceptron   avg        0.627800         0.595442      0.571934   \n",
       "24   chess         knn     1        0.664800         0.648302      0.690089   \n",
       "25   chess         knn     2        0.664000         0.661350      0.705504   \n",
       "26   chess         knn     3        0.660000         0.645750      0.722689   \n",
       "27   chess         knn     4        0.664800         0.649014      0.734833   \n",
       "28   chess         knn     5        0.656600         0.642882      0.764683   \n",
       "29   chess         knn     6        0.668600         0.661605      0.748702   \n",
       "30   chess         knn     7        0.667400         0.687429      0.741961   \n",
       "31   chess         knn   avg        0.663743         0.656619      0.729780   \n",
       "32   chess      forest     1        0.951800         0.946667      0.992689   \n",
       "33   chess      forest     2        0.997000         0.997185      0.996384   \n",
       "34   chess      forest     3        0.974400         0.973339      0.966787   \n",
       "35   chess      forest     4        0.944600         0.942040      0.950984   \n",
       "36   chess      forest     5        0.991200         0.991369      0.959280   \n",
       "37   chess      forest     6        0.959200         0.950787      0.966440   \n",
       "38   chess      forest     7        0.973600         0.968974      0.977894   \n",
       "39   chess      forest   avg        0.970257         0.967194      0.972923   \n",
       "\n",
       "    train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0            0.481875  0.701170       0.705238    1.454112e+01       0.651879   \n",
       "1            0.724014  0.667326       0.689536    1.497608e+01       0.646899   \n",
       "2            0.878049  0.680783       0.683637    1.504514e+01       0.649489   \n",
       "3            0.646356  0.647755       0.654725    1.407817e+01       0.637402   \n",
       "4            0.973017  0.714998       0.672038    1.407134e+01       0.648360   \n",
       "5            0.913897  0.638594       0.677477    1.406440e+01       0.646500   \n",
       "6            0.905255  0.696180       0.696712    1.515565e+01       0.648094   \n",
       "7            0.788923  0.678115       0.682766    1.456170e+01       0.646946   \n",
       "8            0.903073  0.669589       0.668609    1.700689e+01       0.670873   \n",
       "9            0.756272  0.677318       0.685835    1.719340e+01       0.669279   \n",
       "10           1.000000  0.684281       0.681611    1.726248e+01       0.666755   \n",
       "11           0.735962  0.690930       0.679183    1.719340e+01       0.667486   \n",
       "12           0.620196  0.707836       0.685565    1.689676e+01       0.669611   \n",
       "13           0.651982  0.683689       0.684967    1.729011e+01       0.666954   \n",
       "14           1.000000  0.683598       0.673767    1.718650e+01       0.666290   \n",
       "15           0.809641  0.685320       0.679934    1.714708e+01       0.668178   \n",
       "16           1.000000  0.657848       0.619149    1.699339e+01       0.606654   \n",
       "17           0.000000  0.683758       0.648919    1.734578e+01       0.626179   \n",
       "18           0.376250  0.680942       0.590256    1.726248e+01       0.581751   \n",
       "19           0.562724  0.656463       0.596786    1.719340e+01       0.574113   \n",
       "20           0.455437  0.710595       0.615030    1.689676e+01       0.598486   \n",
       "21           0.661193  0.654319       0.673601    1.729011e+01       0.648426   \n",
       "22           0.367834  0.631204       0.647599    1.506600e+01       0.635343   \n",
       "23           0.489063  0.667875       0.627334    1.686399e+01       0.610136   \n",
       "24           0.632782  0.670844       0.665294    9.992007e-16       0.626112   \n",
       "25           0.749502  0.676425       0.664182    9.992007e-16       0.625847   \n",
       "26           0.611755  0.675573       0.660019    9.992007e-16       0.624054   \n",
       "27           0.678614  0.679042       0.665024    9.992007e-16       0.628304   \n",
       "28           1.000000  0.686850       0.654819    9.992007e-16       0.627308   \n",
       "29           0.625150  0.689756       0.668512    9.992007e-16       0.629234   \n",
       "30           0.751592  0.685608       0.667708    9.992007e-16       0.630695   \n",
       "31           0.721342  0.680586       0.663651    9.992007e-16       0.627365   \n",
       "32           1.000000  0.950707       0.951440    9.992007e-16       0.663767   \n",
       "33           0.943847  0.996386       0.996798    6.976932e-01       0.660048   \n",
       "34           0.978409  0.961692       0.976200    9.992007e-16       0.661974   \n",
       "35           0.999602  0.946968       0.947608    1.174331e-01       0.663235   \n",
       "36           0.989779  0.989828       0.990200    9.992007e-16       0.668947   \n",
       "37           0.997197  0.956591       0.959191    9.992007e-16       0.666490   \n",
       "38           0.968153  0.974185       0.975222    6.907915e-03       0.657790   \n",
       "39           0.982427  0.968051       0.970951    1.174335e-01       0.663179   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0         0.589677     0.883804          0.474531  0.688981      0.651822   \n",
       "1         0.629489     0.805511          0.613305  0.662325      0.646779   \n",
       "2         0.648336     0.856172          0.867125  0.679647      0.649786   \n",
       "3         0.635860     0.661608          0.598993  0.633143      0.637577   \n",
       "4         0.632281     0.849604          0.646696  0.689892      0.649447   \n",
       "5         0.641770     0.613897          0.662434  0.624941      0.646235   \n",
       "6         0.661217     0.910954          0.901127  0.689502      0.647578   \n",
       "7         0.634090     0.797364          0.680602  0.666919      0.647032   \n",
       "8         0.748957     0.687492          0.903977  0.676544      0.670851   \n",
       "9         0.662474     0.694888          0.740392  0.678012      0.669314   \n",
       "10        0.659531     0.718875          1.000000  0.686394      0.666881   \n",
       "11        0.661655     0.728168          0.722635  0.686022      0.667622   \n",
       "12        0.651137     0.000000          0.632374  0.681600      0.670100   \n",
       "13        0.657465     1.000000          0.650397  0.682560      0.667056   \n",
       "14        0.672467     0.708106          1.000000  0.679221      0.666379   \n",
       "15        0.673384     0.648218          0.807111  0.681479      0.668315   \n",
       "16        0.524088     0.460008          1.000000  0.651404      0.606485   \n",
       "17        0.631893     0.937966          0.000000  0.684410      0.626438   \n",
       "18        0.561655     0.731405          0.377051  0.651469      0.582284   \n",
       "19        0.590904     0.762380          0.518420  0.641070      0.574538   \n",
       "20        0.564134     0.439909          0.432532  0.684842      0.601541   \n",
       "21        0.648558     0.000000          0.653307  0.641523      0.648398   \n",
       "22        0.540465     0.595102          0.368191  0.619552      0.635258   \n",
       "23        0.580242     0.560967          0.478500  0.653467      0.610706   \n",
       "24        0.619927     0.667463          0.597686  0.641658      0.626075   \n",
       "25        0.610573     0.665335          0.596475  0.639539      0.625936   \n",
       "26        0.610864     0.702879          0.572393  0.641822      0.624240   \n",
       "27        0.610831     0.719915          0.588126  0.658028      0.628462   \n",
       "28        0.605375     0.739224          0.581527  0.652594      0.628175   \n",
       "29        0.610261     0.731262          0.561905  0.663436      0.629592   \n",
       "30        0.614189     0.713297          0.592313  0.657062      0.630820   \n",
       "31        0.611717     0.705625          0.584346  0.650591      0.627614   \n",
       "32        0.659082     0.671972          0.647028  0.670536      0.662618   \n",
       "33        0.654878     0.673190          0.643917  0.665924      0.659605   \n",
       "34        0.654613     0.687550          0.642933  0.667972      0.662706   \n",
       "35        0.649400     0.700479          0.625364  0.674811      0.663985   \n",
       "36        0.650372     0.723379          0.623046  0.681122      0.669468   \n",
       "37        0.655017     0.700720          0.634259  0.675179      0.668354   \n",
       "38        0.650032     0.684680          0.636315  0.667187      0.658437   \n",
       "39        0.653342     0.691710          0.636123  0.671819      0.663596   \n",
       "\n",
       "    test_log_loss  \n",
       "0       14.645670  \n",
       "1       15.150056  \n",
       "2       15.264734  \n",
       "3       14.833637  \n",
       "4       14.654800  \n",
       "5       14.498792  \n",
       "6       15.604190  \n",
       "7       14.950268  \n",
       "8       17.292325  \n",
       "9       17.230395  \n",
       "10      17.207458  \n",
       "11      17.230395  \n",
       "12      17.457877  \n",
       "13      17.198283  \n",
       "14      17.232689  \n",
       "15      17.264203  \n",
       "16      17.122903  \n",
       "17      17.308782  \n",
       "18      17.207458  \n",
       "19      17.230395  \n",
       "20      17.457877  \n",
       "21      17.198283  \n",
       "22      15.088255  \n",
       "23      16.944850  \n",
       "24      14.517096  \n",
       "25      14.473513  \n",
       "26      14.312955  \n",
       "27      14.207446  \n",
       "28      14.395535  \n",
       "29      14.558387  \n",
       "30      14.462048  \n",
       "31      14.418140  \n",
       "32      11.808191  \n",
       "33      11.617813  \n",
       "34      11.718739  \n",
       "35      11.633878  \n",
       "36      11.597180  \n",
       "37      11.663694  \n",
       "38      11.808197  \n",
       "39      11.692527  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_results_no_svm = perform_trials('chess', models_without_svm, chess_X, chess_y)\n",
    "chess_results_no_svm.to_csv('results/chess_no_svm.csv')\n",
    "chess_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 10.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.6min\n"
     ]
    }
   ],
   "source": [
    "chess_results_svm = perform_trials('chess', models_only_svm, chess_X, chess_y)\n",
    "chess_results_svm.to_csv('results/chess_svm.csv')\n",
    "chess_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_results_no_svm = pd.read_csv('results/chess_no_svm.csv')\n",
    "chess_results_svm = pd.read_csv('results/chess_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_results = chess_results_no_svm.append(chess_results_svm, ignore_index=True)\n",
    "chess_results.to_csv('results/chess.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrooms Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.554272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.625254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>1.574997</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>1.592083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999688</td>\n",
       "      <td>1.564635</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999174</td>\n",
       "      <td>0.999175</td>\n",
       "      <td>1.608669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  shrooms  tree     1          1.0000              1.0      1.000000   \n",
       "1  shrooms  tree     2          0.9994              1.0      0.998750   \n",
       "2  shrooms  tree   avg          0.9997              1.0      0.999375   \n",
       "\n",
       "   train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0                1.0  1.000000       1.000000        1.554272       1.000000   \n",
       "1                1.0  0.999375       0.999375        1.574997       0.998399   \n",
       "2                1.0  0.999687       0.999688        1.564635       0.999200   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0             1.0     1.000000               1.0  1.000000      1.000000   \n",
       "1             1.0     0.996702               1.0  0.998348      0.998351   \n",
       "2             1.0     0.998351               1.0  0.999174      0.999175   \n",
       "\n",
       "   test_log_loss  \n",
       "0       1.625254  \n",
       "1       1.592083  \n",
       "2       1.608669  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrooms_results_no_svm = perform_trials('shrooms', models_without_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_no_svm.to_csv('results/shrooms_no_svm.csv')\n",
    "shrooms_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results_svm = perform_trials('shrooms', models_only_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_svm.to_csv('results/shrooms_svm.csv')\n",
    "shrooms_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results_no_svm = pd.read_csv('results/shrooms_no_svm.csv')\n",
    "shrooms_results_svm = pd.read_csv('results/shrooms_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results = shrooms_results_no_svm.append(shrooms_results_svm, ignore_index=True)\n",
    "shrooms_results.to_csv('results/shrooms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Cardio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7122 0.7224 0.7244 0.729  0.7352 0.738  0.738 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71018712 0.72262559 0.72602912 0.73219589 0.7414073\n",
      " 0.7441335  0.74557375]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.7109301  0.71616149 0.71535747 0.71696713 0.71736711\n",
      " 0.72058804 0.71776871]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71342974 0.72853672 0.73330414 0.74085408 0.75277541\n",
      " 0.75516031 0.75794045]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71025872 0.71908501 0.7203257  0.72411356 0.72873901\n",
      " 0.7316989  0.73092221]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71217992 0.7223491  0.72433081 0.7289106  0.73507126\n",
      " 0.73787418 0.73785458]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 9.94037515 9.58807355 9.51899408 9.36011267 9.14596746\n",
      " 9.04925793 9.04925681]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7072 0.7104 0.7134 0.714  0.7182 0.717  0.7176]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71729122 0.72042873 0.72587774 0.72684657 0.73153264\n",
      " 0.73224623 0.73332237]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70368966 0.70643476 0.70447244 0.70408259 0.70722293\n",
      " 0.70172734 0.70133749]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71084999 0.71451931 0.72267343 0.72430359 0.72960389\n",
      " 0.73286088 0.73449603]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71005254 0.71311381 0.71469927 0.71500553 0.71893969\n",
      " 0.71645241 0.71672658]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70726983 0.71047703 0.71357293 0.71419309 0.71841341\n",
      " 0.71729411 0.71791676]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.11306711 10.00254159  9.89892206  9.87819815  9.73313321\n",
      "  9.77457847  9.75385456]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7148 0.7208 0.7226 0.7226 0.7284 0.7274 0.7308]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.72558873 0.73429355 0.73702424 0.73823084 0.74777637\n",
      " 0.74891148 0.75257985]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70640982 0.70640905 0.70641291 0.70404916 0.70286651\n",
      " 0.69775072 0.70090033]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.72345305 0.73565645 0.73932078 0.74175815 0.75477042\n",
      " 0.75802411 0.7616843 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71574225 0.71998699 0.72133472 0.72061665 0.72450029\n",
      " 0.72230869 0.72570451]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71493143 0.72103275 0.72286685 0.72290366 0.72881847\n",
      " 0.72788742 0.73129232]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 9.85056777 9.64333032 9.58115908 9.58115812 9.3808281\n",
      " 9.4153656  9.29793232]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7076 0.7076 0.712  0.7166 0.718  0.7202 0.722 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71354451 0.71574113 0.72136717 0.72743916 0.73286571\n",
      " 0.73634522 0.73776768]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70180968 0.69705092 0.69903898 0.70062471 0.69388732\n",
      " 0.69348421 0.69626434]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71347589 0.71831786 0.72517758 0.73284295 0.7425277\n",
      " 0.74737211 0.74818263]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70744846 0.70613    0.70986868 0.71358537 0.71271145\n",
      " 0.71416158 0.71636865]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70764278 0.70768439 0.71210828 0.71673383 0.71820751\n",
      " 0.72042816 0.72222349]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.09925176 10.09924984  9.94727651  9.7883951   9.74003697\n",
      "  9.66404974  9.60187963]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7028 0.7078 0.714  0.716  0.7196 0.7218 0.7234]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70175927 0.70908966 0.71583799 0.71763381 0.72460695\n",
      " 0.72766677 0.72878402]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71071182 0.70991818 0.71470064 0.71709108 0.71311256\n",
      " 0.71351017 0.71589824]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.69481467 0.70567259 0.71330554 0.71491439 0.72617714\n",
      " 0.73019806 0.73099642]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70613938 0.70941358 0.71513152 0.71722154 0.71866935\n",
      " 0.72035244 0.72220084]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70276325 0.70779538 0.71400309 0.71600273 0.71964485\n",
      " 0.72185411 0.72344733]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.26504572 10.09234752  9.87820407  9.80912588  9.68478181\n",
      "  9.6087949   9.55353254]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7036 0.7082 0.7142 0.7196 0.728  0.7282 0.7314]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70460275 0.70996288 0.71781816 0.7259626  0.73686675\n",
      " 0.73774584 0.74218078]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.68095432 0.6842163  0.68707012 0.68747745 0.69237125\n",
      " 0.69114843 0.69277692]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.72539004 0.73127162 0.74029354 0.75049501 0.76226203\n",
      " 0.76383066 0.76853654]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.69248503 0.69679837 0.7020477  0.7061299  0.71384426\n",
      " 0.7136309  0.71652045]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70317218 0.70774396 0.71368183 0.71898623 0.72731664\n",
      " 0.72748954 0.73065673]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.23740527 10.0785245   9.87128816  9.68477461  9.39464409\n",
      "  9.3877357   9.27720969]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7096 0.7186 0.724  0.7256 0.728  0.7286 0.7306]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71396619 0.72523244 0.73327807 0.7361804  0.74195342\n",
      " 0.74367672 0.74668793]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70064192 0.70503713 0.70543553 0.70463872 0.70023872\n",
      " 0.69864192 0.69904112]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71857715 0.73218838 0.74259719 0.7466004  0.75580922\n",
      " 0.75861082 0.76221082]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70716558 0.71490579 0.71892611 0.71984985 0.72033584\n",
      " 0.72033562 0.72194811]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70960954 0.71861275 0.72401636 0.72561956 0.72802397\n",
      " 0.72862637 0.73062597]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.03017309  9.71931866  9.53280511  9.47754147  9.39464473\n",
      "  9.37392035  9.30484135]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.769610</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.814388</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.726756</td>\n",
       "      <td>3.329554</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.760048</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.803292</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.718082</td>\n",
       "      <td>12.502100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.825455</td>\n",
       "      <td>0.771586</td>\n",
       "      <td>0.884584</td>\n",
       "      <td>0.736182</td>\n",
       "      <td>0.730678</td>\n",
       "      <td>3.377911</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.823521</td>\n",
       "      <td>0.757578</td>\n",
       "      <td>0.888329</td>\n",
       "      <td>0.717287</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>12.549928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.721763</td>\n",
       "      <td>0.817405</td>\n",
       "      <td>0.738914</td>\n",
       "      <td>0.728793</td>\n",
       "      <td>3.143042</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>0.691226</td>\n",
       "      <td>0.803083</td>\n",
       "      <td>0.711474</td>\n",
       "      <td>0.723870</td>\n",
       "      <td>12.463843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.787893</td>\n",
       "      <td>0.746233</td>\n",
       "      <td>0.823245</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>3.426264</td>\n",
       "      <td>0.724569</td>\n",
       "      <td>0.761494</td>\n",
       "      <td>0.689836</td>\n",
       "      <td>0.797068</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.724521</td>\n",
       "      <td>12.273081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.797519</td>\n",
       "      <td>0.734182</td>\n",
       "      <td>0.807801</td>\n",
       "      <td>0.743664</td>\n",
       "      <td>0.735456</td>\n",
       "      <td>2.977256</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.803805</td>\n",
       "      <td>0.711856</td>\n",
       "      <td>0.726788</td>\n",
       "      <td>12.826238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>0.734800</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.731538</td>\n",
       "      <td>0.799922</td>\n",
       "      <td>0.720253</td>\n",
       "      <td>0.734063</td>\n",
       "      <td>3.315736</td>\n",
       "      <td>0.731446</td>\n",
       "      <td>0.761724</td>\n",
       "      <td>0.672682</td>\n",
       "      <td>0.804416</td>\n",
       "      <td>0.720963</td>\n",
       "      <td>0.731479</td>\n",
       "      <td>12.584985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741400</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.714229</td>\n",
       "      <td>0.819456</td>\n",
       "      <td>0.748012</td>\n",
       "      <td>0.741457</td>\n",
       "      <td>3.101595</td>\n",
       "      <td>0.722185</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.658558</td>\n",
       "      <td>0.811395</td>\n",
       "      <td>0.695597</td>\n",
       "      <td>0.722577</td>\n",
       "      <td>12.450020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.733429</td>\n",
       "      <td>0.783695</td>\n",
       "      <td>0.725277</td>\n",
       "      <td>0.823829</td>\n",
       "      <td>0.730977</td>\n",
       "      <td>0.733553</td>\n",
       "      <td>3.238766</td>\n",
       "      <td>0.723389</td>\n",
       "      <td>0.772739</td>\n",
       "      <td>0.689663</td>\n",
       "      <td>0.815913</td>\n",
       "      <td>0.709872</td>\n",
       "      <td>0.723414</td>\n",
       "      <td>12.521457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.760739</td>\n",
       "      <td>0.663446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708817</td>\n",
       "      <td>0.728782</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.726646</td>\n",
       "      <td>0.757817</td>\n",
       "      <td>0.665702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708874</td>\n",
       "      <td>0.726637</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.661729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658646</td>\n",
       "      <td>0.688273</td>\n",
       "      <td>0.652064</td>\n",
       "      <td>16.938208</td>\n",
       "      <td>0.647785</td>\n",
       "      <td>0.649235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661212</td>\n",
       "      <td>0.681556</td>\n",
       "      <td>0.647767</td>\n",
       "      <td>17.306453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.763263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784059</td>\n",
       "      <td>0.715838</td>\n",
       "      <td>0.728898</td>\n",
       "      <td>16.986563</td>\n",
       "      <td>0.726769</td>\n",
       "      <td>0.747150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769117</td>\n",
       "      <td>0.714479</td>\n",
       "      <td>0.726690</td>\n",
       "      <td>17.302733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.652800</td>\n",
       "      <td>0.668092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686844</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.653097</td>\n",
       "      <td>17.117814</td>\n",
       "      <td>0.649785</td>\n",
       "      <td>0.656718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.669713</td>\n",
       "      <td>0.649753</td>\n",
       "      <td>17.292637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.751857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>17.179985</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.744387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764154</td>\n",
       "      <td>0.713106</td>\n",
       "      <td>0.725577</td>\n",
       "      <td>17.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>6</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.749176</td>\n",
       "      <td>0.649531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.720215</td>\n",
       "      <td>16.930908</td>\n",
       "      <td>0.725308</td>\n",
       "      <td>0.759396</td>\n",
       "      <td>0.660293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706385</td>\n",
       "      <td>0.725364</td>\n",
       "      <td>17.284266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.674133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658236</td>\n",
       "      <td>17.283204</td>\n",
       "      <td>0.665477</td>\n",
       "      <td>0.679728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665448</td>\n",
       "      <td>17.257167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.695571</td>\n",
       "      <td>0.718427</td>\n",
       "      <td>0.758997</td>\n",
       "      <td>0.800589</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>17.085078</td>\n",
       "      <td>0.695341</td>\n",
       "      <td>0.713490</td>\n",
       "      <td>0.760856</td>\n",
       "      <td>0.796319</td>\n",
       "      <td>0.599159</td>\n",
       "      <td>0.695319</td>\n",
       "      <td>17.285406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.813711</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.679807</td>\n",
       "      <td>0.658186</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.658831</td>\n",
       "      <td>0.820899</td>\n",
       "      <td>0.930943</td>\n",
       "      <td>0.645531</td>\n",
       "      <td>0.682359</td>\n",
       "      <td>0.658796</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>0.807792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970228</td>\n",
       "      <td>0.680869</td>\n",
       "      <td>0.530236</td>\n",
       "      <td>17.600960</td>\n",
       "      <td>0.532185</td>\n",
       "      <td>0.827289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975099</td>\n",
       "      <td>0.674746</td>\n",
       "      <td>0.533118</td>\n",
       "      <td>17.232724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.785208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718423</td>\n",
       "      <td>17.552606</td>\n",
       "      <td>0.713646</td>\n",
       "      <td>0.765788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713475</td>\n",
       "      <td>17.236444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.533800</td>\n",
       "      <td>0.814642</td>\n",
       "      <td>0.676447</td>\n",
       "      <td>0.424536</td>\n",
       "      <td>0.689242</td>\n",
       "      <td>0.529904</td>\n",
       "      <td>16.454390</td>\n",
       "      <td>0.523138</td>\n",
       "      <td>0.806657</td>\n",
       "      <td>0.686447</td>\n",
       "      <td>0.411917</td>\n",
       "      <td>0.687096</td>\n",
       "      <td>0.523739</td>\n",
       "      <td>16.344931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966224</td>\n",
       "      <td>0.639817</td>\n",
       "      <td>0.499818</td>\n",
       "      <td>17.359189</td>\n",
       "      <td>0.499677</td>\n",
       "      <td>0.823896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.962624</td>\n",
       "      <td>0.655747</td>\n",
       "      <td>0.500197</td>\n",
       "      <td>17.251322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>6</td>\n",
       "      <td>0.709800</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.977152</td>\n",
       "      <td>0.799922</td>\n",
       "      <td>0.675464</td>\n",
       "      <td>0.707998</td>\n",
       "      <td>18.243542</td>\n",
       "      <td>0.714185</td>\n",
       "      <td>0.761628</td>\n",
       "      <td>0.981616</td>\n",
       "      <td>0.804293</td>\n",
       "      <td>0.686119</td>\n",
       "      <td>0.714262</td>\n",
       "      <td>17.966164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>7</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.768566</td>\n",
       "      <td>0.730216</td>\n",
       "      <td>0.946357</td>\n",
       "      <td>0.301020</td>\n",
       "      <td>0.570834</td>\n",
       "      <td>17.283204</td>\n",
       "      <td>0.584415</td>\n",
       "      <td>0.765193</td>\n",
       "      <td>0.712289</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.308886</td>\n",
       "      <td>0.584213</td>\n",
       "      <td>17.257167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.604514</td>\n",
       "      <td>0.797079</td>\n",
       "      <td>0.617288</td>\n",
       "      <td>0.791935</td>\n",
       "      <td>0.523746</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>17.378965</td>\n",
       "      <td>0.603725</td>\n",
       "      <td>0.795907</td>\n",
       "      <td>0.615899</td>\n",
       "      <td>0.787140</td>\n",
       "      <td>0.527850</td>\n",
       "      <td>0.603971</td>\n",
       "      <td>17.222212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.708935</td>\n",
       "      <td>0.665862</td>\n",
       "      <td>0.748808</td>\n",
       "      <td>0.668511</td>\n",
       "      <td>0.688044</td>\n",
       "      <td>0.096709</td>\n",
       "      <td>0.662446</td>\n",
       "      <td>0.682355</td>\n",
       "      <td>0.608432</td>\n",
       "      <td>0.749792</td>\n",
       "      <td>0.642847</td>\n",
       "      <td>0.662438</td>\n",
       "      <td>14.255107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.676200</td>\n",
       "      <td>0.696905</td>\n",
       "      <td>0.645212</td>\n",
       "      <td>0.708401</td>\n",
       "      <td>0.670063</td>\n",
       "      <td>0.676807</td>\n",
       "      <td>0.096710</td>\n",
       "      <td>0.664385</td>\n",
       "      <td>0.674974</td>\n",
       "      <td>0.631371</td>\n",
       "      <td>0.696583</td>\n",
       "      <td>0.652445</td>\n",
       "      <td>0.664315</td>\n",
       "      <td>14.252454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.698636</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.730378</td>\n",
       "      <td>0.680570</td>\n",
       "      <td>0.691301</td>\n",
       "      <td>0.117433</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>0.685064</td>\n",
       "      <td>0.629046</td>\n",
       "      <td>0.719796</td>\n",
       "      <td>0.650257</td>\n",
       "      <td>0.662198</td>\n",
       "      <td>14.284339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.672400</td>\n",
       "      <td>0.702938</td>\n",
       "      <td>0.683584</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.689072</td>\n",
       "      <td>0.672980</td>\n",
       "      <td>0.145065</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.679177</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.718158</td>\n",
       "      <td>0.641689</td>\n",
       "      <td>0.661595</td>\n",
       "      <td>14.293903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.704795</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>0.683841</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>0.663508</td>\n",
       "      <td>0.677895</td>\n",
       "      <td>0.630013</td>\n",
       "      <td>0.714237</td>\n",
       "      <td>0.646774</td>\n",
       "      <td>0.663464</td>\n",
       "      <td>14.255112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.687437</td>\n",
       "      <td>0.658507</td>\n",
       "      <td>0.755983</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.660585</td>\n",
       "      <td>0.700069</td>\n",
       "      <td>0.593427</td>\n",
       "      <td>0.758407</td>\n",
       "      <td>0.628160</td>\n",
       "      <td>0.660660</td>\n",
       "      <td>14.273706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>0.700187</td>\n",
       "      <td>0.639888</td>\n",
       "      <td>0.743395</td>\n",
       "      <td>0.662453</td>\n",
       "      <td>0.679641</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.665154</td>\n",
       "      <td>0.693144</td>\n",
       "      <td>0.616159</td>\n",
       "      <td>0.737847</td>\n",
       "      <td>0.645988</td>\n",
       "      <td>0.665116</td>\n",
       "      <td>14.257235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.679857</td>\n",
       "      <td>0.699976</td>\n",
       "      <td>0.662977</td>\n",
       "      <td>0.737672</td>\n",
       "      <td>0.667303</td>\n",
       "      <td>0.679873</td>\n",
       "      <td>0.112499</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.684668</td>\n",
       "      <td>0.618423</td>\n",
       "      <td>0.727831</td>\n",
       "      <td>0.644023</td>\n",
       "      <td>0.662827</td>\n",
       "      <td>14.267408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.820587</td>\n",
       "      <td>0.818035</td>\n",
       "      <td>0.826709</td>\n",
       "      <td>0.824608</td>\n",
       "      <td>0.829720</td>\n",
       "      <td>0.096709</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.737436</td>\n",
       "      <td>0.711402</td>\n",
       "      <td>0.747270</td>\n",
       "      <td>0.723686</td>\n",
       "      <td>0.727936</td>\n",
       "      <td>10.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.855600</td>\n",
       "      <td>0.835790</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>0.835644</td>\n",
       "      <td>0.857880</td>\n",
       "      <td>0.858193</td>\n",
       "      <td>0.082893</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.713299</td>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.720940</td>\n",
       "      <td>0.725235</td>\n",
       "      <td>10.054622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.845053</td>\n",
       "      <td>0.924046</td>\n",
       "      <td>0.851566</td>\n",
       "      <td>0.816684</td>\n",
       "      <td>0.819709</td>\n",
       "      <td>0.110525</td>\n",
       "      <td>0.729215</td>\n",
       "      <td>0.734981</td>\n",
       "      <td>0.709723</td>\n",
       "      <td>0.743290</td>\n",
       "      <td>0.724629</td>\n",
       "      <td>0.728987</td>\n",
       "      <td>10.091817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.844806</td>\n",
       "      <td>0.992863</td>\n",
       "      <td>0.850686</td>\n",
       "      <td>0.826997</td>\n",
       "      <td>0.828814</td>\n",
       "      <td>0.138156</td>\n",
       "      <td>0.726169</td>\n",
       "      <td>0.731754</td>\n",
       "      <td>0.714361</td>\n",
       "      <td>0.740036</td>\n",
       "      <td>0.722557</td>\n",
       "      <td>0.726227</td>\n",
       "      <td>10.076941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.820430</td>\n",
       "      <td>0.902109</td>\n",
       "      <td>0.822276</td>\n",
       "      <td>0.809648</td>\n",
       "      <td>0.811848</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>0.728569</td>\n",
       "      <td>0.731344</td>\n",
       "      <td>0.724327</td>\n",
       "      <td>0.736583</td>\n",
       "      <td>0.727008</td>\n",
       "      <td>0.729069</td>\n",
       "      <td>10.075348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>6</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.831146</td>\n",
       "      <td>0.774786</td>\n",
       "      <td>0.850137</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>0.811292</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>0.749069</td>\n",
       "      <td>0.692911</td>\n",
       "      <td>0.767338</td>\n",
       "      <td>0.719588</td>\n",
       "      <td>0.730370</td>\n",
       "      <td>9.955777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>0.836871</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.840272</td>\n",
       "      <td>0.818923</td>\n",
       "      <td>0.822015</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.729385</td>\n",
       "      <td>0.744733</td>\n",
       "      <td>0.699818</td>\n",
       "      <td>0.761338</td>\n",
       "      <td>0.720746</td>\n",
       "      <td>0.729624</td>\n",
       "      <td>10.039738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>0.833526</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>0.839613</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.825942</td>\n",
       "      <td>0.108551</td>\n",
       "      <td>0.728002</td>\n",
       "      <td>0.737691</td>\n",
       "      <td>0.709406</td>\n",
       "      <td>0.748510</td>\n",
       "      <td>0.722736</td>\n",
       "      <td>0.728207</td>\n",
       "      <td>10.042702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   cardio        tree     1        0.727200         0.769610      0.657407   \n",
       "1   cardio        tree     2        0.730800         0.825455      0.771586   \n",
       "2   cardio        tree     3        0.727600         0.773550      0.721763   \n",
       "3   cardio        tree     4        0.737200         0.787893      0.746233   \n",
       "4   cardio        tree     5        0.735000         0.797519      0.734182   \n",
       "5   cardio        tree     6        0.734800         0.747525      0.731538   \n",
       "6   cardio        tree     7        0.741400         0.784314      0.714229   \n",
       "7   cardio        tree   avg        0.733429         0.783695      0.725277   \n",
       "8   cardio     log_reg     1        0.729200         0.760739      0.663446   \n",
       "9   cardio     log_reg     2        0.652000         0.661729      1.000000   \n",
       "10  cardio     log_reg     3        0.728000         0.763263      1.000000   \n",
       "11  cardio     log_reg     4        0.652800         0.668092      1.000000   \n",
       "12  cardio     log_reg     5        0.727200         0.751857      0.000000   \n",
       "13  cardio     log_reg     6        0.721600         0.749176      0.649531   \n",
       "14  cardio     log_reg     7        0.658200         0.674133      1.000000   \n",
       "15  cardio     log_reg   avg        0.695571         0.718427      0.758997   \n",
       "16  cardio  perceptron     1        0.659600         0.813711      0.937198   \n",
       "17  cardio  perceptron     2        0.538600         0.807792      1.000000   \n",
       "18  cardio  perceptron     3        0.716800         0.785208      0.000000   \n",
       "19  cardio  perceptron     4        0.533800         0.814642      0.676447   \n",
       "20  cardio  perceptron     5        0.502400         0.842105      0.000000   \n",
       "21  cardio  perceptron     6        0.709800         0.747525      0.977152   \n",
       "22  cardio  perceptron     7        0.570600         0.768566      0.730216   \n",
       "23  cardio  perceptron   avg        0.604514         0.797079      0.617288   \n",
       "24  cardio         knn     1        0.688400         0.708935      0.665862   \n",
       "25  cardio         knn     2        0.676200         0.696905      0.645212   \n",
       "26  cardio         knn     3        0.690600         0.698636      0.679260   \n",
       "27  cardio         knn     4        0.672400         0.702938      0.683584   \n",
       "28  cardio         knn     5        0.683600         0.704795      0.668524   \n",
       "29  cardio         knn     6        0.668200         0.687437      0.658507   \n",
       "30  cardio         knn     7        0.679600         0.700187      0.639888   \n",
       "31  cardio         knn   avg        0.679857         0.699976      0.662977   \n",
       "32  cardio      forest     1        0.830000         0.820587      0.818035   \n",
       "33  cardio      forest     2        0.855600         0.835790      0.845369   \n",
       "34  cardio      forest     3        0.820000         0.845053      0.924046   \n",
       "35  cardio      forest     4        0.829000         0.844806      0.992863   \n",
       "36  cardio      forest     5        0.813600         0.820430      0.902109   \n",
       "37  cardio      forest     6        0.811600         0.831146      0.774786   \n",
       "38  cardio      forest     7        0.822600         0.836871      0.920863   \n",
       "39  cardio      forest   avg        0.826057         0.833526      0.882582   \n",
       "\n",
       "    train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0            0.814388  0.705400       0.726756        3.329554       0.718092   \n",
       "1            0.884584  0.736182       0.730678        3.377911       0.716569   \n",
       "2            0.817405  0.738914       0.728793        3.143042       0.723985   \n",
       "3            0.823245  0.724413       0.737665        3.426264       0.724569   \n",
       "4            0.807801  0.743664       0.735456        2.977256       0.726877   \n",
       "5            0.799922  0.720253       0.734063        3.315736       0.731446   \n",
       "6            0.819456  0.748012       0.741457        3.101595       0.722185   \n",
       "7            0.823829  0.730977       0.733553        3.238766       0.723389   \n",
       "8            1.000000  0.708817       0.728782       17.158864       0.726646   \n",
       "9            0.658646  0.688273       0.652064       16.938208       0.647785   \n",
       "10           0.784059  0.715838       0.728898       16.986563       0.726769   \n",
       "11           0.686844  0.669090       0.653097       17.117814       0.649785   \n",
       "12           0.771612  0.716300       0.727424       17.179985       0.725615   \n",
       "13           1.000000  0.695804       0.720215       16.930908       0.725308   \n",
       "14           0.702962  0.000000       0.658236       17.283204       0.665477   \n",
       "15           0.800589  0.599160       0.695531       17.085078       0.695341   \n",
       "16           0.652623  0.679807       0.658186       17.158864       0.658831   \n",
       "17           0.970228  0.680869       0.530236       17.600960       0.532185   \n",
       "18           0.783652  0.000000       0.718423       17.552606       0.713646   \n",
       "19           0.424536  0.689242       0.529904       16.454390       0.523138   \n",
       "20           0.966224  0.639817       0.499818       17.359189       0.499677   \n",
       "21           0.799922  0.675464       0.707998       18.243542       0.714185   \n",
       "22           0.946357  0.301020       0.570834       17.283204       0.584415   \n",
       "23           0.791935  0.523746       0.602200       17.378965       0.603725   \n",
       "24           0.748808  0.668511       0.688044        0.096709       0.662446   \n",
       "25           0.708401  0.670063       0.676807        0.096710       0.664385   \n",
       "26           0.730378  0.680570       0.691301        0.117433       0.662262   \n",
       "27           0.738095  0.689072       0.672980        0.145065       0.661662   \n",
       "28           0.738641  0.669041       0.683841        0.124341       0.663508   \n",
       "29           0.755983  0.631415       0.666500        0.131248       0.660585   \n",
       "30           0.743395  0.662453       0.679641        0.075986       0.665154   \n",
       "31           0.737672  0.667303       0.679873        0.112499       0.662857   \n",
       "32           0.826709  0.824608       0.829720        0.096709       0.727969   \n",
       "33           0.835644  0.857880       0.858193        0.082893       0.724508   \n",
       "34           0.851566  0.816684       0.819709        0.110525       0.729215   \n",
       "35           0.850686  0.826997       0.828814        0.138156       0.726169   \n",
       "36           0.822276  0.809648       0.811848        0.124341       0.728569   \n",
       "37           0.850137  0.802960       0.811292        0.131248       0.730200   \n",
       "38           0.840272  0.818923       0.822015        0.075986       0.729385   \n",
       "39           0.839613  0.822529       0.825942        0.108551       0.728002   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0         0.760048     0.651762          0.803292  0.698032      0.718082   \n",
       "1         0.823521     0.757578          0.888329  0.717287      0.716578   \n",
       "2         0.753861     0.691226          0.803083  0.711474      0.723870   \n",
       "3         0.761494     0.689836          0.797068  0.713895      0.724521   \n",
       "4         0.775533     0.706000          0.803805  0.711856      0.726788   \n",
       "5         0.761724     0.672682          0.804416  0.720963      0.731479   \n",
       "6         0.772991     0.658558          0.811395  0.695597      0.722577   \n",
       "7         0.772739     0.689663          0.815913  0.709872      0.723414   \n",
       "8         0.757817     0.665702          1.000000  0.708874      0.726637   \n",
       "9         0.649235     1.000000          0.661212  0.681556      0.647767   \n",
       "10        0.747150     1.000000          0.769117  0.714479      0.726690   \n",
       "11        0.656718     1.000000          0.673785  0.669713      0.649753   \n",
       "12        0.744387     0.000000          0.764154  0.713106      0.725577   \n",
       "13        0.759396     0.660293          1.000000  0.706385      0.725364   \n",
       "14        0.679728     1.000000          0.705962  0.000000      0.665448   \n",
       "15        0.713490     0.760856          0.796319  0.599159      0.695319   \n",
       "16        0.820899     0.930943          0.645531  0.682359      0.658796   \n",
       "17        0.827289     1.000000          0.975099  0.674746      0.533118   \n",
       "18        0.765788     0.000000          0.764572  0.000000      0.713475   \n",
       "19        0.806657     0.686447          0.411917  0.687096      0.523739   \n",
       "20        0.823896     0.000000          0.962624  0.655747      0.500197   \n",
       "21        0.761628     0.981616          0.804293  0.686119      0.714262   \n",
       "22        0.765193     0.712289          0.945946  0.308886      0.584213   \n",
       "23        0.795907     0.615899          0.787140  0.527850      0.603971   \n",
       "24        0.682355     0.608432          0.749792  0.642847      0.662438   \n",
       "25        0.674974     0.631371          0.696583  0.652445      0.664315   \n",
       "26        0.685064     0.629046          0.719796  0.650257      0.662198   \n",
       "27        0.679177     0.620513          0.718158  0.641689      0.661595   \n",
       "28        0.677895     0.630013          0.714237  0.646774      0.663464   \n",
       "29        0.700069     0.593427          0.758407  0.628160      0.660660   \n",
       "30        0.693144     0.616159          0.737847  0.645988      0.665116   \n",
       "31        0.684668     0.618423          0.727831  0.644023      0.662827   \n",
       "32        0.737436     0.711402          0.747270  0.723686      0.727936   \n",
       "33        0.734523     0.713299          0.743713  0.720940      0.725235   \n",
       "34        0.734981     0.709723          0.743290  0.724629      0.728987   \n",
       "35        0.731754     0.714361          0.740036  0.722557      0.726227   \n",
       "36        0.731344     0.724327          0.736583  0.727008      0.729069   \n",
       "37        0.749069     0.692911          0.767338  0.719588      0.730370   \n",
       "38        0.744733     0.699818          0.761338  0.720746      0.729624   \n",
       "39        0.737691     0.709406          0.748510  0.722736      0.728207   \n",
       "\n",
       "    test_log_loss  \n",
       "0       12.502100  \n",
       "1       12.549928  \n",
       "2       12.463843  \n",
       "3       12.273081  \n",
       "4       12.826238  \n",
       "5       12.584985  \n",
       "6       12.450020  \n",
       "7       12.521457  \n",
       "8       17.266731  \n",
       "9       17.306453  \n",
       "10      17.302733  \n",
       "11      17.292637  \n",
       "12      17.287855  \n",
       "13      17.284266  \n",
       "14      17.257167  \n",
       "15      17.285406  \n",
       "16      17.266731  \n",
       "17      17.232724  \n",
       "18      17.236444  \n",
       "19      16.344931  \n",
       "20      17.251322  \n",
       "21      17.966164  \n",
       "22      17.257167  \n",
       "23      17.222212  \n",
       "24      14.255107  \n",
       "25      14.252454  \n",
       "26      14.284339  \n",
       "27      14.293903  \n",
       "28      14.255112  \n",
       "29      14.273706  \n",
       "30      14.257235  \n",
       "31      14.267408  \n",
       "32      10.004671  \n",
       "33      10.054622  \n",
       "34      10.091817  \n",
       "35      10.076941  \n",
       "36      10.075348  \n",
       "37       9.955777  \n",
       "38      10.039738  \n",
       "39      10.042702  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on cardio dataset\n",
    "cardio_results_no_svm = perform_trials('cardio', models_without_svm, cardio_X, cardio_y)\n",
    "cardio_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>0.814412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719471</td>\n",
       "      <td>0.736826</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.808387</td>\n",
       "      <td>0.800369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710771</td>\n",
       "      <td>0.727591</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.733200</td>\n",
       "      <td>0.748567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760604</td>\n",
       "      <td>0.732665</td>\n",
       "      <td>0.733509</td>\n",
       "      <td>16.931300</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.733427</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.757929</td>\n",
       "      <td>0.721300</td>\n",
       "      <td>0.726380</td>\n",
       "      <td>17.309641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824319</td>\n",
       "      <td>0.726668</td>\n",
       "      <td>0.737818</td>\n",
       "      <td>16.979656</td>\n",
       "      <td>0.727262</td>\n",
       "      <td>0.773072</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.813709</td>\n",
       "      <td>0.716606</td>\n",
       "      <td>0.727192</td>\n",
       "      <td>17.304327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.777726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.741597</td>\n",
       "      <td>0.735625</td>\n",
       "      <td>17.110906</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>0.752055</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.786744</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.727087</td>\n",
       "      <td>17.293700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.734400</td>\n",
       "      <td>0.770219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805790</td>\n",
       "      <td>0.725506</td>\n",
       "      <td>0.734588</td>\n",
       "      <td>17.179985</td>\n",
       "      <td>0.725523</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802022</td>\n",
       "      <td>0.715822</td>\n",
       "      <td>0.725488</td>\n",
       "      <td>17.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>6</td>\n",
       "      <td>0.728400</td>\n",
       "      <td>0.776371</td>\n",
       "      <td>0.821297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704654</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>16.924001</td>\n",
       "      <td>0.727862</td>\n",
       "      <td>0.784359</td>\n",
       "      <td>0.813484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709144</td>\n",
       "      <td>0.727918</td>\n",
       "      <td>17.280547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>7</td>\n",
       "      <td>0.738600</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>17.255972</td>\n",
       "      <td>0.728046</td>\n",
       "      <td>0.831545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995173</td>\n",
       "      <td>0.712434</td>\n",
       "      <td>0.728008</td>\n",
       "      <td>17.282010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.734829</td>\n",
       "      <td>0.795424</td>\n",
       "      <td>0.947959</td>\n",
       "      <td>0.884253</td>\n",
       "      <td>0.725033</td>\n",
       "      <td>0.734873</td>\n",
       "      <td>17.077241</td>\n",
       "      <td>0.727123</td>\n",
       "      <td>0.778404</td>\n",
       "      <td>0.944748</td>\n",
       "      <td>0.879368</td>\n",
       "      <td>0.713838</td>\n",
       "      <td>0.727095</td>\n",
       "      <td>17.289259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  cardio   svm     1        0.737200         0.805755      0.814412   \n",
       "1  cardio   svm     2        0.733200         0.748567      1.000000   \n",
       "2  cardio   svm     3        0.737000         0.785714      1.000000   \n",
       "3  cardio   svm     4        0.735000         0.777726      1.000000   \n",
       "4  cardio   svm     5        0.734400         0.770219      1.000000   \n",
       "5  cardio   svm     6        0.728400         0.776371      0.821297   \n",
       "6  cardio   svm     7        0.738600         0.903614      1.000000   \n",
       "7  cardio   svm   avg        0.734829         0.795424      0.947959   \n",
       "\n",
       "   train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0           1.000000  0.719471       0.736826       17.158864       0.727600   \n",
       "1           0.760604  0.732665       0.733509       16.931300       0.726415   \n",
       "2           0.824319  0.726668       0.737818       16.979656       0.727262   \n",
       "3           0.802260  0.741597       0.735625       17.110906       0.727154   \n",
       "4           0.805790  0.725506       0.734588       17.179985       0.725523   \n",
       "5           1.000000  0.704654       0.727103       16.924001       0.727862   \n",
       "6           0.996797  0.724668       0.738641       17.255972       0.728046   \n",
       "7           0.884253  0.725033       0.734873       17.077241       0.727123   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0        0.808387     0.800369          1.000000  0.710771      0.727591   \n",
       "1        0.733427     0.999784          0.757929  0.721300      0.726380   \n",
       "2        0.773072     0.999630          0.813709  0.716606      0.727192   \n",
       "3        0.752055     0.999969          0.786744  0.710793      0.727087   \n",
       "4        0.765986     1.000000          0.802022  0.715822      0.725488   \n",
       "5        0.784359     0.813484          1.000000  0.709144      0.727918   \n",
       "6        0.831545     1.000000          0.995173  0.712434      0.728008   \n",
       "7        0.778404     0.944748          0.879368  0.713838      0.727095   \n",
       "\n",
       "   test_log_loss  \n",
       "0      17.266731  \n",
       "1      17.309641  \n",
       "2      17.304327  \n",
       "3      17.293700  \n",
       "4      17.287855  \n",
       "5      17.280547  \n",
       "6      17.282010  \n",
       "7      17.289259  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running SVM algorithm on cardio dataset, generally take longer time to run than other algorithms combined\n",
    "cardio_results_svm = perform_trials('cardio', models_only_svm, cardio_X, cardio_y)\n",
    "cardio_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results of svm and non-svm algorithms and save as a csv file\n",
    "cardio_final_results = cardio_results_no_svm.append(cardio_results_svm, ignore_index=True)\n",
    "cardio_final_results.to_csv('results/cardio_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.769610</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.814388</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.726756</td>\n",
       "      <td>3.329554</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.760048</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.803292</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.718082</td>\n",
       "      <td>12.502100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.825455</td>\n",
       "      <td>0.771586</td>\n",
       "      <td>0.884584</td>\n",
       "      <td>0.736182</td>\n",
       "      <td>0.730678</td>\n",
       "      <td>3.377911</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.823521</td>\n",
       "      <td>0.757578</td>\n",
       "      <td>0.888329</td>\n",
       "      <td>0.717287</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>12.549928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.721763</td>\n",
       "      <td>0.817405</td>\n",
       "      <td>0.738914</td>\n",
       "      <td>0.728793</td>\n",
       "      <td>3.143042</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>0.691226</td>\n",
       "      <td>0.803083</td>\n",
       "      <td>0.711474</td>\n",
       "      <td>0.723870</td>\n",
       "      <td>12.463843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.787893</td>\n",
       "      <td>0.746233</td>\n",
       "      <td>0.823245</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>3.426264</td>\n",
       "      <td>0.724569</td>\n",
       "      <td>0.761494</td>\n",
       "      <td>0.689836</td>\n",
       "      <td>0.797068</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.724521</td>\n",
       "      <td>12.273081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.797519</td>\n",
       "      <td>0.734182</td>\n",
       "      <td>0.807801</td>\n",
       "      <td>0.743664</td>\n",
       "      <td>0.735456</td>\n",
       "      <td>2.977256</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.803805</td>\n",
       "      <td>0.711856</td>\n",
       "      <td>0.726788</td>\n",
       "      <td>12.826238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>0.734800</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.731538</td>\n",
       "      <td>0.799922</td>\n",
       "      <td>0.720253</td>\n",
       "      <td>0.734063</td>\n",
       "      <td>3.315736</td>\n",
       "      <td>0.731446</td>\n",
       "      <td>0.761724</td>\n",
       "      <td>0.672682</td>\n",
       "      <td>0.804416</td>\n",
       "      <td>0.720963</td>\n",
       "      <td>0.731479</td>\n",
       "      <td>12.584985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741400</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.714229</td>\n",
       "      <td>0.819456</td>\n",
       "      <td>0.748012</td>\n",
       "      <td>0.741457</td>\n",
       "      <td>3.101595</td>\n",
       "      <td>0.722185</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.658558</td>\n",
       "      <td>0.811395</td>\n",
       "      <td>0.695597</td>\n",
       "      <td>0.722577</td>\n",
       "      <td>12.450020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.733429</td>\n",
       "      <td>0.783695</td>\n",
       "      <td>0.725277</td>\n",
       "      <td>0.823829</td>\n",
       "      <td>0.730977</td>\n",
       "      <td>0.733553</td>\n",
       "      <td>3.238766</td>\n",
       "      <td>0.723389</td>\n",
       "      <td>0.772739</td>\n",
       "      <td>0.689663</td>\n",
       "      <td>0.815913</td>\n",
       "      <td>0.709872</td>\n",
       "      <td>0.723414</td>\n",
       "      <td>12.521457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.760739</td>\n",
       "      <td>0.663446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708817</td>\n",
       "      <td>0.728782</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.726646</td>\n",
       "      <td>0.757817</td>\n",
       "      <td>0.665702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708874</td>\n",
       "      <td>0.726637</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.661729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658646</td>\n",
       "      <td>0.688273</td>\n",
       "      <td>0.652064</td>\n",
       "      <td>16.938208</td>\n",
       "      <td>0.647785</td>\n",
       "      <td>0.649235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661212</td>\n",
       "      <td>0.681556</td>\n",
       "      <td>0.647767</td>\n",
       "      <td>17.306453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.763263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784059</td>\n",
       "      <td>0.715838</td>\n",
       "      <td>0.728898</td>\n",
       "      <td>16.986563</td>\n",
       "      <td>0.726769</td>\n",
       "      <td>0.747150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769117</td>\n",
       "      <td>0.714479</td>\n",
       "      <td>0.726690</td>\n",
       "      <td>17.302733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.652800</td>\n",
       "      <td>0.668092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686844</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.653097</td>\n",
       "      <td>17.117814</td>\n",
       "      <td>0.649785</td>\n",
       "      <td>0.656718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.669713</td>\n",
       "      <td>0.649753</td>\n",
       "      <td>17.292637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.751857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>17.179985</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.744387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764154</td>\n",
       "      <td>0.713106</td>\n",
       "      <td>0.725577</td>\n",
       "      <td>17.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>6</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.749176</td>\n",
       "      <td>0.649531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.720215</td>\n",
       "      <td>16.930908</td>\n",
       "      <td>0.725308</td>\n",
       "      <td>0.759396</td>\n",
       "      <td>0.660293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706385</td>\n",
       "      <td>0.725364</td>\n",
       "      <td>17.284266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.674133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658236</td>\n",
       "      <td>17.283204</td>\n",
       "      <td>0.665477</td>\n",
       "      <td>0.679728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665448</td>\n",
       "      <td>17.257167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.695571</td>\n",
       "      <td>0.718427</td>\n",
       "      <td>0.758997</td>\n",
       "      <td>0.800589</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>17.085078</td>\n",
       "      <td>0.695341</td>\n",
       "      <td>0.713490</td>\n",
       "      <td>0.760856</td>\n",
       "      <td>0.796319</td>\n",
       "      <td>0.599159</td>\n",
       "      <td>0.695319</td>\n",
       "      <td>17.285406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.813711</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.679807</td>\n",
       "      <td>0.658186</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.658831</td>\n",
       "      <td>0.820899</td>\n",
       "      <td>0.930943</td>\n",
       "      <td>0.645531</td>\n",
       "      <td>0.682359</td>\n",
       "      <td>0.658796</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>0.807792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970228</td>\n",
       "      <td>0.680869</td>\n",
       "      <td>0.530236</td>\n",
       "      <td>17.600960</td>\n",
       "      <td>0.532185</td>\n",
       "      <td>0.827289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975099</td>\n",
       "      <td>0.674746</td>\n",
       "      <td>0.533118</td>\n",
       "      <td>17.232724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.785208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718423</td>\n",
       "      <td>17.552606</td>\n",
       "      <td>0.713646</td>\n",
       "      <td>0.765788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713475</td>\n",
       "      <td>17.236444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.533800</td>\n",
       "      <td>0.814642</td>\n",
       "      <td>0.676447</td>\n",
       "      <td>0.424536</td>\n",
       "      <td>0.689242</td>\n",
       "      <td>0.529904</td>\n",
       "      <td>16.454390</td>\n",
       "      <td>0.523138</td>\n",
       "      <td>0.806657</td>\n",
       "      <td>0.686447</td>\n",
       "      <td>0.411917</td>\n",
       "      <td>0.687096</td>\n",
       "      <td>0.523739</td>\n",
       "      <td>16.344931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966224</td>\n",
       "      <td>0.639817</td>\n",
       "      <td>0.499818</td>\n",
       "      <td>17.359189</td>\n",
       "      <td>0.499677</td>\n",
       "      <td>0.823896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.962624</td>\n",
       "      <td>0.655747</td>\n",
       "      <td>0.500197</td>\n",
       "      <td>17.251322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>6</td>\n",
       "      <td>0.709800</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.977152</td>\n",
       "      <td>0.799922</td>\n",
       "      <td>0.675464</td>\n",
       "      <td>0.707998</td>\n",
       "      <td>18.243542</td>\n",
       "      <td>0.714185</td>\n",
       "      <td>0.761628</td>\n",
       "      <td>0.981616</td>\n",
       "      <td>0.804293</td>\n",
       "      <td>0.686119</td>\n",
       "      <td>0.714262</td>\n",
       "      <td>17.966164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>7</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.768566</td>\n",
       "      <td>0.730216</td>\n",
       "      <td>0.946357</td>\n",
       "      <td>0.301020</td>\n",
       "      <td>0.570834</td>\n",
       "      <td>17.283204</td>\n",
       "      <td>0.584415</td>\n",
       "      <td>0.765193</td>\n",
       "      <td>0.712289</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.308886</td>\n",
       "      <td>0.584213</td>\n",
       "      <td>17.257167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.604514</td>\n",
       "      <td>0.797079</td>\n",
       "      <td>0.617288</td>\n",
       "      <td>0.791935</td>\n",
       "      <td>0.523746</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>17.378965</td>\n",
       "      <td>0.603725</td>\n",
       "      <td>0.795907</td>\n",
       "      <td>0.615899</td>\n",
       "      <td>0.787140</td>\n",
       "      <td>0.527850</td>\n",
       "      <td>0.603971</td>\n",
       "      <td>17.222212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.708935</td>\n",
       "      <td>0.665862</td>\n",
       "      <td>0.748808</td>\n",
       "      <td>0.668511</td>\n",
       "      <td>0.688044</td>\n",
       "      <td>0.096709</td>\n",
       "      <td>0.662446</td>\n",
       "      <td>0.682355</td>\n",
       "      <td>0.608432</td>\n",
       "      <td>0.749792</td>\n",
       "      <td>0.642847</td>\n",
       "      <td>0.662438</td>\n",
       "      <td>14.255107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.676200</td>\n",
       "      <td>0.696905</td>\n",
       "      <td>0.645212</td>\n",
       "      <td>0.708401</td>\n",
       "      <td>0.670063</td>\n",
       "      <td>0.676807</td>\n",
       "      <td>0.096710</td>\n",
       "      <td>0.664385</td>\n",
       "      <td>0.674974</td>\n",
       "      <td>0.631371</td>\n",
       "      <td>0.696583</td>\n",
       "      <td>0.652445</td>\n",
       "      <td>0.664315</td>\n",
       "      <td>14.252454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.698636</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.730378</td>\n",
       "      <td>0.680570</td>\n",
       "      <td>0.691301</td>\n",
       "      <td>0.117433</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>0.685064</td>\n",
       "      <td>0.629046</td>\n",
       "      <td>0.719796</td>\n",
       "      <td>0.650257</td>\n",
       "      <td>0.662198</td>\n",
       "      <td>14.284339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.672400</td>\n",
       "      <td>0.702938</td>\n",
       "      <td>0.683584</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.689072</td>\n",
       "      <td>0.672980</td>\n",
       "      <td>0.145065</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.679177</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.718158</td>\n",
       "      <td>0.641689</td>\n",
       "      <td>0.661595</td>\n",
       "      <td>14.293903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.704795</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>0.683841</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>0.663508</td>\n",
       "      <td>0.677895</td>\n",
       "      <td>0.630013</td>\n",
       "      <td>0.714237</td>\n",
       "      <td>0.646774</td>\n",
       "      <td>0.663464</td>\n",
       "      <td>14.255112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.687437</td>\n",
       "      <td>0.658507</td>\n",
       "      <td>0.755983</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.660585</td>\n",
       "      <td>0.700069</td>\n",
       "      <td>0.593427</td>\n",
       "      <td>0.758407</td>\n",
       "      <td>0.628160</td>\n",
       "      <td>0.660660</td>\n",
       "      <td>14.273706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>0.700187</td>\n",
       "      <td>0.639888</td>\n",
       "      <td>0.743395</td>\n",
       "      <td>0.662453</td>\n",
       "      <td>0.679641</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.665154</td>\n",
       "      <td>0.693144</td>\n",
       "      <td>0.616159</td>\n",
       "      <td>0.737847</td>\n",
       "      <td>0.645988</td>\n",
       "      <td>0.665116</td>\n",
       "      <td>14.257235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.679857</td>\n",
       "      <td>0.699976</td>\n",
       "      <td>0.662977</td>\n",
       "      <td>0.737672</td>\n",
       "      <td>0.667303</td>\n",
       "      <td>0.679873</td>\n",
       "      <td>0.112499</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.684668</td>\n",
       "      <td>0.618423</td>\n",
       "      <td>0.727831</td>\n",
       "      <td>0.644023</td>\n",
       "      <td>0.662827</td>\n",
       "      <td>14.267408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.820587</td>\n",
       "      <td>0.818035</td>\n",
       "      <td>0.826709</td>\n",
       "      <td>0.824608</td>\n",
       "      <td>0.829720</td>\n",
       "      <td>0.096709</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.737436</td>\n",
       "      <td>0.711402</td>\n",
       "      <td>0.747270</td>\n",
       "      <td>0.723686</td>\n",
       "      <td>0.727936</td>\n",
       "      <td>10.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.855600</td>\n",
       "      <td>0.835790</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>0.835644</td>\n",
       "      <td>0.857880</td>\n",
       "      <td>0.858193</td>\n",
       "      <td>0.082893</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.713299</td>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.720940</td>\n",
       "      <td>0.725235</td>\n",
       "      <td>10.054622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.845053</td>\n",
       "      <td>0.924046</td>\n",
       "      <td>0.851566</td>\n",
       "      <td>0.816684</td>\n",
       "      <td>0.819709</td>\n",
       "      <td>0.110525</td>\n",
       "      <td>0.729215</td>\n",
       "      <td>0.734981</td>\n",
       "      <td>0.709723</td>\n",
       "      <td>0.743290</td>\n",
       "      <td>0.724629</td>\n",
       "      <td>0.728987</td>\n",
       "      <td>10.091817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.844806</td>\n",
       "      <td>0.992863</td>\n",
       "      <td>0.850686</td>\n",
       "      <td>0.826997</td>\n",
       "      <td>0.828814</td>\n",
       "      <td>0.138156</td>\n",
       "      <td>0.726169</td>\n",
       "      <td>0.731754</td>\n",
       "      <td>0.714361</td>\n",
       "      <td>0.740036</td>\n",
       "      <td>0.722557</td>\n",
       "      <td>0.726227</td>\n",
       "      <td>10.076941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.820430</td>\n",
       "      <td>0.902109</td>\n",
       "      <td>0.822276</td>\n",
       "      <td>0.809648</td>\n",
       "      <td>0.811848</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>0.728569</td>\n",
       "      <td>0.731344</td>\n",
       "      <td>0.724327</td>\n",
       "      <td>0.736583</td>\n",
       "      <td>0.727008</td>\n",
       "      <td>0.729069</td>\n",
       "      <td>10.075348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>6</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.831146</td>\n",
       "      <td>0.774786</td>\n",
       "      <td>0.850137</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>0.811292</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>0.749069</td>\n",
       "      <td>0.692911</td>\n",
       "      <td>0.767338</td>\n",
       "      <td>0.719588</td>\n",
       "      <td>0.730370</td>\n",
       "      <td>9.955777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>0.836871</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.840272</td>\n",
       "      <td>0.818923</td>\n",
       "      <td>0.822015</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.729385</td>\n",
       "      <td>0.744733</td>\n",
       "      <td>0.699818</td>\n",
       "      <td>0.761338</td>\n",
       "      <td>0.720746</td>\n",
       "      <td>0.729624</td>\n",
       "      <td>10.039738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>0.833526</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>0.839613</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.825942</td>\n",
       "      <td>0.108551</td>\n",
       "      <td>0.728002</td>\n",
       "      <td>0.737691</td>\n",
       "      <td>0.709406</td>\n",
       "      <td>0.748510</td>\n",
       "      <td>0.722736</td>\n",
       "      <td>0.728207</td>\n",
       "      <td>10.042702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>0.814412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719471</td>\n",
       "      <td>0.736826</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.808387</td>\n",
       "      <td>0.800369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710771</td>\n",
       "      <td>0.727591</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.733200</td>\n",
       "      <td>0.748567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760604</td>\n",
       "      <td>0.732665</td>\n",
       "      <td>0.733509</td>\n",
       "      <td>16.931300</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.733427</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.757929</td>\n",
       "      <td>0.721300</td>\n",
       "      <td>0.726380</td>\n",
       "      <td>17.309641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824319</td>\n",
       "      <td>0.726668</td>\n",
       "      <td>0.737818</td>\n",
       "      <td>16.979656</td>\n",
       "      <td>0.727262</td>\n",
       "      <td>0.773072</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.813709</td>\n",
       "      <td>0.716606</td>\n",
       "      <td>0.727192</td>\n",
       "      <td>17.304327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.777726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.741597</td>\n",
       "      <td>0.735625</td>\n",
       "      <td>17.110906</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>0.752055</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.786744</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.727087</td>\n",
       "      <td>17.293700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.734400</td>\n",
       "      <td>0.770219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805790</td>\n",
       "      <td>0.725506</td>\n",
       "      <td>0.734588</td>\n",
       "      <td>17.179985</td>\n",
       "      <td>0.725523</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802022</td>\n",
       "      <td>0.715822</td>\n",
       "      <td>0.725488</td>\n",
       "      <td>17.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>6</td>\n",
       "      <td>0.728400</td>\n",
       "      <td>0.776371</td>\n",
       "      <td>0.821297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704654</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>16.924001</td>\n",
       "      <td>0.727862</td>\n",
       "      <td>0.784359</td>\n",
       "      <td>0.813484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709144</td>\n",
       "      <td>0.727918</td>\n",
       "      <td>17.280547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>7</td>\n",
       "      <td>0.738600</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>17.255972</td>\n",
       "      <td>0.728046</td>\n",
       "      <td>0.831545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995173</td>\n",
       "      <td>0.712434</td>\n",
       "      <td>0.728008</td>\n",
       "      <td>17.282010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.734829</td>\n",
       "      <td>0.795424</td>\n",
       "      <td>0.947959</td>\n",
       "      <td>0.884253</td>\n",
       "      <td>0.725033</td>\n",
       "      <td>0.734873</td>\n",
       "      <td>17.077241</td>\n",
       "      <td>0.727123</td>\n",
       "      <td>0.778404</td>\n",
       "      <td>0.944748</td>\n",
       "      <td>0.879368</td>\n",
       "      <td>0.713838</td>\n",
       "      <td>0.727095</td>\n",
       "      <td>17.289259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   cardio        tree     1        0.727200         0.769610      0.657407   \n",
       "1   cardio        tree     2        0.730800         0.825455      0.771586   \n",
       "2   cardio        tree     3        0.727600         0.773550      0.721763   \n",
       "3   cardio        tree     4        0.737200         0.787893      0.746233   \n",
       "4   cardio        tree     5        0.735000         0.797519      0.734182   \n",
       "5   cardio        tree     6        0.734800         0.747525      0.731538   \n",
       "6   cardio        tree     7        0.741400         0.784314      0.714229   \n",
       "7   cardio        tree   avg        0.733429         0.783695      0.725277   \n",
       "8   cardio     log_reg     1        0.729200         0.760739      0.663446   \n",
       "9   cardio     log_reg     2        0.652000         0.661729      1.000000   \n",
       "10  cardio     log_reg     3        0.728000         0.763263      1.000000   \n",
       "11  cardio     log_reg     4        0.652800         0.668092      1.000000   \n",
       "12  cardio     log_reg     5        0.727200         0.751857      0.000000   \n",
       "13  cardio     log_reg     6        0.721600         0.749176      0.649531   \n",
       "14  cardio     log_reg     7        0.658200         0.674133      1.000000   \n",
       "15  cardio     log_reg   avg        0.695571         0.718427      0.758997   \n",
       "16  cardio  perceptron     1        0.659600         0.813711      0.937198   \n",
       "17  cardio  perceptron     2        0.538600         0.807792      1.000000   \n",
       "18  cardio  perceptron     3        0.716800         0.785208      0.000000   \n",
       "19  cardio  perceptron     4        0.533800         0.814642      0.676447   \n",
       "20  cardio  perceptron     5        0.502400         0.842105      0.000000   \n",
       "21  cardio  perceptron     6        0.709800         0.747525      0.977152   \n",
       "22  cardio  perceptron     7        0.570600         0.768566      0.730216   \n",
       "23  cardio  perceptron   avg        0.604514         0.797079      0.617288   \n",
       "24  cardio         knn     1        0.688400         0.708935      0.665862   \n",
       "25  cardio         knn     2        0.676200         0.696905      0.645212   \n",
       "26  cardio         knn     3        0.690600         0.698636      0.679260   \n",
       "27  cardio         knn     4        0.672400         0.702938      0.683584   \n",
       "28  cardio         knn     5        0.683600         0.704795      0.668524   \n",
       "29  cardio         knn     6        0.668200         0.687437      0.658507   \n",
       "30  cardio         knn     7        0.679600         0.700187      0.639888   \n",
       "31  cardio         knn   avg        0.679857         0.699976      0.662977   \n",
       "32  cardio      forest     1        0.830000         0.820587      0.818035   \n",
       "33  cardio      forest     2        0.855600         0.835790      0.845369   \n",
       "34  cardio      forest     3        0.820000         0.845053      0.924046   \n",
       "35  cardio      forest     4        0.829000         0.844806      0.992863   \n",
       "36  cardio      forest     5        0.813600         0.820430      0.902109   \n",
       "37  cardio      forest     6        0.811600         0.831146      0.774786   \n",
       "38  cardio      forest     7        0.822600         0.836871      0.920863   \n",
       "39  cardio      forest   avg        0.826057         0.833526      0.882582   \n",
       "40  cardio         svm     1        0.737200         0.805755      0.814412   \n",
       "41  cardio         svm     2        0.733200         0.748567      1.000000   \n",
       "42  cardio         svm     3        0.737000         0.785714      1.000000   \n",
       "43  cardio         svm     4        0.735000         0.777726      1.000000   \n",
       "44  cardio         svm     5        0.734400         0.770219      1.000000   \n",
       "45  cardio         svm     6        0.728400         0.776371      0.821297   \n",
       "46  cardio         svm     7        0.738600         0.903614      1.000000   \n",
       "47  cardio         svm   avg        0.734829         0.795424      0.947959   \n",
       "\n",
       "    train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0            0.814388  0.705400       0.726756        3.329554       0.718092   \n",
       "1            0.884584  0.736182       0.730678        3.377911       0.716569   \n",
       "2            0.817405  0.738914       0.728793        3.143042       0.723985   \n",
       "3            0.823245  0.724413       0.737665        3.426264       0.724569   \n",
       "4            0.807801  0.743664       0.735456        2.977256       0.726877   \n",
       "5            0.799922  0.720253       0.734063        3.315736       0.731446   \n",
       "6            0.819456  0.748012       0.741457        3.101595       0.722185   \n",
       "7            0.823829  0.730977       0.733553        3.238766       0.723389   \n",
       "8            1.000000  0.708817       0.728782       17.158864       0.726646   \n",
       "9            0.658646  0.688273       0.652064       16.938208       0.647785   \n",
       "10           0.784059  0.715838       0.728898       16.986563       0.726769   \n",
       "11           0.686844  0.669090       0.653097       17.117814       0.649785   \n",
       "12           0.771612  0.716300       0.727424       17.179985       0.725615   \n",
       "13           1.000000  0.695804       0.720215       16.930908       0.725308   \n",
       "14           0.702962  0.000000       0.658236       17.283204       0.665477   \n",
       "15           0.800589  0.599160       0.695531       17.085078       0.695341   \n",
       "16           0.652623  0.679807       0.658186       17.158864       0.658831   \n",
       "17           0.970228  0.680869       0.530236       17.600960       0.532185   \n",
       "18           0.783652  0.000000       0.718423       17.552606       0.713646   \n",
       "19           0.424536  0.689242       0.529904       16.454390       0.523138   \n",
       "20           0.966224  0.639817       0.499818       17.359189       0.499677   \n",
       "21           0.799922  0.675464       0.707998       18.243542       0.714185   \n",
       "22           0.946357  0.301020       0.570834       17.283204       0.584415   \n",
       "23           0.791935  0.523746       0.602200       17.378965       0.603725   \n",
       "24           0.748808  0.668511       0.688044        0.096709       0.662446   \n",
       "25           0.708401  0.670063       0.676807        0.096710       0.664385   \n",
       "26           0.730378  0.680570       0.691301        0.117433       0.662262   \n",
       "27           0.738095  0.689072       0.672980        0.145065       0.661662   \n",
       "28           0.738641  0.669041       0.683841        0.124341       0.663508   \n",
       "29           0.755983  0.631415       0.666500        0.131248       0.660585   \n",
       "30           0.743395  0.662453       0.679641        0.075986       0.665154   \n",
       "31           0.737672  0.667303       0.679873        0.112499       0.662857   \n",
       "32           0.826709  0.824608       0.829720        0.096709       0.727969   \n",
       "33           0.835644  0.857880       0.858193        0.082893       0.724508   \n",
       "34           0.851566  0.816684       0.819709        0.110525       0.729215   \n",
       "35           0.850686  0.826997       0.828814        0.138156       0.726169   \n",
       "36           0.822276  0.809648       0.811848        0.124341       0.728569   \n",
       "37           0.850137  0.802960       0.811292        0.131248       0.730200   \n",
       "38           0.840272  0.818923       0.822015        0.075986       0.729385   \n",
       "39           0.839613  0.822529       0.825942        0.108551       0.728002   \n",
       "40           1.000000  0.719471       0.736826       17.158864       0.727600   \n",
       "41           0.760604  0.732665       0.733509       16.931300       0.726415   \n",
       "42           0.824319  0.726668       0.737818       16.979656       0.727262   \n",
       "43           0.802260  0.741597       0.735625       17.110906       0.727154   \n",
       "44           0.805790  0.725506       0.734588       17.179985       0.725523   \n",
       "45           1.000000  0.704654       0.727103       16.924001       0.727862   \n",
       "46           0.996797  0.724668       0.738641       17.255972       0.728046   \n",
       "47           0.884253  0.725033       0.734873       17.077241       0.727123   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0         0.760048     0.651762          0.803292  0.698032      0.718082   \n",
       "1         0.823521     0.757578          0.888329  0.717287      0.716578   \n",
       "2         0.753861     0.691226          0.803083  0.711474      0.723870   \n",
       "3         0.761494     0.689836          0.797068  0.713895      0.724521   \n",
       "4         0.775533     0.706000          0.803805  0.711856      0.726788   \n",
       "5         0.761724     0.672682          0.804416  0.720963      0.731479   \n",
       "6         0.772991     0.658558          0.811395  0.695597      0.722577   \n",
       "7         0.772739     0.689663          0.815913  0.709872      0.723414   \n",
       "8         0.757817     0.665702          1.000000  0.708874      0.726637   \n",
       "9         0.649235     1.000000          0.661212  0.681556      0.647767   \n",
       "10        0.747150     1.000000          0.769117  0.714479      0.726690   \n",
       "11        0.656718     1.000000          0.673785  0.669713      0.649753   \n",
       "12        0.744387     0.000000          0.764154  0.713106      0.725577   \n",
       "13        0.759396     0.660293          1.000000  0.706385      0.725364   \n",
       "14        0.679728     1.000000          0.705962  0.000000      0.665448   \n",
       "15        0.713490     0.760856          0.796319  0.599159      0.695319   \n",
       "16        0.820899     0.930943          0.645531  0.682359      0.658796   \n",
       "17        0.827289     1.000000          0.975099  0.674746      0.533118   \n",
       "18        0.765788     0.000000          0.764572  0.000000      0.713475   \n",
       "19        0.806657     0.686447          0.411917  0.687096      0.523739   \n",
       "20        0.823896     0.000000          0.962624  0.655747      0.500197   \n",
       "21        0.761628     0.981616          0.804293  0.686119      0.714262   \n",
       "22        0.765193     0.712289          0.945946  0.308886      0.584213   \n",
       "23        0.795907     0.615899          0.787140  0.527850      0.603971   \n",
       "24        0.682355     0.608432          0.749792  0.642847      0.662438   \n",
       "25        0.674974     0.631371          0.696583  0.652445      0.664315   \n",
       "26        0.685064     0.629046          0.719796  0.650257      0.662198   \n",
       "27        0.679177     0.620513          0.718158  0.641689      0.661595   \n",
       "28        0.677895     0.630013          0.714237  0.646774      0.663464   \n",
       "29        0.700069     0.593427          0.758407  0.628160      0.660660   \n",
       "30        0.693144     0.616159          0.737847  0.645988      0.665116   \n",
       "31        0.684668     0.618423          0.727831  0.644023      0.662827   \n",
       "32        0.737436     0.711402          0.747270  0.723686      0.727936   \n",
       "33        0.734523     0.713299          0.743713  0.720940      0.725235   \n",
       "34        0.734981     0.709723          0.743290  0.724629      0.728987   \n",
       "35        0.731754     0.714361          0.740036  0.722557      0.726227   \n",
       "36        0.731344     0.724327          0.736583  0.727008      0.729069   \n",
       "37        0.749069     0.692911          0.767338  0.719588      0.730370   \n",
       "38        0.744733     0.699818          0.761338  0.720746      0.729624   \n",
       "39        0.737691     0.709406          0.748510  0.722736      0.728207   \n",
       "40        0.808387     0.800369          1.000000  0.710771      0.727591   \n",
       "41        0.733427     0.999784          0.757929  0.721300      0.726380   \n",
       "42        0.773072     0.999630          0.813709  0.716606      0.727192   \n",
       "43        0.752055     0.999969          0.786744  0.710793      0.727087   \n",
       "44        0.765986     1.000000          0.802022  0.715822      0.725488   \n",
       "45        0.784359     0.813484          1.000000  0.709144      0.727918   \n",
       "46        0.831545     1.000000          0.995173  0.712434      0.728008   \n",
       "47        0.778404     0.944748          0.879368  0.713838      0.727095   \n",
       "\n",
       "    test_log_loss  \n",
       "0       12.502100  \n",
       "1       12.549928  \n",
       "2       12.463843  \n",
       "3       12.273081  \n",
       "4       12.826238  \n",
       "5       12.584985  \n",
       "6       12.450020  \n",
       "7       12.521457  \n",
       "8       17.266731  \n",
       "9       17.306453  \n",
       "10      17.302733  \n",
       "11      17.292637  \n",
       "12      17.287855  \n",
       "13      17.284266  \n",
       "14      17.257167  \n",
       "15      17.285406  \n",
       "16      17.266731  \n",
       "17      17.232724  \n",
       "18      17.236444  \n",
       "19      16.344931  \n",
       "20      17.251322  \n",
       "21      17.966164  \n",
       "22      17.257167  \n",
       "23      17.222212  \n",
       "24      14.255107  \n",
       "25      14.252454  \n",
       "26      14.284339  \n",
       "27      14.293903  \n",
       "28      14.255112  \n",
       "29      14.273706  \n",
       "30      14.257235  \n",
       "31      14.267408  \n",
       "32      10.004671  \n",
       "33      10.054622  \n",
       "34      10.091817  \n",
       "35      10.076941  \n",
       "36      10.075348  \n",
       "37       9.955777  \n",
       "38      10.039738  \n",
       "39      10.042702  \n",
       "40      17.266731  \n",
       "41      17.309641  \n",
       "42      17.304327  \n",
       "43      17.293700  \n",
       "44      17.287855  \n",
       "45      17.280547  \n",
       "46      17.282010  \n",
       "47      17.289259  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/cardio_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Australian Rain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7874 0.7874    nan 0.8418 0.7874 0.7874    nan 0.8418 0.7874 0.7874\n",
      "    nan 0.842  0.7874 0.8228    nan 0.8418 0.7874 0.8408    nan 0.8418\n",
      " 0.8338 0.8414    nan 0.8418 0.8404 0.8418    nan 0.8418 0.8418 0.8416\n",
      "    nan 0.8418 0.8418 0.8418    nan 0.8416 0.8418 0.8418    nan 0.8422\n",
      " 0.8418 0.8418    nan 0.8418 0.8418 0.8418    nan 0.8418 0.842  0.8418\n",
      "    nan 0.8418]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.78   0.78      nan 0.8418 0.78   0.78      nan 0.8412 0.78   0.78\n",
      "    nan 0.8416 0.78   0.8304    nan 0.8412 0.78   0.8412    nan 0.8416\n",
      " 0.8382 0.8414    nan 0.8416 0.8408 0.8414    nan 0.8414 0.8408 0.8414\n",
      "    nan 0.8416 0.8412 0.8414    nan 0.8416 0.8416 0.8416    nan 0.8418\n",
      " 0.8414 0.8416    nan 0.8416 0.8414 0.841     nan 0.8416 0.8416 0.8412\n",
      "    nan 0.8412]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7848 0.7848    nan 0.8366 0.7848 0.7848    nan 0.8366 0.7848 0.7848\n",
      "    nan 0.8366 0.7848 0.8252    nan 0.8366 0.7848 0.8354    nan 0.8368\n",
      " 0.8336 0.8366    nan 0.8368 0.8348 0.8368    nan 0.8364 0.8366 0.8368\n",
      "    nan 0.8366 0.8366 0.837     nan 0.8368 0.8366 0.837     nan 0.8368\n",
      " 0.8368 0.8368    nan 0.837  0.8368 0.8366    nan 0.8366 0.8368 0.8368\n",
      "    nan 0.8368]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7742 0.7742    nan 0.8368 0.7742 0.7742    nan 0.8368 0.7742 0.7742\n",
      "    nan 0.8366 0.7742 0.825     nan 0.8366 0.7742 0.8356    nan 0.8368\n",
      " 0.8292 0.8368    nan 0.8366 0.8364 0.8368    nan 0.8368 0.8366 0.8368\n",
      "    nan 0.8366 0.8368 0.8368    nan 0.8368 0.8368 0.8368    nan 0.8368\n",
      " 0.8366 0.8368    nan 0.8366 0.8368 0.8366    nan 0.8368 0.8366 0.8368\n",
      "    nan 0.8368]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7768 0.7768    nan 0.8386 0.7768 0.7768    nan 0.8382 0.7768 0.777\n",
      "    nan 0.8382 0.7768 0.8306    nan 0.8382 0.7768 0.839     nan 0.8382\n",
      " 0.8344 0.838     nan 0.8384 0.8382 0.8386    nan 0.8386 0.8382 0.8382\n",
      "    nan 0.8382 0.8382 0.8382    nan 0.8386 0.8382 0.8384    nan 0.8382\n",
      " 0.838  0.8382    nan 0.8384 0.8384 0.8384    nan 0.8384 0.8382 0.8382\n",
      "    nan 0.8382]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8494 0.8502 0.8496 0.8498 0.8486 0.8484 0.8486]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8522 0.852  0.8508 0.8506 0.8506 0.8502 0.85  ]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8408 0.8408 0.842  0.8422 0.8414 0.8418 0.8402]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8448 0.8462 0.8458 0.8458 0.8468 0.8462 0.8444]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8512 0.848  0.8496 0.85   0.848  0.8484 0.8462]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84920</td>\n",
       "      <td>0.792060</td>\n",
       "      <td>0.394167</td>\n",
       "      <td>0.972060</td>\n",
       "      <td>0.526382</td>\n",
       "      <td>0.683114</td>\n",
       "      <td>5.208465e+00</td>\n",
       "      <td>0.832130</td>\n",
       "      <td>0.738826</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>0.963920</td>\n",
       "      <td>0.486978</td>\n",
       "      <td>0.663550</td>\n",
       "      <td>5.798042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.760962</td>\n",
       "      <td>0.489091</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.595462</td>\n",
       "      <td>0.722879</td>\n",
       "      <td>5.049596e+00</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.670925</td>\n",
       "      <td>0.435163</td>\n",
       "      <td>0.940109</td>\n",
       "      <td>0.527917</td>\n",
       "      <td>0.687636</td>\n",
       "      <td>5.890023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84280</td>\n",
       "      <td>0.776718</td>\n",
       "      <td>0.378253</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>0.508750</td>\n",
       "      <td>0.674218</td>\n",
       "      <td>5.429514e+00</td>\n",
       "      <td>0.829012</td>\n",
       "      <td>0.724368</td>\n",
       "      <td>0.355540</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.476970</td>\n",
       "      <td>0.658770</td>\n",
       "      <td>5.905746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.745074</td>\n",
       "      <td>0.535872</td>\n",
       "      <td>0.946525</td>\n",
       "      <td>0.623390</td>\n",
       "      <td>0.741199</td>\n",
       "      <td>5.049602e+00</td>\n",
       "      <td>0.828855</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.457168</td>\n",
       "      <td>0.933025</td>\n",
       "      <td>0.539068</td>\n",
       "      <td>0.695096</td>\n",
       "      <td>5.911174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86220</td>\n",
       "      <td>0.787349</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.741757</td>\n",
       "      <td>4.759469e+00</td>\n",
       "      <td>0.830016</td>\n",
       "      <td>0.663578</td>\n",
       "      <td>0.453984</td>\n",
       "      <td>0.935460</td>\n",
       "      <td>0.539127</td>\n",
       "      <td>0.694722</td>\n",
       "      <td>5.871091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85236</td>\n",
       "      <td>0.772432</td>\n",
       "      <td>0.464315</td>\n",
       "      <td>0.960951</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.712633</td>\n",
       "      <td>5.099329e+00</td>\n",
       "      <td>0.829896</td>\n",
       "      <td>0.690883</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.514012</td>\n",
       "      <td>0.679955</td>\n",
       "      <td>5.875215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84360</td>\n",
       "      <td>0.727715</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>0.957328</td>\n",
       "      <td>0.534524</td>\n",
       "      <td>0.689859</td>\n",
       "      <td>5.401891e+00</td>\n",
       "      <td>0.838167</td>\n",
       "      <td>0.742602</td>\n",
       "      <td>0.401473</td>\n",
       "      <td>0.960892</td>\n",
       "      <td>0.521180</td>\n",
       "      <td>0.681183</td>\n",
       "      <td>5.589523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.84300</td>\n",
       "      <td>0.727931</td>\n",
       "      <td>0.457273</td>\n",
       "      <td>0.951795</td>\n",
       "      <td>0.561697</td>\n",
       "      <td>0.704534</td>\n",
       "      <td>5.422618e+00</td>\n",
       "      <td>0.839228</td>\n",
       "      <td>0.714293</td>\n",
       "      <td>0.443773</td>\n",
       "      <td>0.950193</td>\n",
       "      <td>0.547437</td>\n",
       "      <td>0.696983</td>\n",
       "      <td>5.552891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83620</td>\n",
       "      <td>0.712397</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>0.955657</td>\n",
       "      <td>0.512790</td>\n",
       "      <td>0.678108</td>\n",
       "      <td>5.657479e+00</td>\n",
       "      <td>0.839784</td>\n",
       "      <td>0.730639</td>\n",
       "      <td>0.426674</td>\n",
       "      <td>0.955818</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.691246</td>\n",
       "      <td>5.533707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83840</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>0.452613</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>0.558470</td>\n",
       "      <td>0.701765</td>\n",
       "      <td>5.581497e+00</td>\n",
       "      <td>0.839193</td>\n",
       "      <td>0.722869</td>\n",
       "      <td>0.430434</td>\n",
       "      <td>0.953752</td>\n",
       "      <td>0.539576</td>\n",
       "      <td>0.692093</td>\n",
       "      <td>5.554118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84080</td>\n",
       "      <td>0.744648</td>\n",
       "      <td>0.436380</td>\n",
       "      <td>0.957003</td>\n",
       "      <td>0.550282</td>\n",
       "      <td>0.696692</td>\n",
       "      <td>5.498600e+00</td>\n",
       "      <td>0.837747</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.414193</td>\n",
       "      <td>0.956517</td>\n",
       "      <td>0.527884</td>\n",
       "      <td>0.685355</td>\n",
       "      <td>5.604033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.84040</td>\n",
       "      <td>0.728330</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>0.954540</td>\n",
       "      <td>0.543553</td>\n",
       "      <td>0.694191</td>\n",
       "      <td>5.512417e+00</td>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.423310</td>\n",
       "      <td>0.955434</td>\n",
       "      <td>0.534963</td>\n",
       "      <td>0.689372</td>\n",
       "      <td>5.566854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83660</td>\n",
       "      <td>0.738372</td>\n",
       "      <td>0.358420</td>\n",
       "      <td>0.965710</td>\n",
       "      <td>0.482584</td>\n",
       "      <td>0.662065</td>\n",
       "      <td>5.643658e+00</td>\n",
       "      <td>0.834245</td>\n",
       "      <td>0.767168</td>\n",
       "      <td>0.350944</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>0.481585</td>\n",
       "      <td>0.660506</td>\n",
       "      <td>5.725007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83440</td>\n",
       "      <td>0.634387</td>\n",
       "      <td>0.583636</td>\n",
       "      <td>0.905128</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.744382</td>\n",
       "      <td>5.719681e+00</td>\n",
       "      <td>0.826819</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.566559</td>\n",
       "      <td>0.899848</td>\n",
       "      <td>0.589098</td>\n",
       "      <td>0.733204</td>\n",
       "      <td>5.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.78480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.780713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.77420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.781197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.500244</td>\n",
       "      <td>7.557171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80020</td>\n",
       "      <td>0.903448</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>0.207772</td>\n",
       "      <td>0.556889</td>\n",
       "      <td>6.900850e+00</td>\n",
       "      <td>0.801096</td>\n",
       "      <td>0.867674</td>\n",
       "      <td>0.108286</td>\n",
       "      <td>0.995369</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.551828</td>\n",
       "      <td>6.869890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.80604</td>\n",
       "      <td>0.455242</td>\n",
       "      <td>0.211888</td>\n",
       "      <td>0.973447</td>\n",
       "      <td>0.259662</td>\n",
       "      <td>0.592667</td>\n",
       "      <td>6.699158e+00</td>\n",
       "      <td>0.804814</td>\n",
       "      <td>0.649669</td>\n",
       "      <td>0.205256</td>\n",
       "      <td>0.973057</td>\n",
       "      <td>0.252840</td>\n",
       "      <td>0.589156</td>\n",
       "      <td>6.741496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85660</td>\n",
       "      <td>0.818015</td>\n",
       "      <td>0.418627</td>\n",
       "      <td>0.974854</td>\n",
       "      <td>0.553827</td>\n",
       "      <td>0.696740</td>\n",
       "      <td>4.952876e+00</td>\n",
       "      <td>0.835462</td>\n",
       "      <td>0.761172</td>\n",
       "      <td>0.364282</td>\n",
       "      <td>0.967878</td>\n",
       "      <td>0.492746</td>\n",
       "      <td>0.666080</td>\n",
       "      <td>5.682959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86400</td>\n",
       "      <td>0.835463</td>\n",
       "      <td>0.475455</td>\n",
       "      <td>0.973590</td>\n",
       "      <td>0.606025</td>\n",
       "      <td>0.724522</td>\n",
       "      <td>4.697290e+00</td>\n",
       "      <td>0.837456</td>\n",
       "      <td>0.730827</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>0.957760</td>\n",
       "      <td>0.524245</td>\n",
       "      <td>0.683237</td>\n",
       "      <td>5.614114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83920</td>\n",
       "      <td>0.770916</td>\n",
       "      <td>0.359665</td>\n",
       "      <td>0.970693</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>5.553854e+00</td>\n",
       "      <td>0.836437</td>\n",
       "      <td>0.763305</td>\n",
       "      <td>0.368332</td>\n",
       "      <td>0.967919</td>\n",
       "      <td>0.496890</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>5.649271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84760</td>\n",
       "      <td>0.814751</td>\n",
       "      <td>0.420726</td>\n",
       "      <td>0.972100</td>\n",
       "      <td>0.554907</td>\n",
       "      <td>0.696413</td>\n",
       "      <td>5.263727e+00</td>\n",
       "      <td>0.837584</td>\n",
       "      <td>0.752049</td>\n",
       "      <td>0.385001</td>\n",
       "      <td>0.964425</td>\n",
       "      <td>0.509282</td>\n",
       "      <td>0.674713</td>\n",
       "      <td>5.609684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.457885</td>\n",
       "      <td>0.967817</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.712851</td>\n",
       "      <td>5.042681e+00</td>\n",
       "      <td>0.837213</td>\n",
       "      <td>0.731799</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.958359</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>0.681774</td>\n",
       "      <td>5.622475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85228</td>\n",
       "      <td>0.808521</td>\n",
       "      <td>0.426472</td>\n",
       "      <td>0.971811</td>\n",
       "      <td>0.557717</td>\n",
       "      <td>0.699141</td>\n",
       "      <td>5.102086e+00</td>\n",
       "      <td>0.836830</td>\n",
       "      <td>0.747830</td>\n",
       "      <td>0.386304</td>\n",
       "      <td>0.963268</td>\n",
       "      <td>0.508949</td>\n",
       "      <td>0.674786</td>\n",
       "      <td>5.635701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992894</td>\n",
       "      <td>0.992944</td>\n",
       "      <td>1.036163e-01</td>\n",
       "      <td>0.842881</td>\n",
       "      <td>0.768038</td>\n",
       "      <td>0.406601</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>0.531712</td>\n",
       "      <td>0.686045</td>\n",
       "      <td>5.426736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.844148</td>\n",
       "      <td>0.738563</td>\n",
       "      <td>0.446925</td>\n",
       "      <td>0.955608</td>\n",
       "      <td>0.556871</td>\n",
       "      <td>0.701267</td>\n",
       "      <td>5.382972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.96800</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.852230</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.919759</td>\n",
       "      <td>0.925988</td>\n",
       "      <td>1.105241e+00</td>\n",
       "      <td>0.843963</td>\n",
       "      <td>0.755229</td>\n",
       "      <td>0.426739</td>\n",
       "      <td>0.961152</td>\n",
       "      <td>0.545338</td>\n",
       "      <td>0.693946</td>\n",
       "      <td>5.389362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94320</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.878303</td>\n",
       "      <td>1.961805e+00</td>\n",
       "      <td>0.843144</td>\n",
       "      <td>0.750460</td>\n",
       "      <td>0.424678</td>\n",
       "      <td>0.960424</td>\n",
       "      <td>0.542411</td>\n",
       "      <td>0.692551</td>\n",
       "      <td>5.417641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.844532</td>\n",
       "      <td>0.741476</td>\n",
       "      <td>0.445402</td>\n",
       "      <td>0.956454</td>\n",
       "      <td>0.556510</td>\n",
       "      <td>0.700928</td>\n",
       "      <td>5.369693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.919617</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.954131</td>\n",
       "      <td>0.959447</td>\n",
       "      <td>6.341324e-01</td>\n",
       "      <td>0.843733</td>\n",
       "      <td>0.750753</td>\n",
       "      <td>0.430069</td>\n",
       "      <td>0.959825</td>\n",
       "      <td>0.546568</td>\n",
       "      <td>0.694947</td>\n",
       "      <td>5.397281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0      aus        tree     1         0.84920         0.792060      0.394167   \n",
       "1      aus        tree     2         0.85380         0.760962      0.489091   \n",
       "2      aus        tree     3         0.84280         0.776718      0.378253   \n",
       "3      aus        tree     4         0.85380         0.745074      0.535872   \n",
       "4      aus        tree     5         0.86220         0.787349      0.524194   \n",
       "5      aus        tree   avg         0.85236         0.772432      0.464315   \n",
       "6      aus     log_reg     1         0.84360         0.727715      0.422389   \n",
       "7      aus     log_reg     2         0.84300         0.727931      0.457273   \n",
       "8      aus     log_reg     3         0.83620         0.712397      0.400558   \n",
       "9      aus     log_reg     4         0.83840         0.728959      0.452613   \n",
       "10     aus     log_reg     5         0.84080         0.744648      0.436380   \n",
       "11     aus     log_reg   avg         0.84040         0.728330      0.433843   \n",
       "12     aus  perceptron     1         0.83660         0.738372      0.358420   \n",
       "13     aus  perceptron     2         0.83440         0.634387      0.583636   \n",
       "14     aus  perceptron     3         0.78480         0.000000      0.000000   \n",
       "15     aus  perceptron     4         0.77420         0.000000      0.000000   \n",
       "16     aus  perceptron     5         0.80020         0.903448      0.117384   \n",
       "17     aus  perceptron   avg         0.80604         0.455242      0.211888   \n",
       "18     aus         knn     1         0.85660         0.818015      0.418627   \n",
       "19     aus         knn     2         0.86400         0.835463      0.475455   \n",
       "20     aus         knn     3         0.83920         0.770916      0.359665   \n",
       "21     aus         knn     4         0.84760         0.814751      0.420726   \n",
       "22     aus         knn     5         0.85400         0.803459      0.457885   \n",
       "23     aus         knn   avg         0.85228         0.808521      0.426472   \n",
       "24     aus      forest     1         0.99700         1.000000      0.985889   \n",
       "25     aus      forest     2         1.00000         1.000000      1.000000   \n",
       "26     aus      forest     3         0.96800         0.998911      0.852230   \n",
       "27     aus      forest     4         0.94320         0.985075      0.759965   \n",
       "28     aus      forest     5         1.00000         1.000000      1.000000   \n",
       "29     aus      forest   avg         0.98164         0.996797      0.919617   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.972060  0.526382   0.683114   5.208465e+00       0.832130   \n",
       "1            0.956667  0.595462   0.722879   5.049596e+00       0.829467   \n",
       "2            0.970183  0.508750   0.674218   5.429514e+00       0.829012   \n",
       "3            0.946525  0.623390   0.741199   5.049602e+00       0.828855   \n",
       "4            0.959320  0.629371   0.741757   4.759469e+00       0.830016   \n",
       "5            0.960951  0.576671   0.712633   5.099329e+00       0.829896   \n",
       "6            0.957328  0.534524   0.689859   5.401891e+00       0.838167   \n",
       "7            0.951795  0.561697   0.704534   5.422618e+00       0.839228   \n",
       "8            0.955657  0.512790   0.678108   5.657479e+00       0.839784   \n",
       "9            0.950917  0.558470   0.701765   5.581497e+00       0.839193   \n",
       "10           0.957003  0.550282   0.696692   5.498600e+00       0.837747   \n",
       "11           0.954540  0.543553   0.694191   5.512417e+00       0.838824   \n",
       "12           0.965710  0.482584   0.662065   5.643658e+00       0.834245   \n",
       "13           0.905128  0.607955   0.744382   5.719681e+00       0.826819   \n",
       "14           1.000000  0.000000   0.500000   7.432745e+00       0.780713   \n",
       "15           1.000000  0.000000   0.500000   7.798856e+00       0.781197   \n",
       "16           0.996395  0.207772   0.556889   6.900850e+00       0.801096   \n",
       "17           0.973447  0.259662   0.592667   6.699158e+00       0.804814   \n",
       "18           0.974854  0.553827   0.696740   4.952876e+00       0.835462   \n",
       "19           0.973590  0.606025   0.724522   4.697290e+00       0.837456   \n",
       "20           0.970693  0.490494   0.665179   5.553854e+00       0.836437   \n",
       "21           0.972100  0.554907   0.696413   5.263727e+00       0.837584   \n",
       "22           0.967817  0.583333   0.712851   5.042681e+00       0.837213   \n",
       "23           0.971811  0.557717   0.699141   5.102086e+00       0.836830   \n",
       "24           1.000000  0.992894   0.992944   1.036163e-01       0.842881   \n",
       "25           1.000000  1.000000   1.000000   9.992007e-16       0.844148   \n",
       "26           0.999745  0.919759   0.925988   1.105241e+00       0.843963   \n",
       "27           0.996642  0.858000   0.878303   1.961805e+00       0.843144   \n",
       "28           1.000000  1.000000   1.000000   9.992007e-16       0.844532   \n",
       "29           0.999277  0.954131   0.959447   6.341324e-01       0.843733   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.738826     0.363179          0.963920  0.486978  0.663550   \n",
       "1         0.670925     0.435163          0.940109  0.527917  0.687636   \n",
       "2         0.724368     0.355540          0.962000  0.476970  0.658770   \n",
       "3         0.656716     0.457168          0.933025  0.539068  0.695096   \n",
       "4         0.663578     0.453984          0.935460  0.539127  0.694722   \n",
       "5         0.690883     0.413007          0.946903  0.514012  0.679955   \n",
       "6         0.742602     0.401473          0.960892  0.521180  0.681183   \n",
       "7         0.714293     0.443773          0.950193  0.547437  0.696983   \n",
       "8         0.730639     0.426674          0.955818  0.538739  0.691246   \n",
       "9         0.722869     0.430434          0.953752  0.539576  0.692093   \n",
       "10        0.727600     0.414193          0.956517  0.527884  0.685355   \n",
       "11        0.727600     0.423310          0.955434  0.534963  0.689372   \n",
       "12        0.767168     0.350944          0.970067  0.481585  0.660506   \n",
       "13        0.613504     0.566559          0.899848  0.589098  0.733204   \n",
       "14        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "15        1.000000     0.000488          1.000000  0.000975  0.500244   \n",
       "16        0.867674     0.108286          0.995369  0.192543  0.551828   \n",
       "17        0.649669     0.205256          0.973057  0.252840  0.589156   \n",
       "18        0.761172     0.364282          0.967878  0.492746  0.666080   \n",
       "19        0.730827     0.408714          0.957760  0.524245  0.683237   \n",
       "20        0.763305     0.368332          0.967919  0.496890  0.668125   \n",
       "21        0.752049     0.385001          0.964425  0.509282  0.674713   \n",
       "22        0.731799     0.405188          0.958359  0.521583  0.681774   \n",
       "23        0.747830     0.386304          0.963268  0.508949  0.674786   \n",
       "24        0.768038     0.406601          0.965489  0.531712  0.686045   \n",
       "25        0.738563     0.446925          0.955608  0.556871  0.701267   \n",
       "26        0.755229     0.426739          0.961152  0.545338  0.693946   \n",
       "27        0.750460     0.424678          0.960424  0.542411  0.692551   \n",
       "28        0.741476     0.445402          0.956454  0.556510  0.700928   \n",
       "29        0.750753     0.430069          0.959825  0.546568  0.694947   \n",
       "\n",
       "    test_logloss  \n",
       "0       5.798042  \n",
       "1       5.890023  \n",
       "2       5.905746  \n",
       "3       5.911174  \n",
       "4       5.871091  \n",
       "5       5.875215  \n",
       "6       5.589523  \n",
       "7       5.552891  \n",
       "8       5.533707  \n",
       "9       5.554118  \n",
       "10      5.604033  \n",
       "11      5.566854  \n",
       "12      5.725007  \n",
       "13      5.981522  \n",
       "14      7.573892  \n",
       "15      7.557171  \n",
       "16      6.869890  \n",
       "17      6.741496  \n",
       "18      5.682959  \n",
       "19      5.614114  \n",
       "20      5.649271  \n",
       "21      5.609684  \n",
       "22      5.622475  \n",
       "23      5.635701  \n",
       "24      5.426736  \n",
       "25      5.382972  \n",
       "26      5.389362  \n",
       "27      5.417641  \n",
       "28      5.369693  \n",
       "29      5.397281  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on Australian rain dataset\n",
    "aus_results_no_svm = perform_trials('aus', models_without_svm, aus_X, aus_y)\n",
    "aus_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8552</td>\n",
       "      <td>0.746725</td>\n",
       "      <td>0.482596</td>\n",
       "      <td>0.955804</td>\n",
       "      <td>0.586286</td>\n",
       "      <td>0.719200</td>\n",
       "      <td>5.001243</td>\n",
       "      <td>0.843778</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.450899</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>0.558766</td>\n",
       "      <td>0.702544</td>\n",
       "      <td>5.395760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.613233</td>\n",
       "      <td>0.734860</td>\n",
       "      <td>4.966706</td>\n",
       "      <td>0.843671</td>\n",
       "      <td>0.709647</td>\n",
       "      <td>0.484973</td>\n",
       "      <td>0.944321</td>\n",
       "      <td>0.576182</td>\n",
       "      <td>0.714647</td>\n",
       "      <td>5.399454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.744838</td>\n",
       "      <td>0.469331</td>\n",
       "      <td>0.955912</td>\n",
       "      <td>0.575827</td>\n",
       "      <td>0.712622</td>\n",
       "      <td>5.139398</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>0.721490</td>\n",
       "      <td>0.462160</td>\n",
       "      <td>0.949890</td>\n",
       "      <td>0.563417</td>\n",
       "      <td>0.706025</td>\n",
       "      <td>5.424778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.729763</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>0.943942</td>\n",
       "      <td>0.606625</td>\n",
       "      <td>0.731493</td>\n",
       "      <td>5.249929</td>\n",
       "      <td>0.840823</td>\n",
       "      <td>0.694537</td>\n",
       "      <td>0.487089</td>\n",
       "      <td>0.939961</td>\n",
       "      <td>0.572603</td>\n",
       "      <td>0.713525</td>\n",
       "      <td>5.497816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8544</td>\n",
       "      <td>0.758667</td>\n",
       "      <td>0.509857</td>\n",
       "      <td>0.953399</td>\n",
       "      <td>0.609861</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>5.028875</td>\n",
       "      <td>0.844297</td>\n",
       "      <td>0.715122</td>\n",
       "      <td>0.480414</td>\n",
       "      <td>0.946335</td>\n",
       "      <td>0.574729</td>\n",
       "      <td>0.713374</td>\n",
       "      <td>5.377814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.746196</td>\n",
       "      <td>0.499802</td>\n",
       "      <td>0.952119</td>\n",
       "      <td>0.598366</td>\n",
       "      <td>0.725960</td>\n",
       "      <td>5.077230</td>\n",
       "      <td>0.843101</td>\n",
       "      <td>0.715054</td>\n",
       "      <td>0.473107</td>\n",
       "      <td>0.946939</td>\n",
       "      <td>0.569139</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>5.419124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0     aus   svm     1          0.8552         0.746725      0.482596   \n",
       "1     aus   svm     2          0.8562         0.750988      0.518182   \n",
       "2     aus   svm     3          0.8512         0.744838      0.469331   \n",
       "3     aus   svm     4          0.8480         0.729763      0.519043   \n",
       "4     aus   svm     5          0.8544         0.758667      0.509857   \n",
       "5     aus   svm   avg          0.8530         0.746196      0.499802   \n",
       "\n",
       "   train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0           0.955804  0.586286   0.719200       5.001243       0.843778   \n",
       "1           0.951538  0.613233   0.734860       4.966706       0.843671   \n",
       "2           0.955912  0.575827   0.712622       5.139398       0.842937   \n",
       "3           0.943942  0.606625   0.731493       5.249929       0.840823   \n",
       "4           0.953399  0.609861   0.731628       5.028875       0.844297   \n",
       "5           0.952119  0.598366   0.725960       5.077230       0.843101   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0        0.734472     0.450899          0.954189  0.558766  0.702544   \n",
       "1        0.709647     0.484973          0.944321  0.576182  0.714647   \n",
       "2        0.721490     0.462160          0.949890  0.563417  0.706025   \n",
       "3        0.694537     0.487089          0.939961  0.572603  0.713525   \n",
       "4        0.715122     0.480414          0.946335  0.574729  0.713374   \n",
       "5        0.715054     0.473107          0.946939  0.569139  0.710023   \n",
       "\n",
       "   test_logloss  \n",
       "0      5.395760  \n",
       "1      5.399454  \n",
       "2      5.424778  \n",
       "3      5.497816  \n",
       "4      5.377814  \n",
       "5      5.419124  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running SVM algorithm on Australian rain dataset, generally take longer time to run than other algorithms combined\n",
    "aus_results_svm = perform_trials('aus', models_only_svm, aus_X, aus_y)\n",
    "aus_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results of svm and non-svm algorithms and save as a csv file\n",
    "aus_final_results = aus_results_no_svm.append(aus_results_svm, ignore_index=True)\n",
    "aus_final_results.to_csv('results/aus_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84920</td>\n",
       "      <td>0.792060</td>\n",
       "      <td>0.394167</td>\n",
       "      <td>0.972060</td>\n",
       "      <td>0.526382</td>\n",
       "      <td>0.683114</td>\n",
       "      <td>5.208465e+00</td>\n",
       "      <td>0.832130</td>\n",
       "      <td>0.738826</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>0.963920</td>\n",
       "      <td>0.486978</td>\n",
       "      <td>0.663550</td>\n",
       "      <td>5.798042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.760962</td>\n",
       "      <td>0.489091</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.595462</td>\n",
       "      <td>0.722879</td>\n",
       "      <td>5.049596e+00</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.670925</td>\n",
       "      <td>0.435163</td>\n",
       "      <td>0.940109</td>\n",
       "      <td>0.527917</td>\n",
       "      <td>0.687636</td>\n",
       "      <td>5.890023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84280</td>\n",
       "      <td>0.776718</td>\n",
       "      <td>0.378253</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>0.508750</td>\n",
       "      <td>0.674218</td>\n",
       "      <td>5.429514e+00</td>\n",
       "      <td>0.829012</td>\n",
       "      <td>0.724368</td>\n",
       "      <td>0.355540</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.476970</td>\n",
       "      <td>0.658770</td>\n",
       "      <td>5.905746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.745074</td>\n",
       "      <td>0.535872</td>\n",
       "      <td>0.946525</td>\n",
       "      <td>0.623390</td>\n",
       "      <td>0.741199</td>\n",
       "      <td>5.049602e+00</td>\n",
       "      <td>0.828855</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.457168</td>\n",
       "      <td>0.933025</td>\n",
       "      <td>0.539068</td>\n",
       "      <td>0.695096</td>\n",
       "      <td>5.911174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86220</td>\n",
       "      <td>0.787349</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.741757</td>\n",
       "      <td>4.759469e+00</td>\n",
       "      <td>0.830016</td>\n",
       "      <td>0.663578</td>\n",
       "      <td>0.453984</td>\n",
       "      <td>0.935460</td>\n",
       "      <td>0.539127</td>\n",
       "      <td>0.694722</td>\n",
       "      <td>5.871091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85236</td>\n",
       "      <td>0.772432</td>\n",
       "      <td>0.464315</td>\n",
       "      <td>0.960951</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.712633</td>\n",
       "      <td>5.099329e+00</td>\n",
       "      <td>0.829896</td>\n",
       "      <td>0.690883</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.514012</td>\n",
       "      <td>0.679955</td>\n",
       "      <td>5.875215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84360</td>\n",
       "      <td>0.727715</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>0.957328</td>\n",
       "      <td>0.534524</td>\n",
       "      <td>0.689859</td>\n",
       "      <td>5.401891e+00</td>\n",
       "      <td>0.838167</td>\n",
       "      <td>0.742602</td>\n",
       "      <td>0.401473</td>\n",
       "      <td>0.960892</td>\n",
       "      <td>0.521180</td>\n",
       "      <td>0.681183</td>\n",
       "      <td>5.589523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.84300</td>\n",
       "      <td>0.727931</td>\n",
       "      <td>0.457273</td>\n",
       "      <td>0.951795</td>\n",
       "      <td>0.561697</td>\n",
       "      <td>0.704534</td>\n",
       "      <td>5.422618e+00</td>\n",
       "      <td>0.839228</td>\n",
       "      <td>0.714293</td>\n",
       "      <td>0.443773</td>\n",
       "      <td>0.950193</td>\n",
       "      <td>0.547437</td>\n",
       "      <td>0.696983</td>\n",
       "      <td>5.552891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83620</td>\n",
       "      <td>0.712397</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>0.955657</td>\n",
       "      <td>0.512790</td>\n",
       "      <td>0.678108</td>\n",
       "      <td>5.657479e+00</td>\n",
       "      <td>0.839784</td>\n",
       "      <td>0.730639</td>\n",
       "      <td>0.426674</td>\n",
       "      <td>0.955818</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.691246</td>\n",
       "      <td>5.533707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83840</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>0.452613</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>0.558470</td>\n",
       "      <td>0.701765</td>\n",
       "      <td>5.581497e+00</td>\n",
       "      <td>0.839193</td>\n",
       "      <td>0.722869</td>\n",
       "      <td>0.430434</td>\n",
       "      <td>0.953752</td>\n",
       "      <td>0.539576</td>\n",
       "      <td>0.692093</td>\n",
       "      <td>5.554118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84080</td>\n",
       "      <td>0.744648</td>\n",
       "      <td>0.436380</td>\n",
       "      <td>0.957003</td>\n",
       "      <td>0.550282</td>\n",
       "      <td>0.696692</td>\n",
       "      <td>5.498600e+00</td>\n",
       "      <td>0.837747</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.414193</td>\n",
       "      <td>0.956517</td>\n",
       "      <td>0.527884</td>\n",
       "      <td>0.685355</td>\n",
       "      <td>5.604033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.84040</td>\n",
       "      <td>0.728330</td>\n",
       "      <td>0.433843</td>\n",
       "      <td>0.954540</td>\n",
       "      <td>0.543553</td>\n",
       "      <td>0.694191</td>\n",
       "      <td>5.512417e+00</td>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.423310</td>\n",
       "      <td>0.955434</td>\n",
       "      <td>0.534963</td>\n",
       "      <td>0.689372</td>\n",
       "      <td>5.566854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83660</td>\n",
       "      <td>0.738372</td>\n",
       "      <td>0.358420</td>\n",
       "      <td>0.965710</td>\n",
       "      <td>0.482584</td>\n",
       "      <td>0.662065</td>\n",
       "      <td>5.643658e+00</td>\n",
       "      <td>0.834245</td>\n",
       "      <td>0.767168</td>\n",
       "      <td>0.350944</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>0.481585</td>\n",
       "      <td>0.660506</td>\n",
       "      <td>5.725007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83440</td>\n",
       "      <td>0.634387</td>\n",
       "      <td>0.583636</td>\n",
       "      <td>0.905128</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.744382</td>\n",
       "      <td>5.719681e+00</td>\n",
       "      <td>0.826819</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.566559</td>\n",
       "      <td>0.899848</td>\n",
       "      <td>0.589098</td>\n",
       "      <td>0.733204</td>\n",
       "      <td>5.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.78480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.780713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.77420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.781197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.500244</td>\n",
       "      <td>7.557171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80020</td>\n",
       "      <td>0.903448</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>0.207772</td>\n",
       "      <td>0.556889</td>\n",
       "      <td>6.900850e+00</td>\n",
       "      <td>0.801096</td>\n",
       "      <td>0.867674</td>\n",
       "      <td>0.108286</td>\n",
       "      <td>0.995369</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.551828</td>\n",
       "      <td>6.869890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.80604</td>\n",
       "      <td>0.455242</td>\n",
       "      <td>0.211888</td>\n",
       "      <td>0.973447</td>\n",
       "      <td>0.259662</td>\n",
       "      <td>0.592667</td>\n",
       "      <td>6.699158e+00</td>\n",
       "      <td>0.804814</td>\n",
       "      <td>0.649669</td>\n",
       "      <td>0.205256</td>\n",
       "      <td>0.973057</td>\n",
       "      <td>0.252840</td>\n",
       "      <td>0.589156</td>\n",
       "      <td>6.741496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85660</td>\n",
       "      <td>0.818015</td>\n",
       "      <td>0.418627</td>\n",
       "      <td>0.974854</td>\n",
       "      <td>0.553827</td>\n",
       "      <td>0.696740</td>\n",
       "      <td>4.952876e+00</td>\n",
       "      <td>0.835462</td>\n",
       "      <td>0.761172</td>\n",
       "      <td>0.364282</td>\n",
       "      <td>0.967878</td>\n",
       "      <td>0.492746</td>\n",
       "      <td>0.666080</td>\n",
       "      <td>5.682959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86400</td>\n",
       "      <td>0.835463</td>\n",
       "      <td>0.475455</td>\n",
       "      <td>0.973590</td>\n",
       "      <td>0.606025</td>\n",
       "      <td>0.724522</td>\n",
       "      <td>4.697290e+00</td>\n",
       "      <td>0.837456</td>\n",
       "      <td>0.730827</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>0.957760</td>\n",
       "      <td>0.524245</td>\n",
       "      <td>0.683237</td>\n",
       "      <td>5.614114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83920</td>\n",
       "      <td>0.770916</td>\n",
       "      <td>0.359665</td>\n",
       "      <td>0.970693</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>5.553854e+00</td>\n",
       "      <td>0.836437</td>\n",
       "      <td>0.763305</td>\n",
       "      <td>0.368332</td>\n",
       "      <td>0.967919</td>\n",
       "      <td>0.496890</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>5.649271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84760</td>\n",
       "      <td>0.814751</td>\n",
       "      <td>0.420726</td>\n",
       "      <td>0.972100</td>\n",
       "      <td>0.554907</td>\n",
       "      <td>0.696413</td>\n",
       "      <td>5.263727e+00</td>\n",
       "      <td>0.837584</td>\n",
       "      <td>0.752049</td>\n",
       "      <td>0.385001</td>\n",
       "      <td>0.964425</td>\n",
       "      <td>0.509282</td>\n",
       "      <td>0.674713</td>\n",
       "      <td>5.609684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.457885</td>\n",
       "      <td>0.967817</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.712851</td>\n",
       "      <td>5.042681e+00</td>\n",
       "      <td>0.837213</td>\n",
       "      <td>0.731799</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.958359</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>0.681774</td>\n",
       "      <td>5.622475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85228</td>\n",
       "      <td>0.808521</td>\n",
       "      <td>0.426472</td>\n",
       "      <td>0.971811</td>\n",
       "      <td>0.557717</td>\n",
       "      <td>0.699141</td>\n",
       "      <td>5.102086e+00</td>\n",
       "      <td>0.836830</td>\n",
       "      <td>0.747830</td>\n",
       "      <td>0.386304</td>\n",
       "      <td>0.963268</td>\n",
       "      <td>0.508949</td>\n",
       "      <td>0.674786</td>\n",
       "      <td>5.635701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992894</td>\n",
       "      <td>0.992944</td>\n",
       "      <td>1.036163e-01</td>\n",
       "      <td>0.842881</td>\n",
       "      <td>0.768038</td>\n",
       "      <td>0.406601</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>0.531712</td>\n",
       "      <td>0.686045</td>\n",
       "      <td>5.426736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.844148</td>\n",
       "      <td>0.738563</td>\n",
       "      <td>0.446925</td>\n",
       "      <td>0.955608</td>\n",
       "      <td>0.556871</td>\n",
       "      <td>0.701267</td>\n",
       "      <td>5.382972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.96800</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.852230</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.919759</td>\n",
       "      <td>0.925988</td>\n",
       "      <td>1.105241e+00</td>\n",
       "      <td>0.843963</td>\n",
       "      <td>0.755229</td>\n",
       "      <td>0.426739</td>\n",
       "      <td>0.961152</td>\n",
       "      <td>0.545338</td>\n",
       "      <td>0.693946</td>\n",
       "      <td>5.389362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94320</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.878303</td>\n",
       "      <td>1.961805e+00</td>\n",
       "      <td>0.843144</td>\n",
       "      <td>0.750460</td>\n",
       "      <td>0.424678</td>\n",
       "      <td>0.960424</td>\n",
       "      <td>0.542411</td>\n",
       "      <td>0.692551</td>\n",
       "      <td>5.417641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.844532</td>\n",
       "      <td>0.741476</td>\n",
       "      <td>0.445402</td>\n",
       "      <td>0.956454</td>\n",
       "      <td>0.556510</td>\n",
       "      <td>0.700928</td>\n",
       "      <td>5.369693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.919617</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.954131</td>\n",
       "      <td>0.959447</td>\n",
       "      <td>6.341324e-01</td>\n",
       "      <td>0.843733</td>\n",
       "      <td>0.750753</td>\n",
       "      <td>0.430069</td>\n",
       "      <td>0.959825</td>\n",
       "      <td>0.546568</td>\n",
       "      <td>0.694947</td>\n",
       "      <td>5.397281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85520</td>\n",
       "      <td>0.746725</td>\n",
       "      <td>0.482596</td>\n",
       "      <td>0.955804</td>\n",
       "      <td>0.586286</td>\n",
       "      <td>0.719200</td>\n",
       "      <td>5.001243e+00</td>\n",
       "      <td>0.843778</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.450899</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>0.558766</td>\n",
       "      <td>0.702544</td>\n",
       "      <td>5.395760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85620</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.613233</td>\n",
       "      <td>0.734860</td>\n",
       "      <td>4.966706e+00</td>\n",
       "      <td>0.843671</td>\n",
       "      <td>0.709647</td>\n",
       "      <td>0.484973</td>\n",
       "      <td>0.944321</td>\n",
       "      <td>0.576182</td>\n",
       "      <td>0.714647</td>\n",
       "      <td>5.399454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.85120</td>\n",
       "      <td>0.744838</td>\n",
       "      <td>0.469331</td>\n",
       "      <td>0.955912</td>\n",
       "      <td>0.575827</td>\n",
       "      <td>0.712622</td>\n",
       "      <td>5.139398e+00</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>0.721490</td>\n",
       "      <td>0.462160</td>\n",
       "      <td>0.949890</td>\n",
       "      <td>0.563417</td>\n",
       "      <td>0.706025</td>\n",
       "      <td>5.424778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84800</td>\n",
       "      <td>0.729763</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>0.943942</td>\n",
       "      <td>0.606625</td>\n",
       "      <td>0.731493</td>\n",
       "      <td>5.249929e+00</td>\n",
       "      <td>0.840823</td>\n",
       "      <td>0.694537</td>\n",
       "      <td>0.487089</td>\n",
       "      <td>0.939961</td>\n",
       "      <td>0.572603</td>\n",
       "      <td>0.713525</td>\n",
       "      <td>5.497816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85440</td>\n",
       "      <td>0.758667</td>\n",
       "      <td>0.509857</td>\n",
       "      <td>0.953399</td>\n",
       "      <td>0.609861</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>5.028875e+00</td>\n",
       "      <td>0.844297</td>\n",
       "      <td>0.715122</td>\n",
       "      <td>0.480414</td>\n",
       "      <td>0.946335</td>\n",
       "      <td>0.574729</td>\n",
       "      <td>0.713374</td>\n",
       "      <td>5.377814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.85300</td>\n",
       "      <td>0.746196</td>\n",
       "      <td>0.499802</td>\n",
       "      <td>0.952119</td>\n",
       "      <td>0.598366</td>\n",
       "      <td>0.725960</td>\n",
       "      <td>5.077230e+00</td>\n",
       "      <td>0.843101</td>\n",
       "      <td>0.715054</td>\n",
       "      <td>0.473107</td>\n",
       "      <td>0.946939</td>\n",
       "      <td>0.569139</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>5.419124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0      aus        tree     1         0.84920         0.792060      0.394167   \n",
       "1      aus        tree     2         0.85380         0.760962      0.489091   \n",
       "2      aus        tree     3         0.84280         0.776718      0.378253   \n",
       "3      aus        tree     4         0.85380         0.745074      0.535872   \n",
       "4      aus        tree     5         0.86220         0.787349      0.524194   \n",
       "5      aus        tree   avg         0.85236         0.772432      0.464315   \n",
       "6      aus     log_reg     1         0.84360         0.727715      0.422389   \n",
       "7      aus     log_reg     2         0.84300         0.727931      0.457273   \n",
       "8      aus     log_reg     3         0.83620         0.712397      0.400558   \n",
       "9      aus     log_reg     4         0.83840         0.728959      0.452613   \n",
       "10     aus     log_reg     5         0.84080         0.744648      0.436380   \n",
       "11     aus     log_reg   avg         0.84040         0.728330      0.433843   \n",
       "12     aus  perceptron     1         0.83660         0.738372      0.358420   \n",
       "13     aus  perceptron     2         0.83440         0.634387      0.583636   \n",
       "14     aus  perceptron     3         0.78480         0.000000      0.000000   \n",
       "15     aus  perceptron     4         0.77420         0.000000      0.000000   \n",
       "16     aus  perceptron     5         0.80020         0.903448      0.117384   \n",
       "17     aus  perceptron   avg         0.80604         0.455242      0.211888   \n",
       "18     aus         knn     1         0.85660         0.818015      0.418627   \n",
       "19     aus         knn     2         0.86400         0.835463      0.475455   \n",
       "20     aus         knn     3         0.83920         0.770916      0.359665   \n",
       "21     aus         knn     4         0.84760         0.814751      0.420726   \n",
       "22     aus         knn     5         0.85400         0.803459      0.457885   \n",
       "23     aus         knn   avg         0.85228         0.808521      0.426472   \n",
       "24     aus      forest     1         0.99700         1.000000      0.985889   \n",
       "25     aus      forest     2         1.00000         1.000000      1.000000   \n",
       "26     aus      forest     3         0.96800         0.998911      0.852230   \n",
       "27     aus      forest     4         0.94320         0.985075      0.759965   \n",
       "28     aus      forest     5         1.00000         1.000000      1.000000   \n",
       "29     aus      forest   avg         0.98164         0.996797      0.919617   \n",
       "30     aus         svm     1         0.85520         0.746725      0.482596   \n",
       "31     aus         svm     2         0.85620         0.750988      0.518182   \n",
       "32     aus         svm     3         0.85120         0.744838      0.469331   \n",
       "33     aus         svm     4         0.84800         0.729763      0.519043   \n",
       "34     aus         svm     5         0.85440         0.758667      0.509857   \n",
       "35     aus         svm   avg         0.85300         0.746196      0.499802   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.972060  0.526382   0.683114   5.208465e+00       0.832130   \n",
       "1            0.956667  0.595462   0.722879   5.049596e+00       0.829467   \n",
       "2            0.970183  0.508750   0.674218   5.429514e+00       0.829012   \n",
       "3            0.946525  0.623390   0.741199   5.049602e+00       0.828855   \n",
       "4            0.959320  0.629371   0.741757   4.759469e+00       0.830016   \n",
       "5            0.960951  0.576671   0.712633   5.099329e+00       0.829896   \n",
       "6            0.957328  0.534524   0.689859   5.401891e+00       0.838167   \n",
       "7            0.951795  0.561697   0.704534   5.422618e+00       0.839228   \n",
       "8            0.955657  0.512790   0.678108   5.657479e+00       0.839784   \n",
       "9            0.950917  0.558470   0.701765   5.581497e+00       0.839193   \n",
       "10           0.957003  0.550282   0.696692   5.498600e+00       0.837747   \n",
       "11           0.954540  0.543553   0.694191   5.512417e+00       0.838824   \n",
       "12           0.965710  0.482584   0.662065   5.643658e+00       0.834245   \n",
       "13           0.905128  0.607955   0.744382   5.719681e+00       0.826819   \n",
       "14           1.000000  0.000000   0.500000   7.432745e+00       0.780713   \n",
       "15           1.000000  0.000000   0.500000   7.798856e+00       0.781197   \n",
       "16           0.996395  0.207772   0.556889   6.900850e+00       0.801096   \n",
       "17           0.973447  0.259662   0.592667   6.699158e+00       0.804814   \n",
       "18           0.974854  0.553827   0.696740   4.952876e+00       0.835462   \n",
       "19           0.973590  0.606025   0.724522   4.697290e+00       0.837456   \n",
       "20           0.970693  0.490494   0.665179   5.553854e+00       0.836437   \n",
       "21           0.972100  0.554907   0.696413   5.263727e+00       0.837584   \n",
       "22           0.967817  0.583333   0.712851   5.042681e+00       0.837213   \n",
       "23           0.971811  0.557717   0.699141   5.102086e+00       0.836830   \n",
       "24           1.000000  0.992894   0.992944   1.036163e-01       0.842881   \n",
       "25           1.000000  1.000000   1.000000   9.992007e-16       0.844148   \n",
       "26           0.999745  0.919759   0.925988   1.105241e+00       0.843963   \n",
       "27           0.996642  0.858000   0.878303   1.961805e+00       0.843144   \n",
       "28           1.000000  1.000000   1.000000   9.992007e-16       0.844532   \n",
       "29           0.999277  0.954131   0.959447   6.341324e-01       0.843733   \n",
       "30           0.955804  0.586286   0.719200   5.001243e+00       0.843778   \n",
       "31           0.951538  0.613233   0.734860   4.966706e+00       0.843671   \n",
       "32           0.955912  0.575827   0.712622   5.139398e+00       0.842937   \n",
       "33           0.943942  0.606625   0.731493   5.249929e+00       0.840823   \n",
       "34           0.953399  0.609861   0.731628   5.028875e+00       0.844297   \n",
       "35           0.952119  0.598366   0.725960   5.077230e+00       0.843101   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.738826     0.363179          0.963920  0.486978  0.663550   \n",
       "1         0.670925     0.435163          0.940109  0.527917  0.687636   \n",
       "2         0.724368     0.355540          0.962000  0.476970  0.658770   \n",
       "3         0.656716     0.457168          0.933025  0.539068  0.695096   \n",
       "4         0.663578     0.453984          0.935460  0.539127  0.694722   \n",
       "5         0.690883     0.413007          0.946903  0.514012  0.679955   \n",
       "6         0.742602     0.401473          0.960892  0.521180  0.681183   \n",
       "7         0.714293     0.443773          0.950193  0.547437  0.696983   \n",
       "8         0.730639     0.426674          0.955818  0.538739  0.691246   \n",
       "9         0.722869     0.430434          0.953752  0.539576  0.692093   \n",
       "10        0.727600     0.414193          0.956517  0.527884  0.685355   \n",
       "11        0.727600     0.423310          0.955434  0.534963  0.689372   \n",
       "12        0.767168     0.350944          0.970067  0.481585  0.660506   \n",
       "13        0.613504     0.566559          0.899848  0.589098  0.733204   \n",
       "14        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "15        1.000000     0.000488          1.000000  0.000975  0.500244   \n",
       "16        0.867674     0.108286          0.995369  0.192543  0.551828   \n",
       "17        0.649669     0.205256          0.973057  0.252840  0.589156   \n",
       "18        0.761172     0.364282          0.967878  0.492746  0.666080   \n",
       "19        0.730827     0.408714          0.957760  0.524245  0.683237   \n",
       "20        0.763305     0.368332          0.967919  0.496890  0.668125   \n",
       "21        0.752049     0.385001          0.964425  0.509282  0.674713   \n",
       "22        0.731799     0.405188          0.958359  0.521583  0.681774   \n",
       "23        0.747830     0.386304          0.963268  0.508949  0.674786   \n",
       "24        0.768038     0.406601          0.965489  0.531712  0.686045   \n",
       "25        0.738563     0.446925          0.955608  0.556871  0.701267   \n",
       "26        0.755229     0.426739          0.961152  0.545338  0.693946   \n",
       "27        0.750460     0.424678          0.960424  0.542411  0.692551   \n",
       "28        0.741476     0.445402          0.956454  0.556510  0.700928   \n",
       "29        0.750753     0.430069          0.959825  0.546568  0.694947   \n",
       "30        0.734472     0.450899          0.954189  0.558766  0.702544   \n",
       "31        0.709647     0.484973          0.944321  0.576182  0.714647   \n",
       "32        0.721490     0.462160          0.949890  0.563417  0.706025   \n",
       "33        0.694537     0.487089          0.939961  0.572603  0.713525   \n",
       "34        0.715122     0.480414          0.946335  0.574729  0.713374   \n",
       "35        0.715054     0.473107          0.946939  0.569139  0.710023   \n",
       "\n",
       "    test_logloss  \n",
       "0       5.798042  \n",
       "1       5.890023  \n",
       "2       5.905746  \n",
       "3       5.911174  \n",
       "4       5.871091  \n",
       "5       5.875215  \n",
       "6       5.589523  \n",
       "7       5.552891  \n",
       "8       5.533707  \n",
       "9       5.554118  \n",
       "10      5.604033  \n",
       "11      5.566854  \n",
       "12      5.725007  \n",
       "13      5.981522  \n",
       "14      7.573892  \n",
       "15      7.557171  \n",
       "16      6.869890  \n",
       "17      6.741496  \n",
       "18      5.682959  \n",
       "19      5.614114  \n",
       "20      5.649271  \n",
       "21      5.609684  \n",
       "22      5.622475  \n",
       "23      5.635701  \n",
       "24      5.426736  \n",
       "25      5.382972  \n",
       "26      5.389362  \n",
       "27      5.417641  \n",
       "28      5.369693  \n",
       "29      5.397281  \n",
       "30      5.395760  \n",
       "31      5.399454  \n",
       "32      5.424778  \n",
       "33      5.497816  \n",
       "34      5.377814  \n",
       "35      5.419124  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/aus_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of AirBnB Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1936 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2104 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   13.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 260 | elapsed:    9.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    9.1s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 260 | elapsed:    8.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    8.9s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 260 | elapsed:    8.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    9.1s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    9.8s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 260 | elapsed:    9.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    9.4s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 398 out of 405 | elapsed:   14.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   14.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 398 out of 405 | elapsed:   14.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 398 out of 405 | elapsed:   14.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 398 out of 405 | elapsed:   15.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   56.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987533</td>\n",
       "      <td>0.987687</td>\n",
       "      <td>4.213731e-01</td>\n",
       "      <td>0.988040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987894</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>4.130962e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990426</td>\n",
       "      <td>0.990517</td>\n",
       "      <td>3.246645e-01</td>\n",
       "      <td>0.987721</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.975849</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.987572</td>\n",
       "      <td>0.987719</td>\n",
       "      <td>4.241123e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.98760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>4.282808e-01</td>\n",
       "      <td>0.989065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988957</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>3.776880e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.98840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988154</td>\n",
       "      <td>0.988292</td>\n",
       "      <td>4.006498e-01</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989618</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>3.548693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98560</td>\n",
       "      <td>0.991857</td>\n",
       "      <td>0.979100</td>\n",
       "      <td>0.992038</td>\n",
       "      <td>0.985437</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>4.973616e-01</td>\n",
       "      <td>0.985853</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.977388</td>\n",
       "      <td>0.994308</td>\n",
       "      <td>0.985724</td>\n",
       "      <td>0.985848</td>\n",
       "      <td>4.886361e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.98800</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.977355</td>\n",
       "      <td>0.998408</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>4.144660e-01</td>\n",
       "      <td>0.988081</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.977384</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.987953</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>4.116804e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84940</td>\n",
       "      <td>0.766873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701546</td>\n",
       "      <td>0.868057</td>\n",
       "      <td>0.850773</td>\n",
       "      <td>5.201660e+00</td>\n",
       "      <td>0.851897</td>\n",
       "      <td>0.771470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703813</td>\n",
       "      <td>0.870994</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>5.115430e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.96988</td>\n",
       "      <td>0.953375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940309</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.970155</td>\n",
       "      <td>1.040332e+00</td>\n",
       "      <td>0.970379</td>\n",
       "      <td>0.954294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940763</td>\n",
       "      <td>0.974199</td>\n",
       "      <td>0.970381</td>\n",
       "      <td>1.023086e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>0.998779</td>\n",
       "      <td>0.990311</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.994527</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>1.865099e-01</td>\n",
       "      <td>0.990318</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.997403</td>\n",
       "      <td>0.990248</td>\n",
       "      <td>0.990317</td>\n",
       "      <td>3.344122e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>0.998373</td>\n",
       "      <td>0.990718</td>\n",
       "      <td>0.998414</td>\n",
       "      <td>0.994531</td>\n",
       "      <td>0.994566</td>\n",
       "      <td>1.865100e-01</td>\n",
       "      <td>0.990819</td>\n",
       "      <td>0.995857</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.990771</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>3.171021e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>0.991425</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>0.994674</td>\n",
       "      <td>0.994733</td>\n",
       "      <td>1.796024e-01</td>\n",
       "      <td>0.991092</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.985619</td>\n",
       "      <td>0.996579</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>0.991099</td>\n",
       "      <td>3.076597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.986677</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.992689</td>\n",
       "      <td>0.992744</td>\n",
       "      <td>2.486797e-01</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>0.998566</td>\n",
       "      <td>0.983368</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>3.115931e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.993137</td>\n",
       "      <td>0.993179</td>\n",
       "      <td>2.348646e-01</td>\n",
       "      <td>0.990090</td>\n",
       "      <td>0.997041</td>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.997086</td>\n",
       "      <td>0.990014</td>\n",
       "      <td>0.990086</td>\n",
       "      <td>3.422809e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.998288</td>\n",
       "      <td>0.989576</td>\n",
       "      <td>0.998337</td>\n",
       "      <td>0.993912</td>\n",
       "      <td>0.993956</td>\n",
       "      <td>2.072333e-01</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.984209</td>\n",
       "      <td>0.997111</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>3.226096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.573700e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>3.147400e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   airbnb        tree     1         1.00000         1.000000      1.000000   \n",
       "1   airbnb        tree     2         1.00000         1.000000      1.000000   \n",
       "2   airbnb        tree     3         1.00000         1.000000      1.000000   \n",
       "3   airbnb        tree     4         1.00000         1.000000      1.000000   \n",
       "4   airbnb        tree     5         1.00000         1.000000      1.000000   \n",
       "5   airbnb        tree   avg         1.00000         1.000000      1.000000   \n",
       "6   airbnb     log_reg     1         0.98780         1.000000      0.975373   \n",
       "7   airbnb     log_reg     2         0.99060         1.000000      0.981033   \n",
       "8   airbnb     log_reg     3         0.98760         1.000000      0.974684   \n",
       "9   airbnb     log_reg     4         0.98840         1.000000      0.976585   \n",
       "10  airbnb     log_reg     5         0.98560         0.991857      0.979100   \n",
       "11  airbnb     log_reg   avg         0.98800         0.998371      0.977355   \n",
       "12  airbnb  perceptron     1         1.00000         1.000000      1.000000   \n",
       "13  airbnb  perceptron     2         1.00000         1.000000      1.000000   \n",
       "14  airbnb  perceptron     3         1.00000         1.000000      1.000000   \n",
       "15  airbnb  perceptron     4         0.84940         0.766873      1.000000   \n",
       "16  airbnb  perceptron     5         1.00000         1.000000      1.000000   \n",
       "17  airbnb  perceptron   avg         0.96988         0.953375      1.000000   \n",
       "18  airbnb         knn     1         0.99460         0.998779      0.990311   \n",
       "19  airbnb         knn     2         0.99460         0.998373      0.990718   \n",
       "20  airbnb         knn     3         0.99480         0.997945      0.991425   \n",
       "21  airbnb         knn     4         0.99280         0.998774      0.986677   \n",
       "22  airbnb         knn     5         0.99320         0.997567      0.988746   \n",
       "23  airbnb         knn   avg         0.99400         0.998288      0.989576   \n",
       "24  airbnb      forest     1         1.00000         1.000000      1.000000   \n",
       "25  airbnb      forest     2         1.00000         1.000000      1.000000   \n",
       "26  airbnb      forest     3         1.00000         1.000000      1.000000   \n",
       "27  airbnb      forest     4         1.00000         1.000000      1.000000   \n",
       "28  airbnb      forest     5         1.00000         1.000000      1.000000   \n",
       "29  airbnb      forest   avg         1.00000         1.000000      1.000000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "1            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "2            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "3            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "4            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "5            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "6            1.000000  0.987533   0.987687   4.213731e-01       0.988040   \n",
       "7            1.000000  0.990426   0.990517   3.246645e-01       0.987721   \n",
       "8            1.000000  0.987179   0.987342   4.282808e-01       0.989065   \n",
       "9            1.000000  0.988154   0.988292   4.006498e-01       0.989725   \n",
       "10           0.992038  0.985437   0.985569   4.973616e-01       0.985853   \n",
       "11           0.998408  0.987746   0.987881   4.144660e-01       0.988081   \n",
       "12           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "13           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "14           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "15           0.701546  0.868057   0.850773   5.201660e+00       0.851897   \n",
       "16           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "17           0.940309  0.973611   0.970155   1.040332e+00       0.970379   \n",
       "18           0.998811  0.994527   0.994561   1.865099e-01       0.990318   \n",
       "19           0.998414  0.994531   0.994566   1.865100e-01       0.990819   \n",
       "20           0.998040  0.994674   0.994733   1.796024e-01       0.991092   \n",
       "21           0.998811  0.992689   0.992744   2.486797e-01       0.990978   \n",
       "22           0.997611  0.993137   0.993179   2.348646e-01       0.990090   \n",
       "23           0.998337  0.993912   0.993956   2.072333e-01       0.990660   \n",
       "24           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "25           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "26           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "27           1.000000  1.000000   1.000000   9.992007e-16       0.999954   \n",
       "28           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "29           1.000000  1.000000   1.000000   9.992007e-16       0.999991   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "1         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "2         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "3         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "4         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "5         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "6         1.000000     0.976078          1.000000  0.987894  0.988039   \n",
       "7         0.999580     0.975849          0.999590  0.987572  0.987719   \n",
       "8         1.000000     0.978156          1.000000  0.988957  0.989078   \n",
       "9         1.000000     0.979450          1.000000  0.989618  0.989725   \n",
       "10        0.994203     0.977388          0.994308  0.985724  0.985848   \n",
       "11        0.998757     0.977384          0.998780  0.987953  0.988082   \n",
       "12        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "13        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "14        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "15        0.771470     1.000000          0.703813  0.870994  0.851907   \n",
       "16        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "17        0.954294     1.000000          0.940763  0.974199  0.970381   \n",
       "18        0.997365     0.983232          0.997403  0.990248  0.990317   \n",
       "19        0.995857     0.985737          0.995900  0.990771  0.990818   \n",
       "20        0.996549     0.985619          0.996579  0.991054  0.991099   \n",
       "21        0.998566     0.983368          0.998588  0.990909  0.990978   \n",
       "22        0.997041     0.983086          0.997086  0.990014  0.990086   \n",
       "23        0.997076     0.984209          0.997111  0.990599  0.990660   \n",
       "24        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "25        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "26        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "27        1.000000     0.999909          1.000000  0.999954  0.999954   \n",
       "28        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "29        1.000000     0.999982          1.000000  0.999991  0.999991   \n",
       "\n",
       "    test_logloss  \n",
       "0   9.992007e-16  \n",
       "1   9.992007e-16  \n",
       "2   9.992007e-16  \n",
       "3   9.992007e-16  \n",
       "4   9.992007e-16  \n",
       "5   9.992007e-16  \n",
       "6   4.130962e-01  \n",
       "7   4.241123e-01  \n",
       "8   3.776880e-01  \n",
       "9   3.548693e-01  \n",
       "10  4.886361e-01  \n",
       "11  4.116804e-01  \n",
       "12  9.992007e-16  \n",
       "13  9.992007e-16  \n",
       "14  9.992007e-16  \n",
       "15  5.115430e+00  \n",
       "16  9.992007e-16  \n",
       "17  1.023086e+00  \n",
       "18  3.344122e-01  \n",
       "19  3.171021e-01  \n",
       "20  3.076597e-01  \n",
       "21  3.115931e-01  \n",
       "22  3.422809e-01  \n",
       "23  3.226096e-01  \n",
       "24  9.992007e-16  \n",
       "25  9.992007e-16  \n",
       "26  9.992007e-16  \n",
       "27  1.573700e-03  \n",
       "28  9.992007e-16  \n",
       "29  3.147400e-04  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on airbnb dataset\n",
    "airbnb_results_no_svm = perform_trials('airbnb', models_without_svm, airbnb_X, airbnb_y)\n",
    "airbnb_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   27.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   25.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   26.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.010229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.998777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.999412</td>\n",
       "      <td>2.072375e-02</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998540</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>0.999270</td>\n",
       "      <td>0.025180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.004721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.001574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>4.144749e-03</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.009757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  airbnb   svm     1         1.00000         1.000000           1.0   \n",
       "1  airbnb   svm     2         1.00000         1.000000           1.0   \n",
       "2  airbnb   svm     3         0.99940         0.998777           1.0   \n",
       "3  airbnb   svm     4         1.00000         1.000000           1.0   \n",
       "4  airbnb   svm     5         1.00000         1.000000           1.0   \n",
       "5  airbnb   svm   avg         0.99988         0.999755           1.0   \n",
       "\n",
       "   train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0           1.000000  1.000000   1.000000   9.992007e-16       0.999795   \n",
       "1           1.000000  1.000000   1.000000   9.992007e-16       0.999704   \n",
       "2           0.998824  0.999388   0.999412   2.072375e-02       0.999271   \n",
       "3           1.000000  1.000000   1.000000   9.992007e-16       0.999863   \n",
       "4           1.000000  1.000000   1.000000   9.992007e-16       0.999954   \n",
       "5           0.999765  0.999878   0.999882   4.144749e-03       0.999718   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0        0.999727     0.999863          0.999727  0.999795  0.999795   \n",
       "1        0.999408     1.000000          0.999408  0.999704  0.999704   \n",
       "2        0.998546     1.000000          0.998540  0.999272  0.999270   \n",
       "3        0.999863     0.999863          0.999863  0.999863  0.999863   \n",
       "4        1.000000     0.999909          1.000000  0.999954  0.999954   \n",
       "5        0.999509     0.999927          0.999508  0.999718  0.999717   \n",
       "\n",
       "   test_logloss  \n",
       "0      0.007082  \n",
       "1      0.010229  \n",
       "2      0.025180  \n",
       "3      0.004721  \n",
       "4      0.001574  \n",
       "5      0.009757  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_results_svm = perform_trials('airbnb', models_only_svm, airbnb_X, airbnb_y)\n",
    "airbnb_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_final_results = airbnb_results_no_svm.append(airbnb_results_svm, ignore_index=True)\n",
    "airbnb_final_results.to_csv('results/airbnb_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987533</td>\n",
       "      <td>0.987687</td>\n",
       "      <td>4.213731e-01</td>\n",
       "      <td>0.988040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987894</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>4.130962e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990426</td>\n",
       "      <td>0.990517</td>\n",
       "      <td>3.246645e-01</td>\n",
       "      <td>0.987721</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.975849</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.987572</td>\n",
       "      <td>0.987719</td>\n",
       "      <td>4.241123e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.98760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>4.282808e-01</td>\n",
       "      <td>0.989065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988957</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>3.776880e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.98840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988154</td>\n",
       "      <td>0.988292</td>\n",
       "      <td>4.006498e-01</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989618</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>3.548693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98560</td>\n",
       "      <td>0.991857</td>\n",
       "      <td>0.979100</td>\n",
       "      <td>0.992038</td>\n",
       "      <td>0.985437</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>4.973616e-01</td>\n",
       "      <td>0.985853</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.977388</td>\n",
       "      <td>0.994308</td>\n",
       "      <td>0.985724</td>\n",
       "      <td>0.985848</td>\n",
       "      <td>4.886361e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.98800</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.977355</td>\n",
       "      <td>0.998408</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>4.144660e-01</td>\n",
       "      <td>0.988081</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.977384</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.987953</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>4.116804e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84940</td>\n",
       "      <td>0.766873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701546</td>\n",
       "      <td>0.868057</td>\n",
       "      <td>0.850773</td>\n",
       "      <td>5.201660e+00</td>\n",
       "      <td>0.851897</td>\n",
       "      <td>0.771470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703813</td>\n",
       "      <td>0.870994</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>5.115430e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.96988</td>\n",
       "      <td>0.953375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940309</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.970155</td>\n",
       "      <td>1.040332e+00</td>\n",
       "      <td>0.970379</td>\n",
       "      <td>0.954294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940763</td>\n",
       "      <td>0.974199</td>\n",
       "      <td>0.970381</td>\n",
       "      <td>1.023086e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>0.998779</td>\n",
       "      <td>0.990311</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.994527</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>1.865099e-01</td>\n",
       "      <td>0.990318</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.997403</td>\n",
       "      <td>0.990248</td>\n",
       "      <td>0.990317</td>\n",
       "      <td>3.344122e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>0.998373</td>\n",
       "      <td>0.990718</td>\n",
       "      <td>0.998414</td>\n",
       "      <td>0.994531</td>\n",
       "      <td>0.994566</td>\n",
       "      <td>1.865100e-01</td>\n",
       "      <td>0.990819</td>\n",
       "      <td>0.995857</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.990771</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>3.171021e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>0.991425</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>0.994674</td>\n",
       "      <td>0.994733</td>\n",
       "      <td>1.796024e-01</td>\n",
       "      <td>0.991092</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.985619</td>\n",
       "      <td>0.996579</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>0.991099</td>\n",
       "      <td>3.076597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.986677</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.992689</td>\n",
       "      <td>0.992744</td>\n",
       "      <td>2.486797e-01</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>0.998566</td>\n",
       "      <td>0.983368</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>3.115931e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.993137</td>\n",
       "      <td>0.993179</td>\n",
       "      <td>2.348646e-01</td>\n",
       "      <td>0.990090</td>\n",
       "      <td>0.997041</td>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.997086</td>\n",
       "      <td>0.990014</td>\n",
       "      <td>0.990086</td>\n",
       "      <td>3.422809e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.998288</td>\n",
       "      <td>0.989576</td>\n",
       "      <td>0.998337</td>\n",
       "      <td>0.993912</td>\n",
       "      <td>0.993956</td>\n",
       "      <td>2.072333e-01</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.984209</td>\n",
       "      <td>0.997111</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>3.226096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.573700e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>3.147400e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>7.081758e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>1.022929e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.998777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.999412</td>\n",
       "      <td>2.072375e-02</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998540</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>0.999270</td>\n",
       "      <td>2.517978e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>4.721154e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.573700e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>4.144749e-03</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>9.757136e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   airbnb        tree     1         1.00000         1.000000      1.000000   \n",
       "1   airbnb        tree     2         1.00000         1.000000      1.000000   \n",
       "2   airbnb        tree     3         1.00000         1.000000      1.000000   \n",
       "3   airbnb        tree     4         1.00000         1.000000      1.000000   \n",
       "4   airbnb        tree     5         1.00000         1.000000      1.000000   \n",
       "5   airbnb        tree   avg         1.00000         1.000000      1.000000   \n",
       "6   airbnb     log_reg     1         0.98780         1.000000      0.975373   \n",
       "7   airbnb     log_reg     2         0.99060         1.000000      0.981033   \n",
       "8   airbnb     log_reg     3         0.98760         1.000000      0.974684   \n",
       "9   airbnb     log_reg     4         0.98840         1.000000      0.976585   \n",
       "10  airbnb     log_reg     5         0.98560         0.991857      0.979100   \n",
       "11  airbnb     log_reg   avg         0.98800         0.998371      0.977355   \n",
       "12  airbnb  perceptron     1         1.00000         1.000000      1.000000   \n",
       "13  airbnb  perceptron     2         1.00000         1.000000      1.000000   \n",
       "14  airbnb  perceptron     3         1.00000         1.000000      1.000000   \n",
       "15  airbnb  perceptron     4         0.84940         0.766873      1.000000   \n",
       "16  airbnb  perceptron     5         1.00000         1.000000      1.000000   \n",
       "17  airbnb  perceptron   avg         0.96988         0.953375      1.000000   \n",
       "18  airbnb         knn     1         0.99460         0.998779      0.990311   \n",
       "19  airbnb         knn     2         0.99460         0.998373      0.990718   \n",
       "20  airbnb         knn     3         0.99480         0.997945      0.991425   \n",
       "21  airbnb         knn     4         0.99280         0.998774      0.986677   \n",
       "22  airbnb         knn     5         0.99320         0.997567      0.988746   \n",
       "23  airbnb         knn   avg         0.99400         0.998288      0.989576   \n",
       "24  airbnb      forest     1         1.00000         1.000000      1.000000   \n",
       "25  airbnb      forest     2         1.00000         1.000000      1.000000   \n",
       "26  airbnb      forest     3         1.00000         1.000000      1.000000   \n",
       "27  airbnb      forest     4         1.00000         1.000000      1.000000   \n",
       "28  airbnb      forest     5         1.00000         1.000000      1.000000   \n",
       "29  airbnb      forest   avg         1.00000         1.000000      1.000000   \n",
       "30  airbnb         svm     1         1.00000         1.000000      1.000000   \n",
       "31  airbnb         svm     2         1.00000         1.000000      1.000000   \n",
       "32  airbnb         svm     3         0.99940         0.998777      1.000000   \n",
       "33  airbnb         svm     4         1.00000         1.000000      1.000000   \n",
       "34  airbnb         svm     5         1.00000         1.000000      1.000000   \n",
       "35  airbnb         svm   avg         0.99988         0.999755      1.000000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "1            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "2            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "3            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "4            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "5            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "6            1.000000  0.987533   0.987687   4.213731e-01       0.988040   \n",
       "7            1.000000  0.990426   0.990517   3.246645e-01       0.987721   \n",
       "8            1.000000  0.987179   0.987342   4.282808e-01       0.989065   \n",
       "9            1.000000  0.988154   0.988292   4.006498e-01       0.989725   \n",
       "10           0.992038  0.985437   0.985569   4.973616e-01       0.985853   \n",
       "11           0.998408  0.987746   0.987881   4.144660e-01       0.988081   \n",
       "12           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "13           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "14           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "15           0.701546  0.868057   0.850773   5.201660e+00       0.851897   \n",
       "16           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "17           0.940309  0.973611   0.970155   1.040332e+00       0.970379   \n",
       "18           0.998811  0.994527   0.994561   1.865099e-01       0.990318   \n",
       "19           0.998414  0.994531   0.994566   1.865100e-01       0.990819   \n",
       "20           0.998040  0.994674   0.994733   1.796024e-01       0.991092   \n",
       "21           0.998811  0.992689   0.992744   2.486797e-01       0.990978   \n",
       "22           0.997611  0.993137   0.993179   2.348646e-01       0.990090   \n",
       "23           0.998337  0.993912   0.993956   2.072333e-01       0.990660   \n",
       "24           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "25           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "26           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "27           1.000000  1.000000   1.000000   9.992007e-16       0.999954   \n",
       "28           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "29           1.000000  1.000000   1.000000   9.992007e-16       0.999991   \n",
       "30           1.000000  1.000000   1.000000   9.992007e-16       0.999795   \n",
       "31           1.000000  1.000000   1.000000   9.992007e-16       0.999704   \n",
       "32           0.998824  0.999388   0.999412   2.072375e-02       0.999271   \n",
       "33           1.000000  1.000000   1.000000   9.992007e-16       0.999863   \n",
       "34           1.000000  1.000000   1.000000   9.992007e-16       0.999954   \n",
       "35           0.999765  0.999878   0.999882   4.144749e-03       0.999718   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "1         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "2         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "3         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "4         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "5         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "6         1.000000     0.976078          1.000000  0.987894  0.988039   \n",
       "7         0.999580     0.975849          0.999590  0.987572  0.987719   \n",
       "8         1.000000     0.978156          1.000000  0.988957  0.989078   \n",
       "9         1.000000     0.979450          1.000000  0.989618  0.989725   \n",
       "10        0.994203     0.977388          0.994308  0.985724  0.985848   \n",
       "11        0.998757     0.977384          0.998780  0.987953  0.988082   \n",
       "12        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "13        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "14        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "15        0.771470     1.000000          0.703813  0.870994  0.851907   \n",
       "16        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "17        0.954294     1.000000          0.940763  0.974199  0.970381   \n",
       "18        0.997365     0.983232          0.997403  0.990248  0.990317   \n",
       "19        0.995857     0.985737          0.995900  0.990771  0.990818   \n",
       "20        0.996549     0.985619          0.996579  0.991054  0.991099   \n",
       "21        0.998566     0.983368          0.998588  0.990909  0.990978   \n",
       "22        0.997041     0.983086          0.997086  0.990014  0.990086   \n",
       "23        0.997076     0.984209          0.997111  0.990599  0.990660   \n",
       "24        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "25        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "26        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "27        1.000000     0.999909          1.000000  0.999954  0.999954   \n",
       "28        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "29        1.000000     0.999982          1.000000  0.999991  0.999991   \n",
       "30        0.999727     0.999863          0.999727  0.999795  0.999795   \n",
       "31        0.999408     1.000000          0.999408  0.999704  0.999704   \n",
       "32        0.998546     1.000000          0.998540  0.999272  0.999270   \n",
       "33        0.999863     0.999863          0.999863  0.999863  0.999863   \n",
       "34        1.000000     0.999909          1.000000  0.999954  0.999954   \n",
       "35        0.999509     0.999927          0.999508  0.999718  0.999717   \n",
       "\n",
       "    test_logloss  \n",
       "0   9.992007e-16  \n",
       "1   9.992007e-16  \n",
       "2   9.992007e-16  \n",
       "3   9.992007e-16  \n",
       "4   9.992007e-16  \n",
       "5   9.992007e-16  \n",
       "6   4.130962e-01  \n",
       "7   4.241123e-01  \n",
       "8   3.776880e-01  \n",
       "9   3.548693e-01  \n",
       "10  4.886361e-01  \n",
       "11  4.116804e-01  \n",
       "12  9.992007e-16  \n",
       "13  9.992007e-16  \n",
       "14  9.992007e-16  \n",
       "15  5.115430e+00  \n",
       "16  9.992007e-16  \n",
       "17  1.023086e+00  \n",
       "18  3.344122e-01  \n",
       "19  3.171021e-01  \n",
       "20  3.076597e-01  \n",
       "21  3.115931e-01  \n",
       "22  3.422809e-01  \n",
       "23  3.226096e-01  \n",
       "24  9.992007e-16  \n",
       "25  9.992007e-16  \n",
       "26  9.992007e-16  \n",
       "27  1.573700e-03  \n",
       "28  9.992007e-16  \n",
       "29  3.147400e-04  \n",
       "30  7.081758e-03  \n",
       "31  1.022929e-02  \n",
       "32  2.517978e-02  \n",
       "33  4.721154e-03  \n",
       "34  1.573700e-03  \n",
       "35  9.757136e-03  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/airbnb_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Olympic Gold Medal Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1892 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2180 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95220</td>\n",
       "      <td>0.954655</td>\n",
       "      <td>0.997053</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>0.546719</td>\n",
       "      <td>1.650989</td>\n",
       "      <td>0.949827</td>\n",
       "      <td>0.953788</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>0.069974</td>\n",
       "      <td>0.974177</td>\n",
       "      <td>0.532715</td>\n",
       "      <td>1.732942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95680</td>\n",
       "      <td>0.958232</td>\n",
       "      <td>0.998108</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.977764</td>\n",
       "      <td>0.571368</td>\n",
       "      <td>1.492108</td>\n",
       "      <td>0.950081</td>\n",
       "      <td>0.954340</td>\n",
       "      <td>0.995100</td>\n",
       "      <td>0.082620</td>\n",
       "      <td>0.974294</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>1.724185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95400</td>\n",
       "      <td>0.954911</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.551368</td>\n",
       "      <td>1.588820</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.953734</td>\n",
       "      <td>0.996816</td>\n",
       "      <td>0.067460</td>\n",
       "      <td>0.974799</td>\n",
       "      <td>0.532138</td>\n",
       "      <td>1.692422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.952678</td>\n",
       "      <td>0.996839</td>\n",
       "      <td>0.074803</td>\n",
       "      <td>0.974259</td>\n",
       "      <td>0.535821</td>\n",
       "      <td>1.726976</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.952527</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.042469</td>\n",
       "      <td>0.973699</td>\n",
       "      <td>0.519151</td>\n",
       "      <td>1.766595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96040</td>\n",
       "      <td>0.961701</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.979671</td>\n",
       "      <td>0.569299</td>\n",
       "      <td>1.367766</td>\n",
       "      <td>0.950568</td>\n",
       "      <td>0.953834</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.072994</td>\n",
       "      <td>0.974563</td>\n",
       "      <td>0.534604</td>\n",
       "      <td>1.707359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95468</td>\n",
       "      <td>0.956436</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0.112018</td>\n",
       "      <td>0.976684</td>\n",
       "      <td>0.554915</td>\n",
       "      <td>1.565332</td>\n",
       "      <td>0.950066</td>\n",
       "      <td>0.953645</td>\n",
       "      <td>0.995884</td>\n",
       "      <td>0.067103</td>\n",
       "      <td>0.974306</td>\n",
       "      <td>0.531494</td>\n",
       "      <td>1.724701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.726979</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>0.951360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.680005</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.703894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.818745</td>\n",
       "      <td>0.049303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.835918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.92880</td>\n",
       "      <td>0.955694</td>\n",
       "      <td>0.970156</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.962870</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>2.459195</td>\n",
       "      <td>0.927110</td>\n",
       "      <td>0.954348</td>\n",
       "      <td>0.969713</td>\n",
       "      <td>0.106196</td>\n",
       "      <td>0.961970</td>\n",
       "      <td>0.537955</td>\n",
       "      <td>2.517581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.811838</td>\n",
       "      <td>0.049298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.836089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950712</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974733</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>1.702383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.58672</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.594031</td>\n",
       "      <td>0.423140</td>\n",
       "      <td>0.582842</td>\n",
       "      <td>0.508586</td>\n",
       "      <td>14.274208</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.571126</td>\n",
       "      <td>0.593941</td>\n",
       "      <td>0.421239</td>\n",
       "      <td>0.582271</td>\n",
       "      <td>0.507590</td>\n",
       "      <td>14.319935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95180</td>\n",
       "      <td>0.951790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.975300</td>\n",
       "      <td>0.502066</td>\n",
       "      <td>1.664808</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.950657</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.499943</td>\n",
       "      <td>1.710968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95180</td>\n",
       "      <td>0.951894</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.975254</td>\n",
       "      <td>0.519895</td>\n",
       "      <td>1.664807</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.997757</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.973748</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>1.766596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950518</td>\n",
       "      <td>0.950556</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974631</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>1.709079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95176</td>\n",
       "      <td>0.951777</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.975271</td>\n",
       "      <td>0.504392</td>\n",
       "      <td>1.666189</td>\n",
       "      <td>0.950251</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.974489</td>\n",
       "      <td>0.500335</td>\n",
       "      <td>1.718316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.959604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196787</td>\n",
       "      <td>0.979386</td>\n",
       "      <td>0.598394</td>\n",
       "      <td>1.381583</td>\n",
       "      <td>0.951115</td>\n",
       "      <td>0.952174</td>\n",
       "      <td>0.998745</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>0.974904</td>\n",
       "      <td>0.515706</td>\n",
       "      <td>1.688475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95940</td>\n",
       "      <td>0.959081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.979113</td>\n",
       "      <td>0.580579</td>\n",
       "      <td>1.402307</td>\n",
       "      <td>0.951696</td>\n",
       "      <td>0.952394</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.037683</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.518407</td>\n",
       "      <td>1.668386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.97060</td>\n",
       "      <td>0.969982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>1.015464</td>\n",
       "      <td>0.951353</td>\n",
       "      <td>0.952849</td>\n",
       "      <td>0.998227</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.975010</td>\n",
       "      <td>0.522810</td>\n",
       "      <td>1.680233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988189</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.994094</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.949226</td>\n",
       "      <td>0.953053</td>\n",
       "      <td>0.995639</td>\n",
       "      <td>0.053768</td>\n",
       "      <td>0.973881</td>\n",
       "      <td>0.524704</td>\n",
       "      <td>1.753717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96180</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.980404</td>\n",
       "      <td>0.570031</td>\n",
       "      <td>1.319412</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.951803</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>0.975112</td>\n",
       "      <td>0.513219</td>\n",
       "      <td>1.675255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.97024</td>\n",
       "      <td>0.969958</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.379681</td>\n",
       "      <td>0.984670</td>\n",
       "      <td>0.689820</td>\n",
       "      <td>1.027898</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>0.952454</td>\n",
       "      <td>0.998267</td>\n",
       "      <td>0.039671</td>\n",
       "      <td>0.974822</td>\n",
       "      <td>0.518969</td>\n",
       "      <td>1.693213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   olympic        tree     1         0.95220         0.954655      0.997053   \n",
       "1   olympic        tree     2         0.95680         0.958232      0.998108   \n",
       "2   olympic        tree     3         0.95400         0.954911      0.998737   \n",
       "3   olympic        tree     4         0.95000         0.952678      0.996839   \n",
       "4   olympic        tree     5         0.96040         0.961701      0.998326   \n",
       "5   olympic        tree   avg         0.95468         0.956436      0.997813   \n",
       "6   olympic     log_reg     1         0.95020         0.950200      1.000000   \n",
       "7   olympic     log_reg     2         0.95160         0.951600      1.000000   \n",
       "8   olympic     log_reg     3         0.95000         0.950000      1.000000   \n",
       "9   olympic     log_reg     4         0.94920         0.949200      1.000000   \n",
       "10  olympic     log_reg     5         0.95580         0.955800      1.000000   \n",
       "11  olympic     log_reg   avg         0.95136         0.951360      1.000000   \n",
       "12  olympic  perceptron     1         0.04980         0.000000      0.000000   \n",
       "13  olympic  perceptron     2         0.92880         0.955694      0.970156   \n",
       "14  olympic  perceptron     3         0.05000         0.000000      0.000000   \n",
       "15  olympic  perceptron     4         0.94920         0.949200      1.000000   \n",
       "16  olympic  perceptron     5         0.95580         0.955800      1.000000   \n",
       "17  olympic  perceptron   avg         0.58672         0.572139      0.594031   \n",
       "18  olympic         knn     1         0.95020         0.950200      1.000000   \n",
       "19  olympic         knn     2         0.95180         0.951790      1.000000   \n",
       "20  olympic         knn     3         0.95180         0.951894      0.999789   \n",
       "21  olympic         knn     4         0.94920         0.949200      1.000000   \n",
       "22  olympic         knn     5         0.95580         0.955800      1.000000   \n",
       "23  olympic         knn   avg         0.95176         0.951777      0.999958   \n",
       "24  olympic      forest     1         0.96000         0.959604      1.000000   \n",
       "25  olympic      forest     2         0.95940         0.959081      1.000000   \n",
       "26  olympic      forest     3         0.97060         0.969982      1.000000   \n",
       "27  olympic      forest     4         0.99940         0.999368      1.000000   \n",
       "28  olympic      forest     5         0.96180         0.961755      0.999791   \n",
       "29  olympic      forest   avg         0.97024         0.969958      0.999958   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.096386  0.975394   0.546719       1.650989       0.949827   \n",
       "1            0.144628  0.977764   0.571368       1.492108       0.950081   \n",
       "2            0.104000  0.976333   0.551368       1.588820       0.951000   \n",
       "3            0.074803  0.974259   0.535821       1.726976       0.948853   \n",
       "4            0.140271  0.979671   0.569299       1.367766       0.950568   \n",
       "5            0.112018  0.976684   0.554915       1.565332       0.950066   \n",
       "6            0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "7            0.000000  0.975200   0.500000       1.671715       0.950662   \n",
       "8            0.000000  0.974359   0.500000       1.726979       0.950702   \n",
       "9            0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "10           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "11           0.000000  0.975072   0.500000       1.680005       0.950668   \n",
       "12           1.000000  0.000000   0.500000      32.818745       0.049303   \n",
       "13           0.115702  0.962870   0.542929       2.459195       0.927110   \n",
       "14           1.000000  0.000000   0.500000      32.811838       0.049298   \n",
       "15           0.000000  0.973938   0.500000       1.754610       0.950712   \n",
       "16           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "17           0.423140  0.582842   0.508586      14.274208       0.585396   \n",
       "18           0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "19           0.004132  0.975300   0.502066       1.664808       0.950464   \n",
       "20           0.040000  0.975254   0.519895       1.664807       0.948853   \n",
       "21           0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "22           0.000000  0.977401   0.500000       1.526649       0.950518   \n",
       "23           0.008826  0.975271   0.504392       1.666189       0.950251   \n",
       "24           0.196787  0.979386   0.598394       1.381583       0.951115   \n",
       "25           0.161157  0.979113   0.580579       1.402307       0.951696   \n",
       "26           0.412000  0.984762   0.706000       1.015464       0.951353   \n",
       "27           0.988189  0.999684   0.994094       0.020724       0.949226   \n",
       "28           0.140271  0.980404   0.570031       1.319412       0.951498   \n",
       "29           0.379681  0.984670   0.689820       1.027898       0.950978   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.953788     0.995456          0.069974  0.974177  0.532715   \n",
       "1         0.954340     0.995100          0.082620  0.974294  0.538860   \n",
       "2         0.953734     0.996816          0.067460  0.974799  0.532138   \n",
       "3         0.952527     0.995833          0.042469  0.973699  0.519151   \n",
       "4         0.953834     0.996214          0.072994  0.974563  0.534604   \n",
       "5         0.953645     0.995884          0.067103  0.974306  0.531494   \n",
       "6         0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "7         0.950662     1.000000          0.000000  0.974707  0.500000   \n",
       "8         0.950702     1.000000          0.000000  0.974728  0.500000   \n",
       "9         0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "10        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "11        0.950668     1.000000          0.000000  0.974710  0.500000   \n",
       "12        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "13        0.954348     0.969713          0.106196  0.961970  0.537955   \n",
       "14        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "15        0.950722     0.999990          0.000000  0.974733  0.499995   \n",
       "16        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "17        0.571126     0.593941          0.421239  0.582271  0.507590   \n",
       "18        0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "19        0.950657     0.999786          0.000101  0.974603  0.499943   \n",
       "20        0.950867     0.997757          0.005748  0.973748  0.501752   \n",
       "21        0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "22        0.950556     0.999958          0.000000  0.974631  0.499979   \n",
       "23        0.950700     0.999500          0.001170  0.974489  0.500335   \n",
       "24        0.952174     0.998745          0.032668  0.974904  0.515706   \n",
       "25        0.952394     0.999132          0.037683  0.975203  0.518407   \n",
       "26        0.952849     0.998227          0.047393  0.975010  0.522810   \n",
       "27        0.953053     0.995639          0.053768  0.973881  0.524704   \n",
       "28        0.951803     0.999592          0.026845  0.975112  0.513219   \n",
       "29        0.952454     0.998267          0.039671  0.974822  0.518969   \n",
       "\n",
       "    test_logloss  \n",
       "0       1.732942  \n",
       "1       1.724185  \n",
       "2       1.692422  \n",
       "3       1.766595  \n",
       "4       1.707359  \n",
       "5       1.724701  \n",
       "6       1.702898  \n",
       "7       1.704100  \n",
       "8       1.702726  \n",
       "9       1.702040  \n",
       "10      1.707706  \n",
       "11      1.703894  \n",
       "12     32.835918  \n",
       "13      2.517581  \n",
       "14     32.836089  \n",
       "15      1.702383  \n",
       "16      1.707706  \n",
       "17     14.319935  \n",
       "18      1.702898  \n",
       "19      1.710968  \n",
       "20      1.766596  \n",
       "21      1.702040  \n",
       "22      1.709079  \n",
       "23      1.718316  \n",
       "24      1.688475  \n",
       "25      1.668386  \n",
       "26      1.680233  \n",
       "27      1.753717  \n",
       "28      1.675255  \n",
       "29      1.693213  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on Olympic dataset\n",
    "olympic_results_no_svm = perform_trials('olympic', models_without_svm, olympic_X, olympic_y)\n",
    "olympic_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   17.4s\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.726979</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.702726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.680005</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.703894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  olympic   svm     1         0.95020          0.95020           1.0   \n",
       "1  olympic   svm     2         0.95160          0.95160           1.0   \n",
       "2  olympic   svm     3         0.95000          0.95000           1.0   \n",
       "3  olympic   svm     4         0.94920          0.94920           1.0   \n",
       "4  olympic   svm     5         0.95580          0.95580           1.0   \n",
       "5  olympic   svm   avg         0.95136          0.95136           1.0   \n",
       "\n",
       "   train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0                0.0  0.974464        0.5       1.720071       0.950697   \n",
       "1                0.0  0.975200        0.5       1.671715       0.950662   \n",
       "2                0.0  0.974359        0.5       1.726979       0.950702   \n",
       "3                0.0  0.973938        0.5       1.754610       0.950722   \n",
       "4                0.0  0.977401        0.5       1.526649       0.950558   \n",
       "5                0.0  0.975072        0.5       1.680005       0.950668   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0        0.950697          1.0               0.0  0.974726       0.5   \n",
       "1        0.950662          1.0               0.0  0.974707       0.5   \n",
       "2        0.950702          1.0               0.0  0.974728       0.5   \n",
       "3        0.950722          1.0               0.0  0.974739       0.5   \n",
       "4        0.950558          1.0               0.0  0.974652       0.5   \n",
       "5        0.950668          1.0               0.0  0.974710       0.5   \n",
       "\n",
       "   test_logloss  \n",
       "0      1.702898  \n",
       "1      1.704100  \n",
       "2      1.702726  \n",
       "3      1.702040  \n",
       "4      1.707706  \n",
       "5      1.703894  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympic_results_svm = perform_trials('olympic', models_only_svm, olympic_X, olympic_y)\n",
    "olympic_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_final_results = olympic_results_no_svm.append(olympic_results_svm, ignore_index=True)\n",
    "olympic_final_results.to_csv('results/olympic_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95220</td>\n",
       "      <td>0.954655</td>\n",
       "      <td>0.997053</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>0.546719</td>\n",
       "      <td>1.650989</td>\n",
       "      <td>0.949827</td>\n",
       "      <td>0.953788</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>0.069974</td>\n",
       "      <td>0.974177</td>\n",
       "      <td>0.532715</td>\n",
       "      <td>1.732942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95680</td>\n",
       "      <td>0.958232</td>\n",
       "      <td>0.998108</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.977764</td>\n",
       "      <td>0.571368</td>\n",
       "      <td>1.492108</td>\n",
       "      <td>0.950081</td>\n",
       "      <td>0.954340</td>\n",
       "      <td>0.995100</td>\n",
       "      <td>0.082620</td>\n",
       "      <td>0.974294</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>1.724185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95400</td>\n",
       "      <td>0.954911</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.551368</td>\n",
       "      <td>1.588820</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.953734</td>\n",
       "      <td>0.996816</td>\n",
       "      <td>0.067460</td>\n",
       "      <td>0.974799</td>\n",
       "      <td>0.532138</td>\n",
       "      <td>1.692422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.952678</td>\n",
       "      <td>0.996839</td>\n",
       "      <td>0.074803</td>\n",
       "      <td>0.974259</td>\n",
       "      <td>0.535821</td>\n",
       "      <td>1.726976</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.952527</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.042469</td>\n",
       "      <td>0.973699</td>\n",
       "      <td>0.519151</td>\n",
       "      <td>1.766595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96040</td>\n",
       "      <td>0.961701</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.979671</td>\n",
       "      <td>0.569299</td>\n",
       "      <td>1.367766</td>\n",
       "      <td>0.950568</td>\n",
       "      <td>0.953834</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.072994</td>\n",
       "      <td>0.974563</td>\n",
       "      <td>0.534604</td>\n",
       "      <td>1.707359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95468</td>\n",
       "      <td>0.956436</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0.112018</td>\n",
       "      <td>0.976684</td>\n",
       "      <td>0.554915</td>\n",
       "      <td>1.565332</td>\n",
       "      <td>0.950066</td>\n",
       "      <td>0.953645</td>\n",
       "      <td>0.995884</td>\n",
       "      <td>0.067103</td>\n",
       "      <td>0.974306</td>\n",
       "      <td>0.531494</td>\n",
       "      <td>1.724701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.726979</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>0.951360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.680005</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.703894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.818745</td>\n",
       "      <td>0.049303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.835918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.92880</td>\n",
       "      <td>0.955694</td>\n",
       "      <td>0.970156</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.962870</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>2.459195</td>\n",
       "      <td>0.927110</td>\n",
       "      <td>0.954348</td>\n",
       "      <td>0.969713</td>\n",
       "      <td>0.106196</td>\n",
       "      <td>0.961970</td>\n",
       "      <td>0.537955</td>\n",
       "      <td>2.517581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.811838</td>\n",
       "      <td>0.049298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.836089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950712</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974733</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>1.702383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.58672</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.594031</td>\n",
       "      <td>0.423140</td>\n",
       "      <td>0.582842</td>\n",
       "      <td>0.508586</td>\n",
       "      <td>14.274208</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.571126</td>\n",
       "      <td>0.593941</td>\n",
       "      <td>0.421239</td>\n",
       "      <td>0.582271</td>\n",
       "      <td>0.507590</td>\n",
       "      <td>14.319935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95180</td>\n",
       "      <td>0.951790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.975300</td>\n",
       "      <td>0.502066</td>\n",
       "      <td>1.664808</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.950657</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.499943</td>\n",
       "      <td>1.710968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95180</td>\n",
       "      <td>0.951894</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.975254</td>\n",
       "      <td>0.519895</td>\n",
       "      <td>1.664807</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.997757</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.973748</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>1.766596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950518</td>\n",
       "      <td>0.950556</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974631</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>1.709079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95176</td>\n",
       "      <td>0.951777</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.975271</td>\n",
       "      <td>0.504392</td>\n",
       "      <td>1.666189</td>\n",
       "      <td>0.950251</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.974489</td>\n",
       "      <td>0.500335</td>\n",
       "      <td>1.718316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.959604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196787</td>\n",
       "      <td>0.979386</td>\n",
       "      <td>0.598394</td>\n",
       "      <td>1.381583</td>\n",
       "      <td>0.951115</td>\n",
       "      <td>0.952174</td>\n",
       "      <td>0.998745</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>0.974904</td>\n",
       "      <td>0.515706</td>\n",
       "      <td>1.688475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95940</td>\n",
       "      <td>0.959081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.979113</td>\n",
       "      <td>0.580579</td>\n",
       "      <td>1.402307</td>\n",
       "      <td>0.951696</td>\n",
       "      <td>0.952394</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.037683</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.518407</td>\n",
       "      <td>1.668386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.97060</td>\n",
       "      <td>0.969982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>1.015464</td>\n",
       "      <td>0.951353</td>\n",
       "      <td>0.952849</td>\n",
       "      <td>0.998227</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.975010</td>\n",
       "      <td>0.522810</td>\n",
       "      <td>1.680233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988189</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.994094</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.949226</td>\n",
       "      <td>0.953053</td>\n",
       "      <td>0.995639</td>\n",
       "      <td>0.053768</td>\n",
       "      <td>0.973881</td>\n",
       "      <td>0.524704</td>\n",
       "      <td>1.753717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96180</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.980404</td>\n",
       "      <td>0.570031</td>\n",
       "      <td>1.319412</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.951803</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>0.975112</td>\n",
       "      <td>0.513219</td>\n",
       "      <td>1.675255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.97024</td>\n",
       "      <td>0.969958</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.379681</td>\n",
       "      <td>0.984670</td>\n",
       "      <td>0.689820</td>\n",
       "      <td>1.027898</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>0.952454</td>\n",
       "      <td>0.998267</td>\n",
       "      <td>0.039671</td>\n",
       "      <td>0.974822</td>\n",
       "      <td>0.518969</td>\n",
       "      <td>1.693213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.726979</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>0.951360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.680005</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.703894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   olympic        tree     1         0.95220         0.954655      0.997053   \n",
       "1   olympic        tree     2         0.95680         0.958232      0.998108   \n",
       "2   olympic        tree     3         0.95400         0.954911      0.998737   \n",
       "3   olympic        tree     4         0.95000         0.952678      0.996839   \n",
       "4   olympic        tree     5         0.96040         0.961701      0.998326   \n",
       "5   olympic        tree   avg         0.95468         0.956436      0.997813   \n",
       "6   olympic     log_reg     1         0.95020         0.950200      1.000000   \n",
       "7   olympic     log_reg     2         0.95160         0.951600      1.000000   \n",
       "8   olympic     log_reg     3         0.95000         0.950000      1.000000   \n",
       "9   olympic     log_reg     4         0.94920         0.949200      1.000000   \n",
       "10  olympic     log_reg     5         0.95580         0.955800      1.000000   \n",
       "11  olympic     log_reg   avg         0.95136         0.951360      1.000000   \n",
       "12  olympic  perceptron     1         0.04980         0.000000      0.000000   \n",
       "13  olympic  perceptron     2         0.92880         0.955694      0.970156   \n",
       "14  olympic  perceptron     3         0.05000         0.000000      0.000000   \n",
       "15  olympic  perceptron     4         0.94920         0.949200      1.000000   \n",
       "16  olympic  perceptron     5         0.95580         0.955800      1.000000   \n",
       "17  olympic  perceptron   avg         0.58672         0.572139      0.594031   \n",
       "18  olympic         knn     1         0.95020         0.950200      1.000000   \n",
       "19  olympic         knn     2         0.95180         0.951790      1.000000   \n",
       "20  olympic         knn     3         0.95180         0.951894      0.999789   \n",
       "21  olympic         knn     4         0.94920         0.949200      1.000000   \n",
       "22  olympic         knn     5         0.95580         0.955800      1.000000   \n",
       "23  olympic         knn   avg         0.95176         0.951777      0.999958   \n",
       "24  olympic      forest     1         0.96000         0.959604      1.000000   \n",
       "25  olympic      forest     2         0.95940         0.959081      1.000000   \n",
       "26  olympic      forest     3         0.97060         0.969982      1.000000   \n",
       "27  olympic      forest     4         0.99940         0.999368      1.000000   \n",
       "28  olympic      forest     5         0.96180         0.961755      0.999791   \n",
       "29  olympic      forest   avg         0.97024         0.969958      0.999958   \n",
       "30  olympic         svm     1         0.95020         0.950200      1.000000   \n",
       "31  olympic         svm     2         0.95160         0.951600      1.000000   \n",
       "32  olympic         svm     3         0.95000         0.950000      1.000000   \n",
       "33  olympic         svm     4         0.94920         0.949200      1.000000   \n",
       "34  olympic         svm     5         0.95580         0.955800      1.000000   \n",
       "35  olympic         svm   avg         0.95136         0.951360      1.000000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.096386  0.975394   0.546719       1.650989       0.949827   \n",
       "1            0.144628  0.977764   0.571368       1.492108       0.950081   \n",
       "2            0.104000  0.976333   0.551368       1.588820       0.951000   \n",
       "3            0.074803  0.974259   0.535821       1.726976       0.948853   \n",
       "4            0.140271  0.979671   0.569299       1.367766       0.950568   \n",
       "5            0.112018  0.976684   0.554915       1.565332       0.950066   \n",
       "6            0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "7            0.000000  0.975200   0.500000       1.671715       0.950662   \n",
       "8            0.000000  0.974359   0.500000       1.726979       0.950702   \n",
       "9            0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "10           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "11           0.000000  0.975072   0.500000       1.680005       0.950668   \n",
       "12           1.000000  0.000000   0.500000      32.818745       0.049303   \n",
       "13           0.115702  0.962870   0.542929       2.459195       0.927110   \n",
       "14           1.000000  0.000000   0.500000      32.811838       0.049298   \n",
       "15           0.000000  0.973938   0.500000       1.754610       0.950712   \n",
       "16           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "17           0.423140  0.582842   0.508586      14.274208       0.585396   \n",
       "18           0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "19           0.004132  0.975300   0.502066       1.664808       0.950464   \n",
       "20           0.040000  0.975254   0.519895       1.664807       0.948853   \n",
       "21           0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "22           0.000000  0.977401   0.500000       1.526649       0.950518   \n",
       "23           0.008826  0.975271   0.504392       1.666189       0.950251   \n",
       "24           0.196787  0.979386   0.598394       1.381583       0.951115   \n",
       "25           0.161157  0.979113   0.580579       1.402307       0.951696   \n",
       "26           0.412000  0.984762   0.706000       1.015464       0.951353   \n",
       "27           0.988189  0.999684   0.994094       0.020724       0.949226   \n",
       "28           0.140271  0.980404   0.570031       1.319412       0.951498   \n",
       "29           0.379681  0.984670   0.689820       1.027898       0.950978   \n",
       "30           0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "31           0.000000  0.975200   0.500000       1.671715       0.950662   \n",
       "32           0.000000  0.974359   0.500000       1.726979       0.950702   \n",
       "33           0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "34           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "35           0.000000  0.975072   0.500000       1.680005       0.950668   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.953788     0.995456          0.069974  0.974177  0.532715   \n",
       "1         0.954340     0.995100          0.082620  0.974294  0.538860   \n",
       "2         0.953734     0.996816          0.067460  0.974799  0.532138   \n",
       "3         0.952527     0.995833          0.042469  0.973699  0.519151   \n",
       "4         0.953834     0.996214          0.072994  0.974563  0.534604   \n",
       "5         0.953645     0.995884          0.067103  0.974306  0.531494   \n",
       "6         0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "7         0.950662     1.000000          0.000000  0.974707  0.500000   \n",
       "8         0.950702     1.000000          0.000000  0.974728  0.500000   \n",
       "9         0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "10        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "11        0.950668     1.000000          0.000000  0.974710  0.500000   \n",
       "12        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "13        0.954348     0.969713          0.106196  0.961970  0.537955   \n",
       "14        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "15        0.950722     0.999990          0.000000  0.974733  0.499995   \n",
       "16        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "17        0.571126     0.593941          0.421239  0.582271  0.507590   \n",
       "18        0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "19        0.950657     0.999786          0.000101  0.974603  0.499943   \n",
       "20        0.950867     0.997757          0.005748  0.973748  0.501752   \n",
       "21        0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "22        0.950556     0.999958          0.000000  0.974631  0.499979   \n",
       "23        0.950700     0.999500          0.001170  0.974489  0.500335   \n",
       "24        0.952174     0.998745          0.032668  0.974904  0.515706   \n",
       "25        0.952394     0.999132          0.037683  0.975203  0.518407   \n",
       "26        0.952849     0.998227          0.047393  0.975010  0.522810   \n",
       "27        0.953053     0.995639          0.053768  0.973881  0.524704   \n",
       "28        0.951803     0.999592          0.026845  0.975112  0.513219   \n",
       "29        0.952454     0.998267          0.039671  0.974822  0.518969   \n",
       "30        0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "31        0.950662     1.000000          0.000000  0.974707  0.500000   \n",
       "32        0.950702     1.000000          0.000000  0.974728  0.500000   \n",
       "33        0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "34        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "35        0.950668     1.000000          0.000000  0.974710  0.500000   \n",
       "\n",
       "    test_logloss  \n",
       "0       1.732942  \n",
       "1       1.724185  \n",
       "2       1.692422  \n",
       "3       1.766595  \n",
       "4       1.707359  \n",
       "5       1.724701  \n",
       "6       1.702898  \n",
       "7       1.704100  \n",
       "8       1.702726  \n",
       "9       1.702040  \n",
       "10      1.707706  \n",
       "11      1.703894  \n",
       "12     32.835918  \n",
       "13      2.517581  \n",
       "14     32.836089  \n",
       "15      1.702383  \n",
       "16      1.707706  \n",
       "17     14.319935  \n",
       "18      1.702898  \n",
       "19      1.710968  \n",
       "20      1.766596  \n",
       "21      1.702040  \n",
       "22      1.709079  \n",
       "23      1.718316  \n",
       "24      1.688475  \n",
       "25      1.668386  \n",
       "26      1.680233  \n",
       "27      1.753717  \n",
       "28      1.675255  \n",
       "29      1.693213  \n",
       "30      1.702898  \n",
       "31      1.704100  \n",
       "32      1.702726  \n",
       "33      1.702040  \n",
       "34      1.707706  \n",
       "35      1.703894  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/olympic_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
