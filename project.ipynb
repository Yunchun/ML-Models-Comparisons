{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Chess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_id</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_id</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>moves</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TZJHLljE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>15+2</td>\n",
       "      <td>bourgris</td>\n",
       "      <td>1500</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1191</td>\n",
       "      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n",
       "      <td>D10</td>\n",
       "      <td>Slav Defense: Exchange Variation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1NXvwaE</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+10</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1322</td>\n",
       "      <td>skinnerua</td>\n",
       "      <td>1261</td>\n",
       "      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n",
       "      <td>B00</td>\n",
       "      <td>Nimzowitsch Defense: Kennedy Variation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mIICvQHh</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>5+10</td>\n",
       "      <td>ischia</td>\n",
       "      <td>1496</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1500</td>\n",
       "      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n",
       "      <td>C20</td>\n",
       "      <td>King's Pawn Game: Leonardis Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kWKvrqYL</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>20+0</td>\n",
       "      <td>daniamurashov</td>\n",
       "      <td>1439</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1454</td>\n",
       "      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n",
       "      <td>D02</td>\n",
       "      <td>Queen's Pawn Game: Zukertort Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9tXo1AUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>30+3</td>\n",
       "      <td>nik221107</td>\n",
       "      <td>1523</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1469</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
       "0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n",
       "1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n",
       "2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n",
       "3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n",
       "4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n",
       "\n",
       "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
       "0           15+2       bourgris          1500          a-00          1191   \n",
       "1           5+10           a-00          1322     skinnerua          1261   \n",
       "2           5+10         ischia          1496          a-00          1500   \n",
       "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
       "4           30+3      nik221107          1523  adivanov2009          1469   \n",
       "\n",
       "                                               moves opening_eco  \\\n",
       "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
       "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
       "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
       "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
       "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
       "\n",
       "                             opening_name  opening_ply  \n",
       "0        Slav Defense: Exchange Variation            5  \n",
       "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
       "2   King's Pawn Game: Leonardis Variation            3  \n",
       "3  Queen's Pawn Game: Zukertort Variation            3  \n",
       "4                        Philidor Defense            5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasnaek/chess\n",
    "chess_df = pd.read_csv('Data/games.csv')\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_ply</th>\n",
       "      <th>winner_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.722528</td>\n",
       "      <td>0.722501</td>\n",
       "      <td>-1.413916</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>-0.331779</td>\n",
       "      <td>-1.366951</td>\n",
       "      <td>D10</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.719721</td>\n",
       "      <td>0.719694</td>\n",
       "      <td>-1.324552</td>\n",
       "      <td>resign</td>\n",
       "      <td>-0.942931</td>\n",
       "      <td>-1.126431</td>\n",
       "      <td>B00</td>\n",
       "      <td>-0.292076</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.719721</td>\n",
       "      <td>0.719694</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>mate</td>\n",
       "      <td>-0.345513</td>\n",
       "      <td>-0.305227</td>\n",
       "      <td>C20</td>\n",
       "      <td>-0.649582</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.719020</td>\n",
       "      <td>0.718992</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>mate</td>\n",
       "      <td>-0.541219</td>\n",
       "      <td>-0.463283</td>\n",
       "      <td>D02</td>\n",
       "      <td>-0.649582</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.716213</td>\n",
       "      <td>0.716185</td>\n",
       "      <td>1.028698</td>\n",
       "      <td>mate</td>\n",
       "      <td>-0.252810</td>\n",
       "      <td>-0.411743</td>\n",
       "      <td>C41</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated  created_at  last_move_at     turns victory_status  white_rating  \\\n",
       "0  False    0.722528      0.722501 -1.413916      outoftime     -0.331779   \n",
       "1   True    0.719721      0.719694 -1.324552         resign     -0.942931   \n",
       "2   True    0.719721      0.719694  0.015907           mate     -0.345513   \n",
       "3   True    0.719020      0.718992  0.015907           mate     -0.541219   \n",
       "4   True    0.716213      0.716185  1.028698           mate     -0.252810   \n",
       "\n",
       "   black_rating opening_eco  opening_ply  winner_white  \n",
       "0     -1.366951         D10     0.065431          True  \n",
       "1     -1.126431         B00    -0.292076         False  \n",
       "2     -0.305227         C20    -0.649582          True  \n",
       "3     -0.463283         D02    -0.649582          True  \n",
       "4     -0.411743         C41     0.065431          True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_num_cols = ['created_at', 'last_move_at', 'turns', 'white_rating', 'black_rating', 'opening_ply']\n",
    "for num_col in chess_num_cols:\n",
    "    chess_df[num_col] = (chess_df[num_col] - chess_df[num_col].mean()) /chess_df[num_col].std()\n",
    "\n",
    "chess_df['winner_white'] = chess_df['winner'] == 'white'\n",
    "chess_df = chess_df[['rated', 'created_at', 'last_move_at', 'turns', 'victory_status',\n",
    "                     'white_rating', 'black_rating', 'opening_eco', 'opening_ply', 'winner_white']]\n",
    "\n",
    "# max_openings = 30\n",
    "# popular_opennings = chess_df['opening_eco'].value_counts()[:max_openings].index.tolist()\n",
    "# def replace_opening(x):\n",
    "#     if (x in popular_opennings):\n",
    "#         return x\n",
    "#     else:\n",
    "#         return 'other'\n",
    "\n",
    "# chess_df['opening_eco'] = chess_df['opening_eco'].apply(replace_opening)\n",
    "\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_df_X = chess_df.drop(columns=['winner_white'])\n",
    "chess_df_y = chess_df['winner_white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_X_cat_col = ['rated', 'victory_status', 'opening_eco']\n",
    "chess_X = pd.get_dummies(columns=chess_X_cat_col, data=chess_df_X)\n",
    "\n",
    "chess_y = chess_df_y.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10057\n",
       "1    10001\n",
       "Name: winner_white, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Mushrooms Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class: edible(e), poisonous(p)\n",
    "\n",
    "cap-shape: bell(b), conical(c), convex(x), flat(f), knobbed(k), sunken(s)\n",
    "\n",
    "cap-surface: fibrous(f), grooves(g), scaly(y), smooth(s)\n",
    "\n",
    "cap-color: brown(n), buff(b), cinnamon(c), gray(g), green(r), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "bruises: bruises(t), no(f)\n",
    "\n",
    "odor: almond(a), anise(l), creosote(c), fishy(y), foul(f), musty(m), none(n), pungent(p), spicy(s)\n",
    "\n",
    "gill-attachment: attached(a), descending(d), free(f), notched(n)\n",
    "\n",
    "gill-spacing: close(c), crowded(w), distant(d)\n",
    "\n",
    "gill-size: broad(b), narrow(n)\n",
    "\n",
    "gill-color: black(k), brown(n), buff(b), chocolate(h), gray(g), green(r), orange(o), pink(p), purple(u), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-shape: enlarging(e), tapering(t)\n",
    "\n",
    "stalk-root: bulbous(b), club(c), cup(u), equal(e), rhizomorphs(z), rooted(r), missing(?)\n",
    "\n",
    "stalk-surface-above-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-surface-below-ring: fibrous(f), scaly(y), silky(k), smooth(s)\n",
    "\n",
    "stalk-color-above-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "stalk-color-below-ring: brown(n), buff(b), cinnamon(c), gray(g), orange(o), pink(p), red(e), white(w), yellow(y)\n",
    "\n",
    "veil-type: partial(p), universal(u)\n",
    "\n",
    "veil-color: brown(n), orange(o), white(w), yellow(y)\n",
    "\n",
    "ring-number: none(n), one(o), two(t)\n",
    "\n",
    "ring-type: cobwebby(c), evanescent(e), flaring(f), large(l), none(n), pendant(p), sheathing(s), zone(z)\n",
    "\n",
    "spore-print-color: black(k), brown(n), buff(b), chocolate(h), green(r), orange(o), purple(u), white(w), yellow(y)\n",
    "\n",
    "population: abundant(a), clustered(c), numerous(n), scattered(s), several(v), solitary(y)\n",
    "\n",
    "habitat: grasses(g), leaves(l), meadows(m), paths(p), urban(u), waste(w), woods(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/uciml/mushroom-classification\n",
    "shrooms = pd.read_csv('Data/mushrooms.csv')\n",
    "shrooms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_df_X = shrooms.drop(columns=['class'])\n",
    "shrooms_df_y = shrooms['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_X = pd.get_dummies(data=shrooms_df_X)\n",
    "shrooms_y = shrooms_df_y.replace({'e': 0, 'p': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4208\n",
       "1    3916\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrooms_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Cardio Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieved from the kaggle site https://www.kaggle.com/sulianova/cardiovascular-disease-dataset, this cardio dataset has 70000 samples and 12 variables, which were collected at the moment of medical examination. It contains a target variable that indicates the presence or absence of cardiovascular disease, as well as 11 features that might be associated with the presence of cardiovascular disease, such as age, gender, and blood pressure. There are 3 types of 11 input features:\n",
    "- objective feature: factual information\n",
    "- examination feature: results of medical examination\n",
    "- subjective feature: information given by the patient\n",
    "\n",
    "A more detailed description of 11 features are shown below:\n",
    "\n",
    "- age: objective feature, int (days)\n",
    "- height: objective feature, int (cm)\n",
    "- weight: objective feature, float (kg)\n",
    "- gender: objective feature, categorical code, 1: male, 2:female\n",
    "- ap_hi: systolic blood pressure, examination feature, int\n",
    "- ap_lo: diastolic blood pressure, examination feature, int\n",
    "- cholesterol: examination feature, categorical code, 1: normal, 2: above normal, 3: well above normal\n",
    "- gluc: glucose, examination feature, categorical code, 1: normal, 2: above normal, 3: well above normal\n",
    "- smoke: subjective feature, binary, 0: do not smoke, 1: smoke\n",
    "- alco: alcohol intake, subjective feature, binary, 0: do not drink alcohol, 1: drink alcohol\n",
    "- active: physical activity, subjective feature, binary, 0: not physically active, 1: physically active\n",
    "\n",
    "A detailed description of the target variable is shown below: \n",
    "\n",
    "- cardio: presence or absence of cardiovascular disease, binary, 0: disease not present, 1: disease present\n",
    "\n",
    "For this dataset, we want use those 11 input features and apply machine learning algorithms to predict whether a person has cardiovascular disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the cardio dataset\n",
    "cardio = pd.read_csv('data/cardio.csv', delimiter = ';')\n",
    "cardio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "age            0\n",
       "gender         0\n",
       "height         0\n",
       "weight         0\n",
       "ap_hi          0\n",
       "ap_lo          0\n",
       "cholesterol    0\n",
       "gluc           0\n",
       "smoke          0\n",
       "alco           0\n",
       "active         0\n",
       "cardio         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing values in cardio dataset\n",
    "cardio.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary column \"id\"\n",
    "cardio = cardio.drop(columns = ['id'])\n",
    "# convert age in days to age in years\n",
    "cardio['age'] = cardio['age'].apply(lambda x: int(x/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding categorical input features stored in cate_cols\n",
    "cardio_cate_cols = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "cardio = pd.get_dummies(columns = cardio_cate_cols, data = cardio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numerical attributes to 0 mean 1 std\n",
    "cardio_num_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "for num_col in cardio_num_cols:\n",
    "    cardio[num_col] = (cardio[num_col] - cardio[num_col].mean()) / cardio[num_col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cardio</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>cholesterol_1</th>\n",
       "      <th>cholesterol_2</th>\n",
       "      <th>cholesterol_3</th>\n",
       "      <th>gluc_1</th>\n",
       "      <th>gluc_2</th>\n",
       "      <th>gluc_3</th>\n",
       "      <th>smoke_0</th>\n",
       "      <th>smoke_1</th>\n",
       "      <th>alco_0</th>\n",
       "      <th>alco_1</th>\n",
       "      <th>active_0</th>\n",
       "      <th>active_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419797</td>\n",
       "      <td>0.443449</td>\n",
       "      <td>-0.847867</td>\n",
       "      <td>-0.122181</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319108</td>\n",
       "      <td>-1.018161</td>\n",
       "      <td>0.749826</td>\n",
       "      <td>0.072610</td>\n",
       "      <td>-0.035180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.272016</td>\n",
       "      <td>0.078046</td>\n",
       "      <td>-0.708937</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>-0.141296</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.715359</td>\n",
       "      <td>0.565250</td>\n",
       "      <td>0.541431</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.863140</td>\n",
       "      <td>-1.018161</td>\n",
       "      <td>-1.264657</td>\n",
       "      <td>-0.187111</td>\n",
       "      <td>-0.194354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    height    weight     ap_hi     ap_lo  cardio  gender_1  \\\n",
       "0 -0.419797  0.443449 -0.847867 -0.122181 -0.088238       0         0   \n",
       "1  0.319108 -1.018161  0.749826  0.072610 -0.035180       1         1   \n",
       "2 -0.272016  0.078046 -0.708937  0.007679 -0.141296       1         1   \n",
       "3 -0.715359  0.565250  0.541431  0.137540  0.017878       1         0   \n",
       "4 -0.863140 -1.018161 -1.264657 -0.187111 -0.194354       0         1   \n",
       "\n",
       "   gender_2  cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  \\\n",
       "0         1              1              0              0       1       0   \n",
       "1         0              0              0              1       1       0   \n",
       "2         0              0              0              1       1       0   \n",
       "3         1              1              0              0       1       0   \n",
       "4         0              1              0              0       1       0   \n",
       "\n",
       "   gluc_3  smoke_0  smoke_1  alco_0  alco_1  active_0  active_1  \n",
       "0       0        1        0       1       0         0         1  \n",
       "1       0        1        0       1       0         0         1  \n",
       "2       0        1        0       1       0         1         0  \n",
       "3       0        1        0       1       0         0         1  \n",
       "4       0        1        0       1       0         1         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look at cleaned dataset\n",
    "cardio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5003\n",
       "1    0.4997\n",
       "Name: cardio, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50.03% negative labels, 49.97% positive labels\n",
    "cardio['cardio'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the cardio dataset into input features and labels \n",
    "cardio_X = cardio.drop(columns=['cardio']) # input features\n",
    "cardio_y = cardio['cardio'] # true lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Rain Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieved from the kaggle site https://www.kaggle.com/jsphyg/weather-dataset-rattle-package, this Rain in Australia dataset contains about 10 years of daily weather observations from many locations across Australia. There are 145460 samples and 23 variables in this dataset. It contains a target variable that indicates whether it rained the next day, as well as 22 features that might be associated with the target variable, such as minimum temperature, maximum temperature, rainfall of the day.\n",
    "\n",
    "A more detailed description of 22 features are shown below:\n",
    "\n",
    "- Date: the date of observation\n",
    "- Location: the common name of the location of the weather station\n",
    "- MinTemp: the minimum temperature in degrees celsius\n",
    "- MaxTemp: the maximum temperature in degrees celsius\n",
    "- Rainfall: the amount of rainfall recorded for the day in mm\n",
    "- Evaporation: the so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
    "- Sunshine: the number of hours of bright sunshine in the day\n",
    "- WindGustDir: the direction of the strongest wind gust in the 24 hours to midnight\n",
    "- WindGustSpeed: the speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "- WindDir9am: direction of the wind at 9am\n",
    "- WindDir3pm: direction of the wind at 3pm\n",
    "- WindSpeed9am: wind speed (km/hr) averaged over 10 minutes prior to 9am\n",
    "- WindSpeed3pm: wind speed (km/hr) averaged over 10 minutes prior to 3pm\n",
    "- Humidity9am: humidity (percent) at 9am\n",
    "- Humidity3pm: humidity (percent) at 3pm\n",
    "- Pressure9am: atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "- Pressure3pm: atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "- Cloud9am: fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast\n",
    "- Cloud3pm: fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n",
    "- Temp9am: temperature (degrees C) at 9am\n",
    "- Temp3pm: temperature (degrees C) at 3pm\n",
    "- RainToday: whether the precipitation (mm) in the 24 hours to 9am exceeded 1mm, Yes: the precipitation exceeded 1mm, No: it did not exceed 1mm\n",
    "\n",
    "A detailed description of the target variable is shown below: \n",
    "\n",
    "- RainTomorrow: whether amount of next day rain exceeded 1mm, Yes: next day precipitation exceeded 1mm, No: it did not exceed 1mm\n",
    "\n",
    "For this dataset, we want use those 22 input features and apply machine learning algorithms to predict whether it rained the next day or not.\n",
    "\n",
    "Data source: http://www.bom.gov.au/climate/dwo/ and http://www.bom.gov.au/climate/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Australian rain dataset\n",
    "aus = pd.read_csv('Data/weatherAUS.csv')\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the number of missing values in each column\n",
    "aus.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in categorical columns with the mode \n",
    "aus_cate_cols = aus.dtypes.index[aus.dtypes == \"object\"].tolist()\n",
    "for cate_col in aus_cate_cols:\n",
    "    aus[cate_col] = aus[cate_col].fillna(aus[cate_col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in numerical columns with the mean\n",
    "aus_num_cols = aus.dtypes.index[aus.dtypes == \"float64\"].tolist()\n",
    "for num_col in aus_num_cols:\n",
    "    aus[num_col] = aus[num_col].fillna(aus[num_col].mean())\n",
    "    # scale numerical attributes to 0 mean 1 std\n",
    "    aus[num_col] = (aus[num_col] - aus[num_col].mean()) / aus[num_col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "Location         0\n",
       "MinTemp          0\n",
       "MaxTemp          0\n",
       "Rainfall         0\n",
       "Evaporation      0\n",
       "Sunshine         0\n",
       "WindGustDir      0\n",
       "WindGustSpeed    0\n",
       "WindDir9am       0\n",
       "WindDir3pm       0\n",
       "WindSpeed9am     0\n",
       "WindSpeed3pm     0\n",
       "Humidity9am      0\n",
       "Humidity3pm      0\n",
       "Pressure9am      0\n",
       "Pressure3pm      0\n",
       "Cloud9am         0\n",
       "Cloud3pm         0\n",
       "Temp9am          0\n",
       "Temp3pm          0\n",
       "RainToday        0\n",
       "RainTomorrow     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all missing values are filled\n",
    "aus.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the date of each observation into year, month, and day\n",
    "splitted_date = aus['Date'].str.split('-')\n",
    "\n",
    "# create 'Year', 'Month', 'Day' columns using splitted results of the date\n",
    "aus['Year'] = splitted_date.str[0].astype(int)\n",
    "aus['Month'] = splitted_date.str[1].astype(int)\n",
    "aus['Day'] = splitted_date.str[2].astype(int)\n",
    "\n",
    "# drop original 'Date' column\n",
    "aus = aus.drop(columns = ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 0 and 1 to indicate whether it rained or not\n",
    "# 0: it rained, 1: it did not rain\n",
    "aus['RainToday'] = aus['RainToday'].replace({'No': 0, 'Yes': 1})\n",
    "aus['RainTomorrow'] = aus['RainTomorrow'].replace({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189446</td>\n",
       "      <td>-0.045336</td>\n",
       "      <td>-0.210071</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>0.612321</td>\n",
       "      <td>0.112394</td>\n",
       "      <td>-1.442960</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.753098</td>\n",
       "      <td>0.265042</td>\n",
       "      <td>-0.281649</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>-1.133434</td>\n",
       "      <td>0.382873</td>\n",
       "      <td>-1.319604</td>\n",
       "      <td>-1.296413</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110901</td>\n",
       "      <td>0.349691</td>\n",
       "      <td>-0.281649</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>0.454692</td>\n",
       "      <td>0.559366</td>\n",
       "      <td>0.841768</td>\n",
       "      <td>-1.637826</td>\n",
       "      <td>-1.052167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.470335</td>\n",
       "      <td>0.674177</td>\n",
       "      <td>-0.281649</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>-1.222360</td>\n",
       "      <td>-0.343461</td>\n",
       "      <td>-1.108537</td>\n",
       "      <td>-1.266567</td>\n",
       "      <td>-1.736055</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.833518</td>\n",
       "      <td>1.280826</td>\n",
       "      <td>-0.162353</td>\n",
       "      <td>-1.737284e-12</td>\n",
       "      <td>-1.385234e-12</td>\n",
       "      <td>0.073544</td>\n",
       "      <td>-0.794874</td>\n",
       "      <td>0.153425</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>-0.905620</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MinTemp   MaxTemp  Rainfall   Evaporation      Sunshine  WindGustSpeed  \\\n",
       "0  0.189446 -0.045336 -0.210071 -1.737284e-12 -1.385234e-12       0.302233   \n",
       "1 -0.753098  0.265042 -0.281649 -1.737284e-12 -1.385234e-12       0.302233   \n",
       "2  0.110901  0.349691 -0.281649 -1.737284e-12 -1.385234e-12       0.454692   \n",
       "3 -0.470335  0.674177 -0.281649 -1.737284e-12 -1.385234e-12      -1.222360   \n",
       "4  0.833518  1.280826 -0.162353 -1.737284e-12 -1.385234e-12       0.073544   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW  \\\n",
       "0      0.672219      0.612321     0.112394    -1.442960  ...               0   \n",
       "1     -1.133434      0.382873    -1.319604    -1.296413  ...               0   \n",
       "2      0.559366      0.841768    -1.637826    -1.052167  ...               0   \n",
       "3     -0.343461     -1.108537    -1.266567    -1.736055  ...               0   \n",
       "4     -0.794874      0.153425     0.695801    -0.905620  ...               0   \n",
       "\n",
       "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n",
       "0              0             0              0               0               0   \n",
       "1              0             0              0               0               0   \n",
       "2              0             0              0               0               0   \n",
       "3              0             0              0               0               0   \n",
       "4              1             0              0               0               0   \n",
       "\n",
       "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0              0             0               1               0  \n",
       "1              0             0               0               1  \n",
       "2              0             0               0               1  \n",
       "3              0             0               0               0  \n",
       "4              0             0               0               0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding all categorical columns\n",
    "cate_cols = aus.dtypes.index[aus.dtypes == \"object\"].tolist()\n",
    "aus = pd.get_dummies(columns = cate_cols, data = aus)\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.780854\n",
       "1    0.219146\n",
       "Name: RainTomorrow, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 78.0854% negative labels, 21.9146% positive labels\n",
    "aus['RainTomorrow'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the rain dataset into input features and labels \n",
    "aus_X = aus.drop(columns=['RainTomorrow']) # input features\n",
    "aus_y = aus['RainTomorrow'] # true lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean BnB Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is from https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv, and contains data from AirBnB listing and metrics in New York City, New York for the year 2019. There are 47900 unique values in this dataset, in which we will be using different features to predict whether an AirBnB pricing is expensive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the AirBnb dataset\n",
    "airbnb = pd.read_csv('data/AB_NYC_2019.csv')\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be looking at these features of the AirBnB for our predictive model\n",
    "airbnb = airbnb[['neighbourhood_group','latitude','longitude','room_type', 'price',\n",
    "                       'minimum_nights','number_of_reviews','availability_365']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The price median will be the threshold for our expensive classifier\n",
    "airbnb['price'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>is_expensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>355</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>194</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group  latitude  longitude        room_type  price  \\\n",
       "0            Brooklyn  40.64749  -73.97237     Private room    149   \n",
       "1           Manhattan  40.75362  -73.98377  Entire home/apt    225   \n",
       "2           Manhattan  40.80902  -73.94190     Private room    150   \n",
       "3            Brooklyn  40.68514  -73.95976  Entire home/apt     89   \n",
       "4           Manhattan  40.79851  -73.94399  Entire home/apt     80   \n",
       "\n",
       "   minimum_nights  number_of_reviews  availability_365  is_expensive  \n",
       "0               1                  9               365          True  \n",
       "1               1                 45               355          True  \n",
       "2               3                  0               365          True  \n",
       "3               1                270               194         False  \n",
       "4              10                  9                 0         False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new column with prices greater than the median as True, lesser than as False\n",
    "airbnb = airbnb.assign(\n",
    "    is_expensive = airbnb.get('price') > 106.0\n",
    ")\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into input features and labels\n",
    "airbnb_df_X = airbnb.drop(columns=['is_expensive'])\n",
    "airbnb_df_y = airbnb['is_expensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for the categorical columns\n",
    "airbnb_X_cat_col = ['neighbourhood_group', 'room_type']\n",
    "airbnb_X = pd.get_dummies(columns=airbnb_X_cat_col, data=airbnb_df_X)\n",
    "\n",
    "airbnb_y = airbnb_df_y.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Olympic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is from https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results?select=athlete_events.csv, and includes historic data of all participants from the Olympic Games, from Athens 1896 to Rio 2016. There are 271116 unique values/observations. We want to see whether or not we can predict a gold medalist just by participant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gunnar Nielsen Aaby</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1920 Summer</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Edgar Lindenau Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900 Summer</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      Name Sex   Age  Height  Weight            Team  \\\n",
       "0   1                 A Dijiang   M  24.0   180.0    80.0           China   \n",
       "1   2                  A Lamusi   M  23.0   170.0    60.0           China   \n",
       "2   3       Gunnar Nielsen Aaby   M  24.0     NaN     NaN         Denmark   \n",
       "3   4      Edgar Lindenau Aabye   M  34.0     NaN     NaN  Denmark/Sweden   \n",
       "4   5  Christine Jacoba Aaftink   F  21.0   185.0    82.0     Netherlands   \n",
       "\n",
       "   NOC        Games  Year  Season       City          Sport  \\\n",
       "0  CHN  1992 Summer  1992  Summer  Barcelona     Basketball   \n",
       "1  CHN  2012 Summer  2012  Summer     London           Judo   \n",
       "2  DEN  1920 Summer  1920  Summer  Antwerpen       Football   \n",
       "3  DEN  1900 Summer  1900  Summer      Paris     Tug-Of-War   \n",
       "4  NED  1988 Winter  1988  Winter    Calgary  Speed Skating   \n",
       "\n",
       "                              Event Medal  \n",
       "0       Basketball Men's Basketball   NaN  \n",
       "1      Judo Men's Extra-Lightweight   NaN  \n",
       "2           Football Men's Football   NaN  \n",
       "3       Tug-Of-War Men's Tug-Of-War  Gold  \n",
       "4  Speed Skating Women's 500 metres   NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Olympic dataset\n",
    "olympic = pd.read_csv('data/athlete_events.csv')\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Judo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Football</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight  NOC          Sport Medal\n",
       "0   M  24.0   180.0    80.0  CHN     Basketball   NaN\n",
       "1   M  23.0   170.0    60.0  CHN           Judo   NaN\n",
       "2   M  24.0     NaN     NaN  DEN       Football   NaN\n",
       "3   M  34.0     NaN     NaN  DEN     Tug-Of-War  Gold\n",
       "4   F  21.0   185.0    82.0  NED  Speed Skating   NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the features we will be looking at for our classifier\n",
    "olympic = olympic[['Sex', 'Age','Height','Weight','NOC','Sport','Medal']]\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271116, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some NaN values in this dataset, so we want to remove those\n",
    "olympic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Judo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight  NOC          Sport Medal\n",
       "0   M  24.0   180.0    80.0  CHN     Basketball   NaN\n",
       "1   M  23.0   170.0    60.0  CHN           Judo   NaN\n",
       "4   F  21.0   185.0    82.0  NED  Speed Skating   NaN\n",
       "5   F  21.0   185.0    82.0  NED  Speed Skating   NaN\n",
       "6   F  25.0   185.0    82.0  NED  Speed Skating   NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This removes the NaN values from the numerical columns\n",
    "olympic = olympic[olympic['Height'].notna()]\n",
    "olympic = olympic[olympic['Weight'].notna()]\n",
    "olympic = olympic[olympic['Age'].notna()]\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206165, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After that cleaning, we are left with 206165 participants to work with\n",
    "olympic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Medal</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Judo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight  NOC          Sport Medal   Gold\n",
       "0   M  24.0   180.0    80.0  CHN     Basketball   NaN  False\n",
       "1   M  23.0   170.0    60.0  CHN           Judo   NaN  False\n",
       "4   F  21.0   185.0    82.0  NED  Speed Skating   NaN  False\n",
       "5   F  21.0   185.0    82.0  NED  Speed Skating   NaN  False\n",
       "6   F  25.0   185.0    82.0  NED  Speed Skating   NaN  False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to make a column to see if the participant is a Gold Medalist\n",
    "olympic['Gold'] = olympic['Medal']=='Gold'\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Judo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NED</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight  NOC          Sport   Gold\n",
       "0   M  24.0   180.0    80.0  CHN     Basketball  False\n",
       "1   M  23.0   170.0    60.0  CHN           Judo  False\n",
       "4   F  21.0   185.0    82.0  NED  Speed Skating  False\n",
       "5   F  21.0   185.0    82.0  NED  Speed Skating  False\n",
       "6   F  25.0   185.0    82.0  NED  Speed Skating  False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We no longer need the Medal column\n",
    "olympic = olympic.drop(columns=['Medal'])\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the olympic dataset into input features and labels\n",
    "olympic_df_X = olympic.drop(columns=['Gold'])\n",
    "olympic_df_y = olympic['Gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode all the categorical columns\n",
    "olympic_X_cat_col = ['Sex','NOC','Sport']\n",
    "olympic_X = pd.get_dummies(columns=olympic_X_cat_col, data=olympic_df_X)\n",
    "olympic_y = olympic_df_y.replace({True: 0, False: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "\n",
    "tree_params = [\n",
    "    {\n",
    "        'max_depth': [2,3,4,5,7,10,13,15,18,None], \n",
    "        'min_samples_split':[2,3,5,7,10,15,20],\n",
    "        'min_samples_leaf':[2,3,5,7,10,15,20]\n",
    "    }\n",
    "]\n",
    "\n",
    "log_reg_params = [        \n",
    "    {\n",
    "        'solver': ['lbfgs'],\n",
    "        'max_iter': [5000],\n",
    "        'penalty': ['l2'],\n",
    "        'C': 10**np.arange(-4, 5, 1, dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'solver': ['saga'],\n",
    "        'max_iter': [5000],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': 10**np.arange(-4, 5, 1, dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'solver': ['saga', 'lbfgs'],\n",
    "        'max_iter': [5000],\n",
    "        'penalty': ['none']\n",
    "    }\n",
    "]\n",
    "\n",
    "perceptron_params = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "    }\n",
    "]\n",
    "\n",
    "svc_params = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32')\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'degree': [2, 3],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': 10 **np.array(np.arange(-3, 2, 2), dtype='float32'),\n",
    "        'gamma': [0.001,0.01,0.1,1,2]\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_params = [\n",
    "    {\n",
    "        'n_neighbors': np.arange(1, 106, 4),\n",
    "        'metric': [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "forest_params = [\n",
    "    {\n",
    "        'n_estimators': [1024],\n",
    "        'min_samples_split': [1, 2, 4, 6, 8, 12, 16, 20]\n",
    "    }\n",
    "]\n",
    "\n",
    "# models that do not include SVM classifier\n",
    "models_without_svm = {\n",
    "    'tree': (DecisionTreeClassifier(), tree_params),\n",
    "    'log_reg': (LogisticRegression(), log_reg_params),\n",
    "    'perceptron': (Perceptron(), perceptron_params),\n",
    "    'knn': (KNeighborsClassifier(), knn_params),\n",
    "    'forest': (RandomForestClassifier(), forest_params)\n",
    "}\n",
    "\n",
    "# SVM model\n",
    "models_only_svm = {\n",
    "    'svm': (SVC(), svc_params)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tree', 'log_reg', 'perceptron', 'knn', 'forest', 'svm']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(models_without_svm.keys()) + list(models_only_svm.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(models_without_svm.keys()) + list(models_only_svm.keys())\n",
    "\n",
    "results_columns = ['dataset', 'model', 'trial',\n",
    "                       'train_accuracy', 'train_precision',\n",
    "                       'train_recall', 'train_specificity',\n",
    "                       'train_f1', 'train_roc_auc',\n",
    "                       'test_accuracy', 'test_precision', \n",
    "                       'test_recall', 'test_specificity',\n",
    "                       'test_f1', 'test_roc_auc']\n",
    "scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score),\n",
    "        'specificity': make_scorer(recall_score, pos_label=0),\n",
    "        'f1': make_scorer(f1_score),\n",
    "        'roc_auc': make_scorer(roc_auc_score),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform 7 trials using each of 6 algorithms on one dataset\n",
    "def perform_trials(dataset_name, models, data_X, data_y):\n",
    "    \n",
    "    num_trials = 7\n",
    "    \n",
    "    data_results = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "    for model_name in models.keys():\n",
    "        model = models[model_name][0]        \n",
    "        model_params_grid = models[model_name][1]\n",
    "        model_results = pd.DataFrame(columns=results_columns)\n",
    "        \n",
    "        # perform 7 trials using each model on the dataset\n",
    "        for trial_count in range(num_trials):\n",
    "            # pick 5000 samples with replacement to be in the training set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, \n",
    "                                                                train_size=5000, \n",
    "                                                                random_state=trial_count)\n",
    "            \n",
    "            # grid search with 5 k-folds\n",
    "            search = GridSearchCV(model, model_params_grid, cv=5, verbose=3,\n",
    "                                  n_jobs=-1, refit=False, scoring=scoring)\n",
    "            \n",
    "            # fit grid search model with training set\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # store 7 metrics calculated in one trial\n",
    "            model_result = {\n",
    "                'dataset': dataset_name,\n",
    "                'model': model_name,\n",
    "                'trial': trial_count + 1\n",
    "            }\n",
    "            \n",
    "            for score_name in scoring.keys():\n",
    "                # find the best parameters that make model achieves best score of the metric\n",
    "                best_params = search.cv_results_['params'][np.argmin(search.cv_results_['rank_test_' + score_name])]\n",
    "                # use best parameters to create the optimal model for the metric\n",
    "                best_model = clone(model).set_params(**best_params)\n",
    "                # train the optimal model\n",
    "                best_model.fit(X_train, y_train)\n",
    "                \n",
    "                # compute metrics\n",
    "                train_score = scoring[score_name](best_model, X_train, y_train)\n",
    "                test_score = scoring[score_name](best_model, X_test, y_test)\n",
    "\n",
    "                # append scores\n",
    "                model_result['train_' + score_name] = train_score\n",
    "                model_result['test_' + score_name] = test_score\n",
    "            \n",
    "            # append scores of one trial to the model_results dataframe\n",
    "            model_results = model_results.append(model_result, ignore_index=True)\n",
    "        \n",
    "        # append model_results to data_results\n",
    "        data_results = data_results.append(model_results, ignore_index=True)\n",
    "        \n",
    "        # store scores averaged over 7 trials\n",
    "        avg_result = {\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'trial': 'avg',\n",
    "            \n",
    "            'train_accuracy': model_results.train_accuracy.mean(),\n",
    "            'train_precision': model_results.train_precision.mean(),\n",
    "            'train_recall': model_results.train_recall.mean(),\n",
    "            'train_specificity': model_results.train_specificity.mean(),\n",
    "            'train_f1': model_results.train_f1.mean(),\n",
    "            'train_roc_auc': model_results.train_roc_auc.mean(),\n",
    "            \n",
    "            'test_accuracy': model_results.test_accuracy.mean(),\n",
    "            'test_precision': model_results.test_precision.mean(),\n",
    "            'test_recall': model_results.test_recall.mean(),\n",
    "            'test_specificity': model_results.test_specificity.mean(),\n",
    "            'test_f1': model_results.test_f1.mean(),\n",
    "            'test_roc_auc': model_results.test_roc_auc.mean()\n",
    "        }\n",
    "        \n",
    "        # append avg_result to the data_results dataframe\n",
    "        data_results = data_results.append(avg_result, ignore_index=True)\n",
    "    \n",
    "    return data_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chess Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.9s\n"
     ]
    }
   ],
   "source": [
    "chess_results_no_svm = perform_trials('chess', models_without_svm, chess_X, chess_y)\n",
    "chess_results_no_svm.to_csv('results/chess_no_svm.csv')\n",
    "chess_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_results_svm = perform_trials('chess', models_only_svm, chess_X, chess_y)\n",
    "chess_results_svm.to_csv('results/chess_svm.csv')\n",
    "chess_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_results_no_svm = pd.read_csv('results/chess_no_svm.csv')\n",
    "chess_results_svm = pd.read_csv('results/chess_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "chess_results = chess_results_no_svm.append(chess_results_svm, ignore_index=True)\n",
    "chess_results.to_csv('results/chess.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrooms Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1904 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.554272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.625254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>1.574997</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>1.592083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shrooms</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999688</td>\n",
       "      <td>1.564635</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999174</td>\n",
       "      <td>0.999175</td>\n",
       "      <td>1.608669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  shrooms  tree     1          1.0000              1.0      1.000000   \n",
       "1  shrooms  tree     2          0.9994              1.0      0.998750   \n",
       "2  shrooms  tree   avg          0.9997              1.0      0.999375   \n",
       "\n",
       "   train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0                1.0  1.000000       1.000000        1.554272       1.000000   \n",
       "1                1.0  0.999375       0.999375        1.574997       0.998399   \n",
       "2                1.0  0.999687       0.999688        1.564635       0.999200   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0             1.0     1.000000               1.0  1.000000      1.000000   \n",
       "1             1.0     0.996702               1.0  0.998348      0.998351   \n",
       "2             1.0     0.998351               1.0  0.999174      0.999175   \n",
       "\n",
       "   test_log_loss  \n",
       "0       1.625254  \n",
       "1       1.592083  \n",
       "2       1.608669  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrooms_results_no_svm = perform_trials('shrooms', models_without_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_no_svm.to_csv('results/shrooms_no_svm.csv')\n",
    "shrooms_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results_svm = perform_trials('shrooms', models_only_svm, shrooms_X, shrooms_y)\n",
    "shrooms_results_svm.to_csv('results/shrooms_svm.csv')\n",
    "shrooms_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results_no_svm = pd.read_csv('results/shrooms_no_svm.csv')\n",
    "shrooms_results_svm = pd.read_csv('results/shrooms_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrooms_results = shrooms_results_no_svm.append(shrooms_results_svm, ignore_index=True)\n",
    "shrooms_results.to_csv('results/shrooms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Cardio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7122 0.7224 0.7244 0.729  0.7352 0.738  0.738 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71018712 0.72262559 0.72602912 0.73219589 0.7414073\n",
      " 0.7441335  0.74557375]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.7109301  0.71616149 0.71535747 0.71696713 0.71736711\n",
      " 0.72058804 0.71776871]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71342974 0.72853672 0.73330414 0.74085408 0.75277541\n",
      " 0.75516031 0.75794045]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71025872 0.71908501 0.7203257  0.72411356 0.72873901\n",
      " 0.7316989  0.73092221]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71217992 0.7223491  0.72433081 0.7289106  0.73507126\n",
      " 0.73787418 0.73785458]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 9.94037515 9.58807355 9.51899408 9.36011267 9.14596746\n",
      " 9.04925793 9.04925681]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7072 0.7104 0.7134 0.714  0.7182 0.717  0.7176]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71729122 0.72042873 0.72587774 0.72684657 0.73153264\n",
      " 0.73224623 0.73332237]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70368966 0.70643476 0.70447244 0.70408259 0.70722293\n",
      " 0.70172734 0.70133749]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71084999 0.71451931 0.72267343 0.72430359 0.72960389\n",
      " 0.73286088 0.73449603]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71005254 0.71311381 0.71469927 0.71500553 0.71893969\n",
      " 0.71645241 0.71672658]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70726983 0.71047703 0.71357293 0.71419309 0.71841341\n",
      " 0.71729411 0.71791676]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.11306711 10.00254159  9.89892206  9.87819815  9.73313321\n",
      "  9.77457847  9.75385456]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7148 0.7208 0.7226 0.7226 0.7284 0.7274 0.7308]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.72558873 0.73429355 0.73702424 0.73823084 0.74777637\n",
      " 0.74891148 0.75257985]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70640982 0.70640905 0.70641291 0.70404916 0.70286651\n",
      " 0.69775072 0.70090033]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.72345305 0.73565645 0.73932078 0.74175815 0.75477042\n",
      " 0.75802411 0.7616843 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71574225 0.71998699 0.72133472 0.72061665 0.72450029\n",
      " 0.72230869 0.72570451]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71493143 0.72103275 0.72286685 0.72290366 0.72881847\n",
      " 0.72788742 0.73129232]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 9.85056777 9.64333032 9.58115908 9.58115812 9.3808281\n",
      " 9.4153656  9.29793232]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7076 0.7076 0.712  0.7166 0.718  0.7202 0.722 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71354451 0.71574113 0.72136717 0.72743916 0.73286571\n",
      " 0.73634522 0.73776768]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70180968 0.69705092 0.69903898 0.70062471 0.69388732\n",
      " 0.69348421 0.69626434]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71347589 0.71831786 0.72517758 0.73284295 0.7425277\n",
      " 0.74737211 0.74818263]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70744846 0.70613    0.70986868 0.71358537 0.71271145\n",
      " 0.71416158 0.71636865]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70764278 0.70768439 0.71210828 0.71673383 0.71820751\n",
      " 0.72042816 0.72222349]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.09925176 10.09924984  9.94727651  9.7883951   9.74003697\n",
      "  9.66404974  9.60187963]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7028 0.7078 0.714  0.716  0.7196 0.7218 0.7234]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70175927 0.70908966 0.71583799 0.71763381 0.72460695\n",
      " 0.72766677 0.72878402]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71071182 0.70991818 0.71470064 0.71709108 0.71311256\n",
      " 0.71351017 0.71589824]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.69481467 0.70567259 0.71330554 0.71491439 0.72617714\n",
      " 0.73019806 0.73099642]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70613938 0.70941358 0.71513152 0.71722154 0.71866935\n",
      " 0.72035244 0.72220084]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70276325 0.70779538 0.71400309 0.71600273 0.71964485\n",
      " 0.72185411 0.72344733]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.26504572 10.09234752  9.87820407  9.80912588  9.68478181\n",
      "  9.6087949   9.55353254]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7036 0.7082 0.7142 0.7196 0.728  0.7282 0.7314]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70460275 0.70996288 0.71781816 0.7259626  0.73686675\n",
      " 0.73774584 0.74218078]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.68095432 0.6842163  0.68707012 0.68747745 0.69237125\n",
      " 0.69114843 0.69277692]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.72539004 0.73127162 0.74029354 0.75049501 0.76226203\n",
      " 0.76383066 0.76853654]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.69248503 0.69679837 0.7020477  0.7061299  0.71384426\n",
      " 0.7136309  0.71652045]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70317218 0.70774396 0.71368183 0.71898623 0.72731664\n",
      " 0.72748954 0.73065673]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.23740527 10.0785245   9.87128816  9.68477461  9.39464409\n",
      "  9.3877357   9.27720969]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.7096 0.7186 0.724  0.7256 0.728  0.7286 0.7306]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71396619 0.72523244 0.73327807 0.7361804  0.74195342\n",
      " 0.74367672 0.74668793]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70064192 0.70503713 0.70543553 0.70463872 0.70023872\n",
      " 0.69864192 0.69904112]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71857715 0.73218838 0.74259719 0.7466004  0.75580922\n",
      " 0.75861082 0.76221082]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70716558 0.71490579 0.71892611 0.71984985 0.72033584\n",
      " 0.72033562 0.72194811]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70960954 0.71861275 0.72401636 0.72561956 0.72802397\n",
      " 0.72862637 0.73062597]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan 10.03017309  9.71931866  9.53280511  9.47754147  9.39464473\n",
      "  9.37392035  9.30484135]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.769610</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.814388</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.726756</td>\n",
       "      <td>3.329554</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.760048</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.803292</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.718082</td>\n",
       "      <td>12.502100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.825455</td>\n",
       "      <td>0.771586</td>\n",
       "      <td>0.884584</td>\n",
       "      <td>0.736182</td>\n",
       "      <td>0.730678</td>\n",
       "      <td>3.377911</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.823521</td>\n",
       "      <td>0.757578</td>\n",
       "      <td>0.888329</td>\n",
       "      <td>0.717287</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>12.549928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.721763</td>\n",
       "      <td>0.817405</td>\n",
       "      <td>0.738914</td>\n",
       "      <td>0.728793</td>\n",
       "      <td>3.143042</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>0.691226</td>\n",
       "      <td>0.803083</td>\n",
       "      <td>0.711474</td>\n",
       "      <td>0.723870</td>\n",
       "      <td>12.463843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.787893</td>\n",
       "      <td>0.746233</td>\n",
       "      <td>0.823245</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>3.426264</td>\n",
       "      <td>0.724569</td>\n",
       "      <td>0.761494</td>\n",
       "      <td>0.689836</td>\n",
       "      <td>0.797068</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.724521</td>\n",
       "      <td>12.273081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.797519</td>\n",
       "      <td>0.734182</td>\n",
       "      <td>0.807801</td>\n",
       "      <td>0.743664</td>\n",
       "      <td>0.735456</td>\n",
       "      <td>2.977256</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.803805</td>\n",
       "      <td>0.711856</td>\n",
       "      <td>0.726788</td>\n",
       "      <td>12.826238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>0.734800</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.731538</td>\n",
       "      <td>0.799922</td>\n",
       "      <td>0.720253</td>\n",
       "      <td>0.734063</td>\n",
       "      <td>3.315736</td>\n",
       "      <td>0.731446</td>\n",
       "      <td>0.761724</td>\n",
       "      <td>0.672682</td>\n",
       "      <td>0.804416</td>\n",
       "      <td>0.720963</td>\n",
       "      <td>0.731479</td>\n",
       "      <td>12.584985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741400</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.714229</td>\n",
       "      <td>0.819456</td>\n",
       "      <td>0.748012</td>\n",
       "      <td>0.741457</td>\n",
       "      <td>3.101595</td>\n",
       "      <td>0.722185</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.658558</td>\n",
       "      <td>0.811395</td>\n",
       "      <td>0.695597</td>\n",
       "      <td>0.722577</td>\n",
       "      <td>12.450020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.733429</td>\n",
       "      <td>0.783695</td>\n",
       "      <td>0.725277</td>\n",
       "      <td>0.823829</td>\n",
       "      <td>0.730977</td>\n",
       "      <td>0.733553</td>\n",
       "      <td>3.238766</td>\n",
       "      <td>0.723389</td>\n",
       "      <td>0.772739</td>\n",
       "      <td>0.689663</td>\n",
       "      <td>0.815913</td>\n",
       "      <td>0.709872</td>\n",
       "      <td>0.723414</td>\n",
       "      <td>12.521457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.760739</td>\n",
       "      <td>0.663446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708817</td>\n",
       "      <td>0.728782</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.726646</td>\n",
       "      <td>0.757817</td>\n",
       "      <td>0.665702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708874</td>\n",
       "      <td>0.726637</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.661729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658646</td>\n",
       "      <td>0.688273</td>\n",
       "      <td>0.652064</td>\n",
       "      <td>16.938208</td>\n",
       "      <td>0.647785</td>\n",
       "      <td>0.649235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661212</td>\n",
       "      <td>0.681556</td>\n",
       "      <td>0.647767</td>\n",
       "      <td>17.306453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.763263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784059</td>\n",
       "      <td>0.715838</td>\n",
       "      <td>0.728898</td>\n",
       "      <td>16.986563</td>\n",
       "      <td>0.726769</td>\n",
       "      <td>0.747150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769117</td>\n",
       "      <td>0.714479</td>\n",
       "      <td>0.726690</td>\n",
       "      <td>17.302733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.652800</td>\n",
       "      <td>0.668092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686844</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.653097</td>\n",
       "      <td>17.117814</td>\n",
       "      <td>0.649785</td>\n",
       "      <td>0.656718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.669713</td>\n",
       "      <td>0.649753</td>\n",
       "      <td>17.292637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.751857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>17.179985</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.744387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764154</td>\n",
       "      <td>0.713106</td>\n",
       "      <td>0.725577</td>\n",
       "      <td>17.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>6</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.749176</td>\n",
       "      <td>0.649531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.720215</td>\n",
       "      <td>16.930908</td>\n",
       "      <td>0.725308</td>\n",
       "      <td>0.759396</td>\n",
       "      <td>0.660293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706385</td>\n",
       "      <td>0.725364</td>\n",
       "      <td>17.284266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.674133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658236</td>\n",
       "      <td>17.283204</td>\n",
       "      <td>0.665477</td>\n",
       "      <td>0.679728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665448</td>\n",
       "      <td>17.257167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.695571</td>\n",
       "      <td>0.718427</td>\n",
       "      <td>0.758997</td>\n",
       "      <td>0.800589</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>17.085078</td>\n",
       "      <td>0.695341</td>\n",
       "      <td>0.713490</td>\n",
       "      <td>0.760856</td>\n",
       "      <td>0.796319</td>\n",
       "      <td>0.599159</td>\n",
       "      <td>0.695319</td>\n",
       "      <td>17.285406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.813711</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.679807</td>\n",
       "      <td>0.658186</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.658831</td>\n",
       "      <td>0.820899</td>\n",
       "      <td>0.930943</td>\n",
       "      <td>0.645531</td>\n",
       "      <td>0.682359</td>\n",
       "      <td>0.658796</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>0.807792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970228</td>\n",
       "      <td>0.680869</td>\n",
       "      <td>0.530236</td>\n",
       "      <td>17.600960</td>\n",
       "      <td>0.532185</td>\n",
       "      <td>0.827289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975099</td>\n",
       "      <td>0.674746</td>\n",
       "      <td>0.533118</td>\n",
       "      <td>17.232724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.785208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718423</td>\n",
       "      <td>17.552606</td>\n",
       "      <td>0.713646</td>\n",
       "      <td>0.765788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713475</td>\n",
       "      <td>17.236444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.533800</td>\n",
       "      <td>0.814642</td>\n",
       "      <td>0.676447</td>\n",
       "      <td>0.424536</td>\n",
       "      <td>0.689242</td>\n",
       "      <td>0.529904</td>\n",
       "      <td>16.454390</td>\n",
       "      <td>0.523138</td>\n",
       "      <td>0.806657</td>\n",
       "      <td>0.686447</td>\n",
       "      <td>0.411917</td>\n",
       "      <td>0.687096</td>\n",
       "      <td>0.523739</td>\n",
       "      <td>16.344931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966224</td>\n",
       "      <td>0.639817</td>\n",
       "      <td>0.499818</td>\n",
       "      <td>17.359189</td>\n",
       "      <td>0.499677</td>\n",
       "      <td>0.823896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.962624</td>\n",
       "      <td>0.655747</td>\n",
       "      <td>0.500197</td>\n",
       "      <td>17.251322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>6</td>\n",
       "      <td>0.709800</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.977152</td>\n",
       "      <td>0.799922</td>\n",
       "      <td>0.675464</td>\n",
       "      <td>0.707998</td>\n",
       "      <td>18.243542</td>\n",
       "      <td>0.714185</td>\n",
       "      <td>0.761628</td>\n",
       "      <td>0.981616</td>\n",
       "      <td>0.804293</td>\n",
       "      <td>0.686119</td>\n",
       "      <td>0.714262</td>\n",
       "      <td>17.966164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>7</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.768566</td>\n",
       "      <td>0.730216</td>\n",
       "      <td>0.946357</td>\n",
       "      <td>0.301020</td>\n",
       "      <td>0.570834</td>\n",
       "      <td>17.283204</td>\n",
       "      <td>0.584415</td>\n",
       "      <td>0.765193</td>\n",
       "      <td>0.712289</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.308886</td>\n",
       "      <td>0.584213</td>\n",
       "      <td>17.257167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.604514</td>\n",
       "      <td>0.797079</td>\n",
       "      <td>0.617288</td>\n",
       "      <td>0.791935</td>\n",
       "      <td>0.523746</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>17.378965</td>\n",
       "      <td>0.603725</td>\n",
       "      <td>0.795907</td>\n",
       "      <td>0.615899</td>\n",
       "      <td>0.787140</td>\n",
       "      <td>0.527850</td>\n",
       "      <td>0.603971</td>\n",
       "      <td>17.222212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.708935</td>\n",
       "      <td>0.665862</td>\n",
       "      <td>0.748808</td>\n",
       "      <td>0.668511</td>\n",
       "      <td>0.688044</td>\n",
       "      <td>0.096709</td>\n",
       "      <td>0.662446</td>\n",
       "      <td>0.682355</td>\n",
       "      <td>0.608432</td>\n",
       "      <td>0.749792</td>\n",
       "      <td>0.642847</td>\n",
       "      <td>0.662438</td>\n",
       "      <td>14.255107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.676200</td>\n",
       "      <td>0.696905</td>\n",
       "      <td>0.645212</td>\n",
       "      <td>0.708401</td>\n",
       "      <td>0.670063</td>\n",
       "      <td>0.676807</td>\n",
       "      <td>0.096710</td>\n",
       "      <td>0.664385</td>\n",
       "      <td>0.674974</td>\n",
       "      <td>0.631371</td>\n",
       "      <td>0.696583</td>\n",
       "      <td>0.652445</td>\n",
       "      <td>0.664315</td>\n",
       "      <td>14.252454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.698636</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.730378</td>\n",
       "      <td>0.680570</td>\n",
       "      <td>0.691301</td>\n",
       "      <td>0.117433</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>0.685064</td>\n",
       "      <td>0.629046</td>\n",
       "      <td>0.719796</td>\n",
       "      <td>0.650257</td>\n",
       "      <td>0.662198</td>\n",
       "      <td>14.284339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.672400</td>\n",
       "      <td>0.702938</td>\n",
       "      <td>0.683584</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.689072</td>\n",
       "      <td>0.672980</td>\n",
       "      <td>0.145065</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.679177</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.718158</td>\n",
       "      <td>0.641689</td>\n",
       "      <td>0.661595</td>\n",
       "      <td>14.293903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.704795</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>0.683841</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>0.663508</td>\n",
       "      <td>0.677895</td>\n",
       "      <td>0.630013</td>\n",
       "      <td>0.714237</td>\n",
       "      <td>0.646774</td>\n",
       "      <td>0.663464</td>\n",
       "      <td>14.255112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.687437</td>\n",
       "      <td>0.658507</td>\n",
       "      <td>0.755983</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.660585</td>\n",
       "      <td>0.700069</td>\n",
       "      <td>0.593427</td>\n",
       "      <td>0.758407</td>\n",
       "      <td>0.628160</td>\n",
       "      <td>0.660660</td>\n",
       "      <td>14.273706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>0.700187</td>\n",
       "      <td>0.639888</td>\n",
       "      <td>0.743395</td>\n",
       "      <td>0.662453</td>\n",
       "      <td>0.679641</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.665154</td>\n",
       "      <td>0.693144</td>\n",
       "      <td>0.616159</td>\n",
       "      <td>0.737847</td>\n",
       "      <td>0.645988</td>\n",
       "      <td>0.665116</td>\n",
       "      <td>14.257235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.679857</td>\n",
       "      <td>0.699976</td>\n",
       "      <td>0.662977</td>\n",
       "      <td>0.737672</td>\n",
       "      <td>0.667303</td>\n",
       "      <td>0.679873</td>\n",
       "      <td>0.112499</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.684668</td>\n",
       "      <td>0.618423</td>\n",
       "      <td>0.727831</td>\n",
       "      <td>0.644023</td>\n",
       "      <td>0.662827</td>\n",
       "      <td>14.267408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.820587</td>\n",
       "      <td>0.818035</td>\n",
       "      <td>0.826709</td>\n",
       "      <td>0.824608</td>\n",
       "      <td>0.829720</td>\n",
       "      <td>0.096709</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.737436</td>\n",
       "      <td>0.711402</td>\n",
       "      <td>0.747270</td>\n",
       "      <td>0.723686</td>\n",
       "      <td>0.727936</td>\n",
       "      <td>10.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.855600</td>\n",
       "      <td>0.835790</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>0.835644</td>\n",
       "      <td>0.857880</td>\n",
       "      <td>0.858193</td>\n",
       "      <td>0.082893</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.713299</td>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.720940</td>\n",
       "      <td>0.725235</td>\n",
       "      <td>10.054622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.845053</td>\n",
       "      <td>0.924046</td>\n",
       "      <td>0.851566</td>\n",
       "      <td>0.816684</td>\n",
       "      <td>0.819709</td>\n",
       "      <td>0.110525</td>\n",
       "      <td>0.729215</td>\n",
       "      <td>0.734981</td>\n",
       "      <td>0.709723</td>\n",
       "      <td>0.743290</td>\n",
       "      <td>0.724629</td>\n",
       "      <td>0.728987</td>\n",
       "      <td>10.091817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.844806</td>\n",
       "      <td>0.992863</td>\n",
       "      <td>0.850686</td>\n",
       "      <td>0.826997</td>\n",
       "      <td>0.828814</td>\n",
       "      <td>0.138156</td>\n",
       "      <td>0.726169</td>\n",
       "      <td>0.731754</td>\n",
       "      <td>0.714361</td>\n",
       "      <td>0.740036</td>\n",
       "      <td>0.722557</td>\n",
       "      <td>0.726227</td>\n",
       "      <td>10.076941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.820430</td>\n",
       "      <td>0.902109</td>\n",
       "      <td>0.822276</td>\n",
       "      <td>0.809648</td>\n",
       "      <td>0.811848</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>0.728569</td>\n",
       "      <td>0.731344</td>\n",
       "      <td>0.724327</td>\n",
       "      <td>0.736583</td>\n",
       "      <td>0.727008</td>\n",
       "      <td>0.729069</td>\n",
       "      <td>10.075348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>6</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.831146</td>\n",
       "      <td>0.774786</td>\n",
       "      <td>0.850137</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>0.811292</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>0.749069</td>\n",
       "      <td>0.692911</td>\n",
       "      <td>0.767338</td>\n",
       "      <td>0.719588</td>\n",
       "      <td>0.730370</td>\n",
       "      <td>9.955777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>0.836871</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.840272</td>\n",
       "      <td>0.818923</td>\n",
       "      <td>0.822015</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.729385</td>\n",
       "      <td>0.744733</td>\n",
       "      <td>0.699818</td>\n",
       "      <td>0.761338</td>\n",
       "      <td>0.720746</td>\n",
       "      <td>0.729624</td>\n",
       "      <td>10.039738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>0.833526</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>0.839613</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.825942</td>\n",
       "      <td>0.108551</td>\n",
       "      <td>0.728002</td>\n",
       "      <td>0.737691</td>\n",
       "      <td>0.709406</td>\n",
       "      <td>0.748510</td>\n",
       "      <td>0.722736</td>\n",
       "      <td>0.728207</td>\n",
       "      <td>10.042702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   cardio        tree     1        0.727200         0.769610      0.657407   \n",
       "1   cardio        tree     2        0.730800         0.825455      0.771586   \n",
       "2   cardio        tree     3        0.727600         0.773550      0.721763   \n",
       "3   cardio        tree     4        0.737200         0.787893      0.746233   \n",
       "4   cardio        tree     5        0.735000         0.797519      0.734182   \n",
       "5   cardio        tree     6        0.734800         0.747525      0.731538   \n",
       "6   cardio        tree     7        0.741400         0.784314      0.714229   \n",
       "7   cardio        tree   avg        0.733429         0.783695      0.725277   \n",
       "8   cardio     log_reg     1        0.729200         0.760739      0.663446   \n",
       "9   cardio     log_reg     2        0.652000         0.661729      1.000000   \n",
       "10  cardio     log_reg     3        0.728000         0.763263      1.000000   \n",
       "11  cardio     log_reg     4        0.652800         0.668092      1.000000   \n",
       "12  cardio     log_reg     5        0.727200         0.751857      0.000000   \n",
       "13  cardio     log_reg     6        0.721600         0.749176      0.649531   \n",
       "14  cardio     log_reg     7        0.658200         0.674133      1.000000   \n",
       "15  cardio     log_reg   avg        0.695571         0.718427      0.758997   \n",
       "16  cardio  perceptron     1        0.659600         0.813711      0.937198   \n",
       "17  cardio  perceptron     2        0.538600         0.807792      1.000000   \n",
       "18  cardio  perceptron     3        0.716800         0.785208      0.000000   \n",
       "19  cardio  perceptron     4        0.533800         0.814642      0.676447   \n",
       "20  cardio  perceptron     5        0.502400         0.842105      0.000000   \n",
       "21  cardio  perceptron     6        0.709800         0.747525      0.977152   \n",
       "22  cardio  perceptron     7        0.570600         0.768566      0.730216   \n",
       "23  cardio  perceptron   avg        0.604514         0.797079      0.617288   \n",
       "24  cardio         knn     1        0.688400         0.708935      0.665862   \n",
       "25  cardio         knn     2        0.676200         0.696905      0.645212   \n",
       "26  cardio         knn     3        0.690600         0.698636      0.679260   \n",
       "27  cardio         knn     4        0.672400         0.702938      0.683584   \n",
       "28  cardio         knn     5        0.683600         0.704795      0.668524   \n",
       "29  cardio         knn     6        0.668200         0.687437      0.658507   \n",
       "30  cardio         knn     7        0.679600         0.700187      0.639888   \n",
       "31  cardio         knn   avg        0.679857         0.699976      0.662977   \n",
       "32  cardio      forest     1        0.830000         0.820587      0.818035   \n",
       "33  cardio      forest     2        0.855600         0.835790      0.845369   \n",
       "34  cardio      forest     3        0.820000         0.845053      0.924046   \n",
       "35  cardio      forest     4        0.829000         0.844806      0.992863   \n",
       "36  cardio      forest     5        0.813600         0.820430      0.902109   \n",
       "37  cardio      forest     6        0.811600         0.831146      0.774786   \n",
       "38  cardio      forest     7        0.822600         0.836871      0.920863   \n",
       "39  cardio      forest   avg        0.826057         0.833526      0.882582   \n",
       "\n",
       "    train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0            0.814388  0.705400       0.726756        3.329554       0.718092   \n",
       "1            0.884584  0.736182       0.730678        3.377911       0.716569   \n",
       "2            0.817405  0.738914       0.728793        3.143042       0.723985   \n",
       "3            0.823245  0.724413       0.737665        3.426264       0.724569   \n",
       "4            0.807801  0.743664       0.735456        2.977256       0.726877   \n",
       "5            0.799922  0.720253       0.734063        3.315736       0.731446   \n",
       "6            0.819456  0.748012       0.741457        3.101595       0.722185   \n",
       "7            0.823829  0.730977       0.733553        3.238766       0.723389   \n",
       "8            1.000000  0.708817       0.728782       17.158864       0.726646   \n",
       "9            0.658646  0.688273       0.652064       16.938208       0.647785   \n",
       "10           0.784059  0.715838       0.728898       16.986563       0.726769   \n",
       "11           0.686844  0.669090       0.653097       17.117814       0.649785   \n",
       "12           0.771612  0.716300       0.727424       17.179985       0.725615   \n",
       "13           1.000000  0.695804       0.720215       16.930908       0.725308   \n",
       "14           0.702962  0.000000       0.658236       17.283204       0.665477   \n",
       "15           0.800589  0.599160       0.695531       17.085078       0.695341   \n",
       "16           0.652623  0.679807       0.658186       17.158864       0.658831   \n",
       "17           0.970228  0.680869       0.530236       17.600960       0.532185   \n",
       "18           0.783652  0.000000       0.718423       17.552606       0.713646   \n",
       "19           0.424536  0.689242       0.529904       16.454390       0.523138   \n",
       "20           0.966224  0.639817       0.499818       17.359189       0.499677   \n",
       "21           0.799922  0.675464       0.707998       18.243542       0.714185   \n",
       "22           0.946357  0.301020       0.570834       17.283204       0.584415   \n",
       "23           0.791935  0.523746       0.602200       17.378965       0.603725   \n",
       "24           0.748808  0.668511       0.688044        0.096709       0.662446   \n",
       "25           0.708401  0.670063       0.676807        0.096710       0.664385   \n",
       "26           0.730378  0.680570       0.691301        0.117433       0.662262   \n",
       "27           0.738095  0.689072       0.672980        0.145065       0.661662   \n",
       "28           0.738641  0.669041       0.683841        0.124341       0.663508   \n",
       "29           0.755983  0.631415       0.666500        0.131248       0.660585   \n",
       "30           0.743395  0.662453       0.679641        0.075986       0.665154   \n",
       "31           0.737672  0.667303       0.679873        0.112499       0.662857   \n",
       "32           0.826709  0.824608       0.829720        0.096709       0.727969   \n",
       "33           0.835644  0.857880       0.858193        0.082893       0.724508   \n",
       "34           0.851566  0.816684       0.819709        0.110525       0.729215   \n",
       "35           0.850686  0.826997       0.828814        0.138156       0.726169   \n",
       "36           0.822276  0.809648       0.811848        0.124341       0.728569   \n",
       "37           0.850137  0.802960       0.811292        0.131248       0.730200   \n",
       "38           0.840272  0.818923       0.822015        0.075986       0.729385   \n",
       "39           0.839613  0.822529       0.825942        0.108551       0.728002   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0         0.760048     0.651762          0.803292  0.698032      0.718082   \n",
       "1         0.823521     0.757578          0.888329  0.717287      0.716578   \n",
       "2         0.753861     0.691226          0.803083  0.711474      0.723870   \n",
       "3         0.761494     0.689836          0.797068  0.713895      0.724521   \n",
       "4         0.775533     0.706000          0.803805  0.711856      0.726788   \n",
       "5         0.761724     0.672682          0.804416  0.720963      0.731479   \n",
       "6         0.772991     0.658558          0.811395  0.695597      0.722577   \n",
       "7         0.772739     0.689663          0.815913  0.709872      0.723414   \n",
       "8         0.757817     0.665702          1.000000  0.708874      0.726637   \n",
       "9         0.649235     1.000000          0.661212  0.681556      0.647767   \n",
       "10        0.747150     1.000000          0.769117  0.714479      0.726690   \n",
       "11        0.656718     1.000000          0.673785  0.669713      0.649753   \n",
       "12        0.744387     0.000000          0.764154  0.713106      0.725577   \n",
       "13        0.759396     0.660293          1.000000  0.706385      0.725364   \n",
       "14        0.679728     1.000000          0.705962  0.000000      0.665448   \n",
       "15        0.713490     0.760856          0.796319  0.599159      0.695319   \n",
       "16        0.820899     0.930943          0.645531  0.682359      0.658796   \n",
       "17        0.827289     1.000000          0.975099  0.674746      0.533118   \n",
       "18        0.765788     0.000000          0.764572  0.000000      0.713475   \n",
       "19        0.806657     0.686447          0.411917  0.687096      0.523739   \n",
       "20        0.823896     0.000000          0.962624  0.655747      0.500197   \n",
       "21        0.761628     0.981616          0.804293  0.686119      0.714262   \n",
       "22        0.765193     0.712289          0.945946  0.308886      0.584213   \n",
       "23        0.795907     0.615899          0.787140  0.527850      0.603971   \n",
       "24        0.682355     0.608432          0.749792  0.642847      0.662438   \n",
       "25        0.674974     0.631371          0.696583  0.652445      0.664315   \n",
       "26        0.685064     0.629046          0.719796  0.650257      0.662198   \n",
       "27        0.679177     0.620513          0.718158  0.641689      0.661595   \n",
       "28        0.677895     0.630013          0.714237  0.646774      0.663464   \n",
       "29        0.700069     0.593427          0.758407  0.628160      0.660660   \n",
       "30        0.693144     0.616159          0.737847  0.645988      0.665116   \n",
       "31        0.684668     0.618423          0.727831  0.644023      0.662827   \n",
       "32        0.737436     0.711402          0.747270  0.723686      0.727936   \n",
       "33        0.734523     0.713299          0.743713  0.720940      0.725235   \n",
       "34        0.734981     0.709723          0.743290  0.724629      0.728987   \n",
       "35        0.731754     0.714361          0.740036  0.722557      0.726227   \n",
       "36        0.731344     0.724327          0.736583  0.727008      0.729069   \n",
       "37        0.749069     0.692911          0.767338  0.719588      0.730370   \n",
       "38        0.744733     0.699818          0.761338  0.720746      0.729624   \n",
       "39        0.737691     0.709406          0.748510  0.722736      0.728207   \n",
       "\n",
       "    test_log_loss  \n",
       "0       12.502100  \n",
       "1       12.549928  \n",
       "2       12.463843  \n",
       "3       12.273081  \n",
       "4       12.826238  \n",
       "5       12.584985  \n",
       "6       12.450020  \n",
       "7       12.521457  \n",
       "8       17.266731  \n",
       "9       17.306453  \n",
       "10      17.302733  \n",
       "11      17.292637  \n",
       "12      17.287855  \n",
       "13      17.284266  \n",
       "14      17.257167  \n",
       "15      17.285406  \n",
       "16      17.266731  \n",
       "17      17.232724  \n",
       "18      17.236444  \n",
       "19      16.344931  \n",
       "20      17.251322  \n",
       "21      17.966164  \n",
       "22      17.257167  \n",
       "23      17.222212  \n",
       "24      14.255107  \n",
       "25      14.252454  \n",
       "26      14.284339  \n",
       "27      14.293903  \n",
       "28      14.255112  \n",
       "29      14.273706  \n",
       "30      14.257235  \n",
       "31      14.267408  \n",
       "32      10.004671  \n",
       "33      10.054622  \n",
       "34      10.091817  \n",
       "35      10.076941  \n",
       "36      10.075348  \n",
       "37       9.955777  \n",
       "38      10.039738  \n",
       "39      10.042702  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on cardio dataset\n",
    "cardio_results_no_svm = perform_trials('cardio', models_without_svm, cardio_X, cardio_y)\n",
    "cardio_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>0.814412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719471</td>\n",
       "      <td>0.736826</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.808387</td>\n",
       "      <td>0.800369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710771</td>\n",
       "      <td>0.727591</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.733200</td>\n",
       "      <td>0.748567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760604</td>\n",
       "      <td>0.732665</td>\n",
       "      <td>0.733509</td>\n",
       "      <td>16.931300</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.733427</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.757929</td>\n",
       "      <td>0.721300</td>\n",
       "      <td>0.726380</td>\n",
       "      <td>17.309641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824319</td>\n",
       "      <td>0.726668</td>\n",
       "      <td>0.737818</td>\n",
       "      <td>16.979656</td>\n",
       "      <td>0.727262</td>\n",
       "      <td>0.773072</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.813709</td>\n",
       "      <td>0.716606</td>\n",
       "      <td>0.727192</td>\n",
       "      <td>17.304327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.777726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.741597</td>\n",
       "      <td>0.735625</td>\n",
       "      <td>17.110906</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>0.752055</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.786744</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.727087</td>\n",
       "      <td>17.293700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.734400</td>\n",
       "      <td>0.770219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805790</td>\n",
       "      <td>0.725506</td>\n",
       "      <td>0.734588</td>\n",
       "      <td>17.179985</td>\n",
       "      <td>0.725523</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802022</td>\n",
       "      <td>0.715822</td>\n",
       "      <td>0.725488</td>\n",
       "      <td>17.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>6</td>\n",
       "      <td>0.728400</td>\n",
       "      <td>0.776371</td>\n",
       "      <td>0.821297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704654</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>16.924001</td>\n",
       "      <td>0.727862</td>\n",
       "      <td>0.784359</td>\n",
       "      <td>0.813484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709144</td>\n",
       "      <td>0.727918</td>\n",
       "      <td>17.280547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>7</td>\n",
       "      <td>0.738600</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>17.255972</td>\n",
       "      <td>0.728046</td>\n",
       "      <td>0.831545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995173</td>\n",
       "      <td>0.712434</td>\n",
       "      <td>0.728008</td>\n",
       "      <td>17.282010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.734829</td>\n",
       "      <td>0.795424</td>\n",
       "      <td>0.947959</td>\n",
       "      <td>0.884253</td>\n",
       "      <td>0.725033</td>\n",
       "      <td>0.734873</td>\n",
       "      <td>17.077241</td>\n",
       "      <td>0.727123</td>\n",
       "      <td>0.778404</td>\n",
       "      <td>0.944748</td>\n",
       "      <td>0.879368</td>\n",
       "      <td>0.713838</td>\n",
       "      <td>0.727095</td>\n",
       "      <td>17.289259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  cardio   svm     1        0.737200         0.805755      0.814412   \n",
       "1  cardio   svm     2        0.733200         0.748567      1.000000   \n",
       "2  cardio   svm     3        0.737000         0.785714      1.000000   \n",
       "3  cardio   svm     4        0.735000         0.777726      1.000000   \n",
       "4  cardio   svm     5        0.734400         0.770219      1.000000   \n",
       "5  cardio   svm     6        0.728400         0.776371      0.821297   \n",
       "6  cardio   svm     7        0.738600         0.903614      1.000000   \n",
       "7  cardio   svm   avg        0.734829         0.795424      0.947959   \n",
       "\n",
       "   train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0           1.000000  0.719471       0.736826       17.158864       0.727600   \n",
       "1           0.760604  0.732665       0.733509       16.931300       0.726415   \n",
       "2           0.824319  0.726668       0.737818       16.979656       0.727262   \n",
       "3           0.802260  0.741597       0.735625       17.110906       0.727154   \n",
       "4           0.805790  0.725506       0.734588       17.179985       0.725523   \n",
       "5           1.000000  0.704654       0.727103       16.924001       0.727862   \n",
       "6           0.996797  0.724668       0.738641       17.255972       0.728046   \n",
       "7           0.884253  0.725033       0.734873       17.077241       0.727123   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0        0.808387     0.800369          1.000000  0.710771      0.727591   \n",
       "1        0.733427     0.999784          0.757929  0.721300      0.726380   \n",
       "2        0.773072     0.999630          0.813709  0.716606      0.727192   \n",
       "3        0.752055     0.999969          0.786744  0.710793      0.727087   \n",
       "4        0.765986     1.000000          0.802022  0.715822      0.725488   \n",
       "5        0.784359     0.813484          1.000000  0.709144      0.727918   \n",
       "6        0.831545     1.000000          0.995173  0.712434      0.728008   \n",
       "7        0.778404     0.944748          0.879368  0.713838      0.727095   \n",
       "\n",
       "   test_log_loss  \n",
       "0      17.266731  \n",
       "1      17.309641  \n",
       "2      17.304327  \n",
       "3      17.293700  \n",
       "4      17.287855  \n",
       "5      17.280547  \n",
       "6      17.282010  \n",
       "7      17.289259  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running SVM algorithm on cardio dataset, generally take longer time to run than other algorithms combined\n",
    "cardio_results_svm = perform_trials('cardio', models_only_svm, cardio_X, cardio_y)\n",
    "cardio_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results of svm and non-svm algorithms and save as a csv file\n",
    "cardio_final_results = cardio_results_no_svm.append(cardio_results_svm, ignore_index=True)\n",
    "cardio_final_results.to_csv('results/cardio_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.769610</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.814388</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.726756</td>\n",
       "      <td>3.329554</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.760048</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.803292</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.718082</td>\n",
       "      <td>12.502100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.825455</td>\n",
       "      <td>0.771586</td>\n",
       "      <td>0.884584</td>\n",
       "      <td>0.736182</td>\n",
       "      <td>0.730678</td>\n",
       "      <td>3.377911</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.823521</td>\n",
       "      <td>0.757578</td>\n",
       "      <td>0.888329</td>\n",
       "      <td>0.717287</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>12.549928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.721763</td>\n",
       "      <td>0.817405</td>\n",
       "      <td>0.738914</td>\n",
       "      <td>0.728793</td>\n",
       "      <td>3.143042</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>0.691226</td>\n",
       "      <td>0.803083</td>\n",
       "      <td>0.711474</td>\n",
       "      <td>0.723870</td>\n",
       "      <td>12.463843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.787893</td>\n",
       "      <td>0.746233</td>\n",
       "      <td>0.823245</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.737665</td>\n",
       "      <td>3.426264</td>\n",
       "      <td>0.724569</td>\n",
       "      <td>0.761494</td>\n",
       "      <td>0.689836</td>\n",
       "      <td>0.797068</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.724521</td>\n",
       "      <td>12.273081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.797519</td>\n",
       "      <td>0.734182</td>\n",
       "      <td>0.807801</td>\n",
       "      <td>0.743664</td>\n",
       "      <td>0.735456</td>\n",
       "      <td>2.977256</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.803805</td>\n",
       "      <td>0.711856</td>\n",
       "      <td>0.726788</td>\n",
       "      <td>12.826238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>0.734800</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.731538</td>\n",
       "      <td>0.799922</td>\n",
       "      <td>0.720253</td>\n",
       "      <td>0.734063</td>\n",
       "      <td>3.315736</td>\n",
       "      <td>0.731446</td>\n",
       "      <td>0.761724</td>\n",
       "      <td>0.672682</td>\n",
       "      <td>0.804416</td>\n",
       "      <td>0.720963</td>\n",
       "      <td>0.731479</td>\n",
       "      <td>12.584985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741400</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.714229</td>\n",
       "      <td>0.819456</td>\n",
       "      <td>0.748012</td>\n",
       "      <td>0.741457</td>\n",
       "      <td>3.101595</td>\n",
       "      <td>0.722185</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.658558</td>\n",
       "      <td>0.811395</td>\n",
       "      <td>0.695597</td>\n",
       "      <td>0.722577</td>\n",
       "      <td>12.450020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.733429</td>\n",
       "      <td>0.783695</td>\n",
       "      <td>0.725277</td>\n",
       "      <td>0.823829</td>\n",
       "      <td>0.730977</td>\n",
       "      <td>0.733553</td>\n",
       "      <td>3.238766</td>\n",
       "      <td>0.723389</td>\n",
       "      <td>0.772739</td>\n",
       "      <td>0.689663</td>\n",
       "      <td>0.815913</td>\n",
       "      <td>0.709872</td>\n",
       "      <td>0.723414</td>\n",
       "      <td>12.521457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.760739</td>\n",
       "      <td>0.663446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708817</td>\n",
       "      <td>0.728782</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.726646</td>\n",
       "      <td>0.757817</td>\n",
       "      <td>0.665702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708874</td>\n",
       "      <td>0.726637</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.661729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658646</td>\n",
       "      <td>0.688273</td>\n",
       "      <td>0.652064</td>\n",
       "      <td>16.938208</td>\n",
       "      <td>0.647785</td>\n",
       "      <td>0.649235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661212</td>\n",
       "      <td>0.681556</td>\n",
       "      <td>0.647767</td>\n",
       "      <td>17.306453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.763263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784059</td>\n",
       "      <td>0.715838</td>\n",
       "      <td>0.728898</td>\n",
       "      <td>16.986563</td>\n",
       "      <td>0.726769</td>\n",
       "      <td>0.747150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769117</td>\n",
       "      <td>0.714479</td>\n",
       "      <td>0.726690</td>\n",
       "      <td>17.302733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.652800</td>\n",
       "      <td>0.668092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686844</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.653097</td>\n",
       "      <td>17.117814</td>\n",
       "      <td>0.649785</td>\n",
       "      <td>0.656718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.669713</td>\n",
       "      <td>0.649753</td>\n",
       "      <td>17.292637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.751857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>17.179985</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.744387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764154</td>\n",
       "      <td>0.713106</td>\n",
       "      <td>0.725577</td>\n",
       "      <td>17.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>6</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.749176</td>\n",
       "      <td>0.649531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.720215</td>\n",
       "      <td>16.930908</td>\n",
       "      <td>0.725308</td>\n",
       "      <td>0.759396</td>\n",
       "      <td>0.660293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706385</td>\n",
       "      <td>0.725364</td>\n",
       "      <td>17.284266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.674133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658236</td>\n",
       "      <td>17.283204</td>\n",
       "      <td>0.665477</td>\n",
       "      <td>0.679728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665448</td>\n",
       "      <td>17.257167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.695571</td>\n",
       "      <td>0.718427</td>\n",
       "      <td>0.758997</td>\n",
       "      <td>0.800589</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>17.085078</td>\n",
       "      <td>0.695341</td>\n",
       "      <td>0.713490</td>\n",
       "      <td>0.760856</td>\n",
       "      <td>0.796319</td>\n",
       "      <td>0.599159</td>\n",
       "      <td>0.695319</td>\n",
       "      <td>17.285406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.813711</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.679807</td>\n",
       "      <td>0.658186</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.658831</td>\n",
       "      <td>0.820899</td>\n",
       "      <td>0.930943</td>\n",
       "      <td>0.645531</td>\n",
       "      <td>0.682359</td>\n",
       "      <td>0.658796</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>0.807792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970228</td>\n",
       "      <td>0.680869</td>\n",
       "      <td>0.530236</td>\n",
       "      <td>17.600960</td>\n",
       "      <td>0.532185</td>\n",
       "      <td>0.827289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975099</td>\n",
       "      <td>0.674746</td>\n",
       "      <td>0.533118</td>\n",
       "      <td>17.232724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.785208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718423</td>\n",
       "      <td>17.552606</td>\n",
       "      <td>0.713646</td>\n",
       "      <td>0.765788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713475</td>\n",
       "      <td>17.236444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.533800</td>\n",
       "      <td>0.814642</td>\n",
       "      <td>0.676447</td>\n",
       "      <td>0.424536</td>\n",
       "      <td>0.689242</td>\n",
       "      <td>0.529904</td>\n",
       "      <td>16.454390</td>\n",
       "      <td>0.523138</td>\n",
       "      <td>0.806657</td>\n",
       "      <td>0.686447</td>\n",
       "      <td>0.411917</td>\n",
       "      <td>0.687096</td>\n",
       "      <td>0.523739</td>\n",
       "      <td>16.344931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966224</td>\n",
       "      <td>0.639817</td>\n",
       "      <td>0.499818</td>\n",
       "      <td>17.359189</td>\n",
       "      <td>0.499677</td>\n",
       "      <td>0.823896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.962624</td>\n",
       "      <td>0.655747</td>\n",
       "      <td>0.500197</td>\n",
       "      <td>17.251322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>6</td>\n",
       "      <td>0.709800</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.977152</td>\n",
       "      <td>0.799922</td>\n",
       "      <td>0.675464</td>\n",
       "      <td>0.707998</td>\n",
       "      <td>18.243542</td>\n",
       "      <td>0.714185</td>\n",
       "      <td>0.761628</td>\n",
       "      <td>0.981616</td>\n",
       "      <td>0.804293</td>\n",
       "      <td>0.686119</td>\n",
       "      <td>0.714262</td>\n",
       "      <td>17.966164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>7</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.768566</td>\n",
       "      <td>0.730216</td>\n",
       "      <td>0.946357</td>\n",
       "      <td>0.301020</td>\n",
       "      <td>0.570834</td>\n",
       "      <td>17.283204</td>\n",
       "      <td>0.584415</td>\n",
       "      <td>0.765193</td>\n",
       "      <td>0.712289</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.308886</td>\n",
       "      <td>0.584213</td>\n",
       "      <td>17.257167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.604514</td>\n",
       "      <td>0.797079</td>\n",
       "      <td>0.617288</td>\n",
       "      <td>0.791935</td>\n",
       "      <td>0.523746</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>17.378965</td>\n",
       "      <td>0.603725</td>\n",
       "      <td>0.795907</td>\n",
       "      <td>0.615899</td>\n",
       "      <td>0.787140</td>\n",
       "      <td>0.527850</td>\n",
       "      <td>0.603971</td>\n",
       "      <td>17.222212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.708935</td>\n",
       "      <td>0.665862</td>\n",
       "      <td>0.748808</td>\n",
       "      <td>0.668511</td>\n",
       "      <td>0.688044</td>\n",
       "      <td>0.096709</td>\n",
       "      <td>0.662446</td>\n",
       "      <td>0.682355</td>\n",
       "      <td>0.608432</td>\n",
       "      <td>0.749792</td>\n",
       "      <td>0.642847</td>\n",
       "      <td>0.662438</td>\n",
       "      <td>14.255107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.676200</td>\n",
       "      <td>0.696905</td>\n",
       "      <td>0.645212</td>\n",
       "      <td>0.708401</td>\n",
       "      <td>0.670063</td>\n",
       "      <td>0.676807</td>\n",
       "      <td>0.096710</td>\n",
       "      <td>0.664385</td>\n",
       "      <td>0.674974</td>\n",
       "      <td>0.631371</td>\n",
       "      <td>0.696583</td>\n",
       "      <td>0.652445</td>\n",
       "      <td>0.664315</td>\n",
       "      <td>14.252454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.698636</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.730378</td>\n",
       "      <td>0.680570</td>\n",
       "      <td>0.691301</td>\n",
       "      <td>0.117433</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>0.685064</td>\n",
       "      <td>0.629046</td>\n",
       "      <td>0.719796</td>\n",
       "      <td>0.650257</td>\n",
       "      <td>0.662198</td>\n",
       "      <td>14.284339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.672400</td>\n",
       "      <td>0.702938</td>\n",
       "      <td>0.683584</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.689072</td>\n",
       "      <td>0.672980</td>\n",
       "      <td>0.145065</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.679177</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.718158</td>\n",
       "      <td>0.641689</td>\n",
       "      <td>0.661595</td>\n",
       "      <td>14.293903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.704795</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>0.683841</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>0.663508</td>\n",
       "      <td>0.677895</td>\n",
       "      <td>0.630013</td>\n",
       "      <td>0.714237</td>\n",
       "      <td>0.646774</td>\n",
       "      <td>0.663464</td>\n",
       "      <td>14.255112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.687437</td>\n",
       "      <td>0.658507</td>\n",
       "      <td>0.755983</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.660585</td>\n",
       "      <td>0.700069</td>\n",
       "      <td>0.593427</td>\n",
       "      <td>0.758407</td>\n",
       "      <td>0.628160</td>\n",
       "      <td>0.660660</td>\n",
       "      <td>14.273706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>0.700187</td>\n",
       "      <td>0.639888</td>\n",
       "      <td>0.743395</td>\n",
       "      <td>0.662453</td>\n",
       "      <td>0.679641</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.665154</td>\n",
       "      <td>0.693144</td>\n",
       "      <td>0.616159</td>\n",
       "      <td>0.737847</td>\n",
       "      <td>0.645988</td>\n",
       "      <td>0.665116</td>\n",
       "      <td>14.257235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.679857</td>\n",
       "      <td>0.699976</td>\n",
       "      <td>0.662977</td>\n",
       "      <td>0.737672</td>\n",
       "      <td>0.667303</td>\n",
       "      <td>0.679873</td>\n",
       "      <td>0.112499</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.684668</td>\n",
       "      <td>0.618423</td>\n",
       "      <td>0.727831</td>\n",
       "      <td>0.644023</td>\n",
       "      <td>0.662827</td>\n",
       "      <td>14.267408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.820587</td>\n",
       "      <td>0.818035</td>\n",
       "      <td>0.826709</td>\n",
       "      <td>0.824608</td>\n",
       "      <td>0.829720</td>\n",
       "      <td>0.096709</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.737436</td>\n",
       "      <td>0.711402</td>\n",
       "      <td>0.747270</td>\n",
       "      <td>0.723686</td>\n",
       "      <td>0.727936</td>\n",
       "      <td>10.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.855600</td>\n",
       "      <td>0.835790</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>0.835644</td>\n",
       "      <td>0.857880</td>\n",
       "      <td>0.858193</td>\n",
       "      <td>0.082893</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.713299</td>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.720940</td>\n",
       "      <td>0.725235</td>\n",
       "      <td>10.054622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.845053</td>\n",
       "      <td>0.924046</td>\n",
       "      <td>0.851566</td>\n",
       "      <td>0.816684</td>\n",
       "      <td>0.819709</td>\n",
       "      <td>0.110525</td>\n",
       "      <td>0.729215</td>\n",
       "      <td>0.734981</td>\n",
       "      <td>0.709723</td>\n",
       "      <td>0.743290</td>\n",
       "      <td>0.724629</td>\n",
       "      <td>0.728987</td>\n",
       "      <td>10.091817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.844806</td>\n",
       "      <td>0.992863</td>\n",
       "      <td>0.850686</td>\n",
       "      <td>0.826997</td>\n",
       "      <td>0.828814</td>\n",
       "      <td>0.138156</td>\n",
       "      <td>0.726169</td>\n",
       "      <td>0.731754</td>\n",
       "      <td>0.714361</td>\n",
       "      <td>0.740036</td>\n",
       "      <td>0.722557</td>\n",
       "      <td>0.726227</td>\n",
       "      <td>10.076941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.820430</td>\n",
       "      <td>0.902109</td>\n",
       "      <td>0.822276</td>\n",
       "      <td>0.809648</td>\n",
       "      <td>0.811848</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>0.728569</td>\n",
       "      <td>0.731344</td>\n",
       "      <td>0.724327</td>\n",
       "      <td>0.736583</td>\n",
       "      <td>0.727008</td>\n",
       "      <td>0.729069</td>\n",
       "      <td>10.075348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>6</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.831146</td>\n",
       "      <td>0.774786</td>\n",
       "      <td>0.850137</td>\n",
       "      <td>0.802960</td>\n",
       "      <td>0.811292</td>\n",
       "      <td>0.131248</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>0.749069</td>\n",
       "      <td>0.692911</td>\n",
       "      <td>0.767338</td>\n",
       "      <td>0.719588</td>\n",
       "      <td>0.730370</td>\n",
       "      <td>9.955777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>0.836871</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.840272</td>\n",
       "      <td>0.818923</td>\n",
       "      <td>0.822015</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.729385</td>\n",
       "      <td>0.744733</td>\n",
       "      <td>0.699818</td>\n",
       "      <td>0.761338</td>\n",
       "      <td>0.720746</td>\n",
       "      <td>0.729624</td>\n",
       "      <td>10.039738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>0.833526</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>0.839613</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.825942</td>\n",
       "      <td>0.108551</td>\n",
       "      <td>0.728002</td>\n",
       "      <td>0.737691</td>\n",
       "      <td>0.709406</td>\n",
       "      <td>0.748510</td>\n",
       "      <td>0.722736</td>\n",
       "      <td>0.728207</td>\n",
       "      <td>10.042702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>0.814412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719471</td>\n",
       "      <td>0.736826</td>\n",
       "      <td>17.158864</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.808387</td>\n",
       "      <td>0.800369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710771</td>\n",
       "      <td>0.727591</td>\n",
       "      <td>17.266731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.733200</td>\n",
       "      <td>0.748567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760604</td>\n",
       "      <td>0.732665</td>\n",
       "      <td>0.733509</td>\n",
       "      <td>16.931300</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.733427</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.757929</td>\n",
       "      <td>0.721300</td>\n",
       "      <td>0.726380</td>\n",
       "      <td>17.309641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824319</td>\n",
       "      <td>0.726668</td>\n",
       "      <td>0.737818</td>\n",
       "      <td>16.979656</td>\n",
       "      <td>0.727262</td>\n",
       "      <td>0.773072</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.813709</td>\n",
       "      <td>0.716606</td>\n",
       "      <td>0.727192</td>\n",
       "      <td>17.304327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.777726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.741597</td>\n",
       "      <td>0.735625</td>\n",
       "      <td>17.110906</td>\n",
       "      <td>0.727154</td>\n",
       "      <td>0.752055</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.786744</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.727087</td>\n",
       "      <td>17.293700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.734400</td>\n",
       "      <td>0.770219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805790</td>\n",
       "      <td>0.725506</td>\n",
       "      <td>0.734588</td>\n",
       "      <td>17.179985</td>\n",
       "      <td>0.725523</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802022</td>\n",
       "      <td>0.715822</td>\n",
       "      <td>0.725488</td>\n",
       "      <td>17.287855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>6</td>\n",
       "      <td>0.728400</td>\n",
       "      <td>0.776371</td>\n",
       "      <td>0.821297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704654</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>16.924001</td>\n",
       "      <td>0.727862</td>\n",
       "      <td>0.784359</td>\n",
       "      <td>0.813484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709144</td>\n",
       "      <td>0.727918</td>\n",
       "      <td>17.280547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>7</td>\n",
       "      <td>0.738600</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>17.255972</td>\n",
       "      <td>0.728046</td>\n",
       "      <td>0.831545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995173</td>\n",
       "      <td>0.712434</td>\n",
       "      <td>0.728008</td>\n",
       "      <td>17.282010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cardio</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.734829</td>\n",
       "      <td>0.795424</td>\n",
       "      <td>0.947959</td>\n",
       "      <td>0.884253</td>\n",
       "      <td>0.725033</td>\n",
       "      <td>0.734873</td>\n",
       "      <td>17.077241</td>\n",
       "      <td>0.727123</td>\n",
       "      <td>0.778404</td>\n",
       "      <td>0.944748</td>\n",
       "      <td>0.879368</td>\n",
       "      <td>0.713838</td>\n",
       "      <td>0.727095</td>\n",
       "      <td>17.289259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   cardio        tree     1        0.727200         0.769610      0.657407   \n",
       "1   cardio        tree     2        0.730800         0.825455      0.771586   \n",
       "2   cardio        tree     3        0.727600         0.773550      0.721763   \n",
       "3   cardio        tree     4        0.737200         0.787893      0.746233   \n",
       "4   cardio        tree     5        0.735000         0.797519      0.734182   \n",
       "5   cardio        tree     6        0.734800         0.747525      0.731538   \n",
       "6   cardio        tree     7        0.741400         0.784314      0.714229   \n",
       "7   cardio        tree   avg        0.733429         0.783695      0.725277   \n",
       "8   cardio     log_reg     1        0.729200         0.760739      0.663446   \n",
       "9   cardio     log_reg     2        0.652000         0.661729      1.000000   \n",
       "10  cardio     log_reg     3        0.728000         0.763263      1.000000   \n",
       "11  cardio     log_reg     4        0.652800         0.668092      1.000000   \n",
       "12  cardio     log_reg     5        0.727200         0.751857      0.000000   \n",
       "13  cardio     log_reg     6        0.721600         0.749176      0.649531   \n",
       "14  cardio     log_reg     7        0.658200         0.674133      1.000000   \n",
       "15  cardio     log_reg   avg        0.695571         0.718427      0.758997   \n",
       "16  cardio  perceptron     1        0.659600         0.813711      0.937198   \n",
       "17  cardio  perceptron     2        0.538600         0.807792      1.000000   \n",
       "18  cardio  perceptron     3        0.716800         0.785208      0.000000   \n",
       "19  cardio  perceptron     4        0.533800         0.814642      0.676447   \n",
       "20  cardio  perceptron     5        0.502400         0.842105      0.000000   \n",
       "21  cardio  perceptron     6        0.709800         0.747525      0.977152   \n",
       "22  cardio  perceptron     7        0.570600         0.768566      0.730216   \n",
       "23  cardio  perceptron   avg        0.604514         0.797079      0.617288   \n",
       "24  cardio         knn     1        0.688400         0.708935      0.665862   \n",
       "25  cardio         knn     2        0.676200         0.696905      0.645212   \n",
       "26  cardio         knn     3        0.690600         0.698636      0.679260   \n",
       "27  cardio         knn     4        0.672400         0.702938      0.683584   \n",
       "28  cardio         knn     5        0.683600         0.704795      0.668524   \n",
       "29  cardio         knn     6        0.668200         0.687437      0.658507   \n",
       "30  cardio         knn     7        0.679600         0.700187      0.639888   \n",
       "31  cardio         knn   avg        0.679857         0.699976      0.662977   \n",
       "32  cardio      forest     1        0.830000         0.820587      0.818035   \n",
       "33  cardio      forest     2        0.855600         0.835790      0.845369   \n",
       "34  cardio      forest     3        0.820000         0.845053      0.924046   \n",
       "35  cardio      forest     4        0.829000         0.844806      0.992863   \n",
       "36  cardio      forest     5        0.813600         0.820430      0.902109   \n",
       "37  cardio      forest     6        0.811600         0.831146      0.774786   \n",
       "38  cardio      forest     7        0.822600         0.836871      0.920863   \n",
       "39  cardio      forest   avg        0.826057         0.833526      0.882582   \n",
       "40  cardio         svm     1        0.737200         0.805755      0.814412   \n",
       "41  cardio         svm     2        0.733200         0.748567      1.000000   \n",
       "42  cardio         svm     3        0.737000         0.785714      1.000000   \n",
       "43  cardio         svm     4        0.735000         0.777726      1.000000   \n",
       "44  cardio         svm     5        0.734400         0.770219      1.000000   \n",
       "45  cardio         svm     6        0.728400         0.776371      0.821297   \n",
       "46  cardio         svm     7        0.738600         0.903614      1.000000   \n",
       "47  cardio         svm   avg        0.734829         0.795424      0.947959   \n",
       "\n",
       "    train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0            0.814388  0.705400       0.726756        3.329554       0.718092   \n",
       "1            0.884584  0.736182       0.730678        3.377911       0.716569   \n",
       "2            0.817405  0.738914       0.728793        3.143042       0.723985   \n",
       "3            0.823245  0.724413       0.737665        3.426264       0.724569   \n",
       "4            0.807801  0.743664       0.735456        2.977256       0.726877   \n",
       "5            0.799922  0.720253       0.734063        3.315736       0.731446   \n",
       "6            0.819456  0.748012       0.741457        3.101595       0.722185   \n",
       "7            0.823829  0.730977       0.733553        3.238766       0.723389   \n",
       "8            1.000000  0.708817       0.728782       17.158864       0.726646   \n",
       "9            0.658646  0.688273       0.652064       16.938208       0.647785   \n",
       "10           0.784059  0.715838       0.728898       16.986563       0.726769   \n",
       "11           0.686844  0.669090       0.653097       17.117814       0.649785   \n",
       "12           0.771612  0.716300       0.727424       17.179985       0.725615   \n",
       "13           1.000000  0.695804       0.720215       16.930908       0.725308   \n",
       "14           0.702962  0.000000       0.658236       17.283204       0.665477   \n",
       "15           0.800589  0.599160       0.695531       17.085078       0.695341   \n",
       "16           0.652623  0.679807       0.658186       17.158864       0.658831   \n",
       "17           0.970228  0.680869       0.530236       17.600960       0.532185   \n",
       "18           0.783652  0.000000       0.718423       17.552606       0.713646   \n",
       "19           0.424536  0.689242       0.529904       16.454390       0.523138   \n",
       "20           0.966224  0.639817       0.499818       17.359189       0.499677   \n",
       "21           0.799922  0.675464       0.707998       18.243542       0.714185   \n",
       "22           0.946357  0.301020       0.570834       17.283204       0.584415   \n",
       "23           0.791935  0.523746       0.602200       17.378965       0.603725   \n",
       "24           0.748808  0.668511       0.688044        0.096709       0.662446   \n",
       "25           0.708401  0.670063       0.676807        0.096710       0.664385   \n",
       "26           0.730378  0.680570       0.691301        0.117433       0.662262   \n",
       "27           0.738095  0.689072       0.672980        0.145065       0.661662   \n",
       "28           0.738641  0.669041       0.683841        0.124341       0.663508   \n",
       "29           0.755983  0.631415       0.666500        0.131248       0.660585   \n",
       "30           0.743395  0.662453       0.679641        0.075986       0.665154   \n",
       "31           0.737672  0.667303       0.679873        0.112499       0.662857   \n",
       "32           0.826709  0.824608       0.829720        0.096709       0.727969   \n",
       "33           0.835644  0.857880       0.858193        0.082893       0.724508   \n",
       "34           0.851566  0.816684       0.819709        0.110525       0.729215   \n",
       "35           0.850686  0.826997       0.828814        0.138156       0.726169   \n",
       "36           0.822276  0.809648       0.811848        0.124341       0.728569   \n",
       "37           0.850137  0.802960       0.811292        0.131248       0.730200   \n",
       "38           0.840272  0.818923       0.822015        0.075986       0.729385   \n",
       "39           0.839613  0.822529       0.825942        0.108551       0.728002   \n",
       "40           1.000000  0.719471       0.736826       17.158864       0.727600   \n",
       "41           0.760604  0.732665       0.733509       16.931300       0.726415   \n",
       "42           0.824319  0.726668       0.737818       16.979656       0.727262   \n",
       "43           0.802260  0.741597       0.735625       17.110906       0.727154   \n",
       "44           0.805790  0.725506       0.734588       17.179985       0.725523   \n",
       "45           1.000000  0.704654       0.727103       16.924001       0.727862   \n",
       "46           0.996797  0.724668       0.738641       17.255972       0.728046   \n",
       "47           0.884253  0.725033       0.734873       17.077241       0.727123   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0         0.760048     0.651762          0.803292  0.698032      0.718082   \n",
       "1         0.823521     0.757578          0.888329  0.717287      0.716578   \n",
       "2         0.753861     0.691226          0.803083  0.711474      0.723870   \n",
       "3         0.761494     0.689836          0.797068  0.713895      0.724521   \n",
       "4         0.775533     0.706000          0.803805  0.711856      0.726788   \n",
       "5         0.761724     0.672682          0.804416  0.720963      0.731479   \n",
       "6         0.772991     0.658558          0.811395  0.695597      0.722577   \n",
       "7         0.772739     0.689663          0.815913  0.709872      0.723414   \n",
       "8         0.757817     0.665702          1.000000  0.708874      0.726637   \n",
       "9         0.649235     1.000000          0.661212  0.681556      0.647767   \n",
       "10        0.747150     1.000000          0.769117  0.714479      0.726690   \n",
       "11        0.656718     1.000000          0.673785  0.669713      0.649753   \n",
       "12        0.744387     0.000000          0.764154  0.713106      0.725577   \n",
       "13        0.759396     0.660293          1.000000  0.706385      0.725364   \n",
       "14        0.679728     1.000000          0.705962  0.000000      0.665448   \n",
       "15        0.713490     0.760856          0.796319  0.599159      0.695319   \n",
       "16        0.820899     0.930943          0.645531  0.682359      0.658796   \n",
       "17        0.827289     1.000000          0.975099  0.674746      0.533118   \n",
       "18        0.765788     0.000000          0.764572  0.000000      0.713475   \n",
       "19        0.806657     0.686447          0.411917  0.687096      0.523739   \n",
       "20        0.823896     0.000000          0.962624  0.655747      0.500197   \n",
       "21        0.761628     0.981616          0.804293  0.686119      0.714262   \n",
       "22        0.765193     0.712289          0.945946  0.308886      0.584213   \n",
       "23        0.795907     0.615899          0.787140  0.527850      0.603971   \n",
       "24        0.682355     0.608432          0.749792  0.642847      0.662438   \n",
       "25        0.674974     0.631371          0.696583  0.652445      0.664315   \n",
       "26        0.685064     0.629046          0.719796  0.650257      0.662198   \n",
       "27        0.679177     0.620513          0.718158  0.641689      0.661595   \n",
       "28        0.677895     0.630013          0.714237  0.646774      0.663464   \n",
       "29        0.700069     0.593427          0.758407  0.628160      0.660660   \n",
       "30        0.693144     0.616159          0.737847  0.645988      0.665116   \n",
       "31        0.684668     0.618423          0.727831  0.644023      0.662827   \n",
       "32        0.737436     0.711402          0.747270  0.723686      0.727936   \n",
       "33        0.734523     0.713299          0.743713  0.720940      0.725235   \n",
       "34        0.734981     0.709723          0.743290  0.724629      0.728987   \n",
       "35        0.731754     0.714361          0.740036  0.722557      0.726227   \n",
       "36        0.731344     0.724327          0.736583  0.727008      0.729069   \n",
       "37        0.749069     0.692911          0.767338  0.719588      0.730370   \n",
       "38        0.744733     0.699818          0.761338  0.720746      0.729624   \n",
       "39        0.737691     0.709406          0.748510  0.722736      0.728207   \n",
       "40        0.808387     0.800369          1.000000  0.710771      0.727591   \n",
       "41        0.733427     0.999784          0.757929  0.721300      0.726380   \n",
       "42        0.773072     0.999630          0.813709  0.716606      0.727192   \n",
       "43        0.752055     0.999969          0.786744  0.710793      0.727087   \n",
       "44        0.765986     1.000000          0.802022  0.715822      0.725488   \n",
       "45        0.784359     0.813484          1.000000  0.709144      0.727918   \n",
       "46        0.831545     1.000000          0.995173  0.712434      0.728008   \n",
       "47        0.778404     0.944748          0.879368  0.713838      0.727095   \n",
       "\n",
       "    test_log_loss  \n",
       "0       12.502100  \n",
       "1       12.549928  \n",
       "2       12.463843  \n",
       "3       12.273081  \n",
       "4       12.826238  \n",
       "5       12.584985  \n",
       "6       12.450020  \n",
       "7       12.521457  \n",
       "8       17.266731  \n",
       "9       17.306453  \n",
       "10      17.302733  \n",
       "11      17.292637  \n",
       "12      17.287855  \n",
       "13      17.284266  \n",
       "14      17.257167  \n",
       "15      17.285406  \n",
       "16      17.266731  \n",
       "17      17.232724  \n",
       "18      17.236444  \n",
       "19      16.344931  \n",
       "20      17.251322  \n",
       "21      17.966164  \n",
       "22      17.257167  \n",
       "23      17.222212  \n",
       "24      14.255107  \n",
       "25      14.252454  \n",
       "26      14.284339  \n",
       "27      14.293903  \n",
       "28      14.255112  \n",
       "29      14.273706  \n",
       "30      14.257235  \n",
       "31      14.267408  \n",
       "32      10.004671  \n",
       "33      10.054622  \n",
       "34      10.091817  \n",
       "35      10.076941  \n",
       "36      10.075348  \n",
       "37       9.955777  \n",
       "38      10.039738  \n",
       "39      10.042702  \n",
       "40      17.266731  \n",
       "41      17.309641  \n",
       "42      17.304327  \n",
       "43      17.293700  \n",
       "44      17.287855  \n",
       "45      17.280547  \n",
       "46      17.282010  \n",
       "47      17.289259  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/cardio_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Australian Rain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.85   0.8492 0.8484 0.8476 0.8488 0.8488 0.848 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.77078197 0.76847984 0.76417492 0.75953388 0.76707169\n",
      " 0.77282843 0.77207898]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.41957215 0.41580742 0.41487731 0.41393835 0.41486403\n",
      " 0.40921694 0.4045221 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.96621882 0.9662185  0.96545643 0.96469501 0.96596502\n",
      " 0.96748818 0.96774199]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.54317007 0.5395262  0.53760203 0.53552029 0.53838741\n",
      " 0.53495496 0.5307424 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.69289549 0.69101296 0.69016687 0.68931668 0.69041452\n",
      " 0.68835256 0.68613204]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 5.18083773 5.20846875 5.23610025 5.26373175 5.22228442\n",
      " 5.22228346 5.24991432]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.852  0.8524 0.8514 0.8496 0.8506 0.8494 0.849 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.7823224  0.78499371 0.78099866 0.77447377 0.77724464\n",
      " 0.77497655 0.78039805]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.45545455 0.45545455 0.45363636 0.44818182 0.45181818\n",
      " 0.44636364 0.43818182]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.96384615 0.96435897 0.96358974 0.96282051 0.96307692\n",
      " 0.96307692 0.96487179]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.57513264 0.57590409 0.57318264 0.56715967 0.57083811\n",
      " 0.5659159  0.56063584]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70965035 0.70990676 0.70861305 0.70550117 0.70744755\n",
      " 0.70472028 0.70152681]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 5.11176146 5.09794562 5.13248488 5.19465516 5.16011622\n",
      " 5.20156275 5.21537714]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8416 0.8408 0.8424 0.842  0.8406 0.8408 0.8416]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.74541461 0.7419427  0.74676226 0.74633012 0.74178147\n",
      " 0.74481347 0.75098865]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.39970284 0.39877692 0.40434539 0.40248923 0.39690353\n",
      " 0.39597761 0.39411714]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.96279312 0.96202944 0.96253802 0.96253867 0.96228357\n",
      " 0.9627928  0.96432179]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.51859996 0.51694399 0.52308851 0.5209391  0.51585833\n",
      " 0.51566134 0.51539945]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.68124798 0.68040318 0.68344171 0.68251395 0.67959355\n",
      " 0.6793852  0.67921946]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 5.47096553 5.49859703 5.44333467 5.45715018 5.50550463\n",
      " 5.49859655 5.47096457]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8446 0.8458 0.8456 0.8462 0.8462 0.8458 0.8454]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.76745731 0.77148249 0.76921997 0.77385103 0.77679943\n",
      " 0.77640566 0.77869872]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.45169322 0.45701082 0.45612586 0.45522911 0.45257424\n",
      " 0.45081219 0.4472645 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.95918713 0.9591878  0.9591868  0.96022072 0.96099558\n",
      " 0.96099525 0.96151238]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.56704707 0.57189414 0.57117806 0.57181823 0.57027965\n",
      " 0.56853344 0.56619252]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70544017 0.70809931 0.70765633 0.70772491 0.70678491\n",
      " 0.70590372 0.70438844]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 5.36735112 5.32590459 5.33281234 5.31208844 5.31208796\n",
      " 5.32590347 5.33971866]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8496 0.8466 0.8484 0.848  0.8486 0.848  0.8494]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.77152588 0.76234394 0.77047328 0.77058279 0.77082221\n",
      " 0.77434258 0.78001521]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.4632247  0.45335922 0.45694266 0.45426009 0.45784753\n",
      " 0.44978379 0.45337524]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.9606088  0.95957821 0.9608672  0.96112294 0.9608662\n",
      " 0.96241127 0.96318314]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.57833168 0.56798063 0.57289324 0.57082712 0.57380873\n",
      " 0.56859129 0.5728229 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.71191675 0.70646872 0.70890493 0.70769152 0.70935687\n",
      " 0.70609753 0.70827919]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 5.19465644 5.29827341 5.23610281 5.24991816 5.22919505\n",
      " 5.24991736 5.20156259]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8512 0.8508 0.8504 0.8494 0.8526 0.852  0.85  ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.75652198 0.76075047 0.75905053 0.75302406 0.77044582\n",
      " 0.76996873 0.76524748]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.44953271 0.44205607 0.4411215  0.4411215  0.44392523\n",
      " 0.44018692 0.4317757 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.9605598  0.96208651 0.96183206 0.9605598  0.96386768\n",
      " 0.96412214 0.96386768]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.56377245 0.55885265 0.55762946 0.55595726 0.56286741\n",
      " 0.55988356 0.55158775]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70504625 0.70207129 0.70147678 0.70084065 0.70389646\n",
      " 0.70215453 0.69782169]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 5.13939472 5.15320927 5.16702494 5.20156451 5.09103835\n",
      " 5.11176146 5.18083917]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan 0.8378 0.8384 0.838  0.8386 0.838  0.8382 0.8374]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.73272994 0.73577455 0.73418    0.73469899 0.73681262\n",
      " 0.7402196  0.7397975 ]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.41503908 0.41503085 0.41412587 0.41775812 0.41049774\n",
      " 0.40777046 0.40323735]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.95716895 0.95793851 0.95768177 0.95742536 0.95870742\n",
      " 0.95973339 0.95999013]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.52929984 0.53016198 0.52884267 0.53197703 0.52668\n",
      " 0.52520984 0.52145675]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.68610402 0.68648468 0.68590382 0.68759174 0.68460258\n",
      " 0.68375193 0.68161374]\n",
      "  category=UserWarning\n",
      "C:\\Users\\panyu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 5.60221624 5.58149249 5.59530816 5.57458506 5.59530752\n",
      " 5.58839913 5.61602999]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849200</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.634995</td>\n",
       "      <td>0.982220</td>\n",
       "      <td>0.577857</td>\n",
       "      <td>0.793885</td>\n",
       "      <td>1.768402e+00</td>\n",
       "      <td>0.832130</td>\n",
       "      <td>0.793374</td>\n",
       "      <td>0.454306</td>\n",
       "      <td>0.981741</td>\n",
       "      <td>0.514792</td>\n",
       "      <td>0.680295</td>\n",
       "      <td>7.417087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853400</td>\n",
       "      <td>0.777567</td>\n",
       "      <td>0.864545</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.595251</td>\n",
       "      <td>0.722949</td>\n",
       "      <td>1.733863e+00</td>\n",
       "      <td>0.829382</td>\n",
       "      <td>0.734551</td>\n",
       "      <td>0.487182</td>\n",
       "      <td>0.965026</td>\n",
       "      <td>0.528443</td>\n",
       "      <td>0.687990</td>\n",
       "      <td>7.434552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842400</td>\n",
       "      <td>0.784884</td>\n",
       "      <td>0.860595</td>\n",
       "      <td>0.981142</td>\n",
       "      <td>0.559152</td>\n",
       "      <td>0.799772</td>\n",
       "      <td>1.733862e+00</td>\n",
       "      <td>0.828926</td>\n",
       "      <td>0.780864</td>\n",
       "      <td>0.467777</td>\n",
       "      <td>0.978989</td>\n",
       "      <td>0.524279</td>\n",
       "      <td>0.680138</td>\n",
       "      <td>7.590942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.853800</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.713906</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>0.623390</td>\n",
       "      <td>0.741199</td>\n",
       "      <td>1.125968e+00</td>\n",
       "      <td>0.828435</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.492878</td>\n",
       "      <td>0.983840</td>\n",
       "      <td>0.539103</td>\n",
       "      <td>0.695147</td>\n",
       "      <td>7.276675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.862200</td>\n",
       "      <td>0.838608</td>\n",
       "      <td>0.879928</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.703435</td>\n",
       "      <td>0.796881</td>\n",
       "      <td>1.637154e+00</td>\n",
       "      <td>0.829895</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.503917</td>\n",
       "      <td>0.983756</td>\n",
       "      <td>0.541967</td>\n",
       "      <td>0.702007</td>\n",
       "      <td>7.460127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.772182</td>\n",
       "      <td>0.715888</td>\n",
       "      <td>0.975827</td>\n",
       "      <td>0.656448</td>\n",
       "      <td>0.764614</td>\n",
       "      <td>1.699321e+00</td>\n",
       "      <td>0.823978</td>\n",
       "      <td>0.768040</td>\n",
       "      <td>0.463466</td>\n",
       "      <td>0.976079</td>\n",
       "      <td>0.544421</td>\n",
       "      <td>0.699465</td>\n",
       "      <td>7.465532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>0.838800</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.849228</td>\n",
       "      <td>0.969223</td>\n",
       "      <td>0.697723</td>\n",
       "      <td>0.793170</td>\n",
       "      <td>1.678599e+00</td>\n",
       "      <td>0.833198</td>\n",
       "      <td>0.735950</td>\n",
       "      <td>0.481284</td>\n",
       "      <td>0.962520</td>\n",
       "      <td>0.517844</td>\n",
       "      <td>0.690402</td>\n",
       "      <td>7.350698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.850943</td>\n",
       "      <td>0.796067</td>\n",
       "      <td>0.788441</td>\n",
       "      <td>0.978540</td>\n",
       "      <td>0.630465</td>\n",
       "      <td>0.773210</td>\n",
       "      <td>1.625310e+00</td>\n",
       "      <td>0.829421</td>\n",
       "      <td>0.773609</td>\n",
       "      <td>0.478687</td>\n",
       "      <td>0.975993</td>\n",
       "      <td>0.530121</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>7.427945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853600</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.493885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592217</td>\n",
       "      <td>0.723448</td>\n",
       "      <td>7.336036e+00</td>\n",
       "      <td>0.844789</td>\n",
       "      <td>0.822835</td>\n",
       "      <td>0.466541</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.568289</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>7.570941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854600</td>\n",
       "      <td>0.852665</td>\n",
       "      <td>0.532727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614256</td>\n",
       "      <td>0.737902</td>\n",
       "      <td>7.584715e+00</td>\n",
       "      <td>0.842987</td>\n",
       "      <td>0.798050</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.584528</td>\n",
       "      <td>0.721091</td>\n",
       "      <td>7.559876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.826568</td>\n",
       "      <td>0.504647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.594417</td>\n",
       "      <td>0.725820</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.841407</td>\n",
       "      <td>0.820193</td>\n",
       "      <td>0.493620</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.577177</td>\n",
       "      <td>0.716357</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>0.824607</td>\n",
       "      <td>0.534101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618462</td>\n",
       "      <td>0.738892</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.843585</td>\n",
       "      <td>0.791807</td>\n",
       "      <td>0.500585</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.583539</td>\n",
       "      <td>0.720150</td>\n",
       "      <td>7.549794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.852400</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615465</td>\n",
       "      <td>0.736984</td>\n",
       "      <td>7.709055e+00</td>\n",
       "      <td>0.843308</td>\n",
       "      <td>0.790676</td>\n",
       "      <td>0.496245</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.582311</td>\n",
       "      <td>0.718938</td>\n",
       "      <td>7.564056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>6</td>\n",
       "      <td>0.853600</td>\n",
       "      <td>0.783607</td>\n",
       "      <td>0.512150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606530</td>\n",
       "      <td>0.732029</td>\n",
       "      <td>7.377483e+00</td>\n",
       "      <td>0.843115</td>\n",
       "      <td>0.821836</td>\n",
       "      <td>0.485052</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.579321</td>\n",
       "      <td>0.715906</td>\n",
       "      <td>7.566023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.847800</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.498638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.590640</td>\n",
       "      <td>0.722517</td>\n",
       "      <td>7.598531e+00</td>\n",
       "      <td>0.843343</td>\n",
       "      <td>0.804531</td>\n",
       "      <td>0.491584</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>0.716813</td>\n",
       "      <td>7.562335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.852143</td>\n",
       "      <td>0.811858</td>\n",
       "      <td>0.514846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604569</td>\n",
       "      <td>0.731085</td>\n",
       "      <td>7.548203e+00</td>\n",
       "      <td>0.843219</td>\n",
       "      <td>0.807133</td>\n",
       "      <td>0.491110</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.579162</td>\n",
       "      <td>0.716840</td>\n",
       "      <td>7.563845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.576074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.515593</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.472579e+00</td>\n",
       "      <td>0.808066</td>\n",
       "      <td>0.581878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504020</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.780639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.825200</td>\n",
       "      <td>0.704710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958205</td>\n",
       "      <td>0.417767</td>\n",
       "      <td>0.608648</td>\n",
       "      <td>2.694087e+01</td>\n",
       "      <td>0.819500</td>\n",
       "      <td>0.668720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951451</td>\n",
       "      <td>0.416190</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>26.971410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.784800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.780713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563072</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.781091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556308</td>\n",
       "      <td>7.560859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552980</td>\n",
       "      <td>0.759433</td>\n",
       "      <td>7.709055e+00</td>\n",
       "      <td>0.219002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544798</td>\n",
       "      <td>0.759386</td>\n",
       "      <td>7.564056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>6</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.885047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.352554</td>\n",
       "      <td>0.758681</td>\n",
       "      <td>7.391298e+00</td>\n",
       "      <td>0.780671</td>\n",
       "      <td>0.219329</td>\n",
       "      <td>0.870192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359754</td>\n",
       "      <td>0.750847</td>\n",
       "      <td>7.575367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>7</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507093</td>\n",
       "      <td>0.716482</td>\n",
       "      <td>7.605439e+00</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513731</td>\n",
       "      <td>0.724962</td>\n",
       "      <td>7.567744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.632457</td>\n",
       "      <td>0.244998</td>\n",
       "      <td>0.376179</td>\n",
       "      <td>0.708315</td>\n",
       "      <td>0.335141</td>\n",
       "      <td>0.629474</td>\n",
       "      <td>1.019298e+01</td>\n",
       "      <td>0.629736</td>\n",
       "      <td>0.241291</td>\n",
       "      <td>0.374365</td>\n",
       "      <td>0.707350</td>\n",
       "      <td>0.334070</td>\n",
       "      <td>0.628555</td>\n",
       "      <td>10.227710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848400</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.815520</td>\n",
       "      <td>0.882158</td>\n",
       "      <td>0.410073</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.441787</td>\n",
       "      <td>0.642317</td>\n",
       "      <td>8.104128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.817179</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.430419</td>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.457014</td>\n",
       "      <td>0.651626</td>\n",
       "      <td>7.979461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.846200</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.815677</td>\n",
       "      <td>0.876491</td>\n",
       "      <td>0.419207</td>\n",
       "      <td>0.998878</td>\n",
       "      <td>0.448108</td>\n",
       "      <td>0.646152</td>\n",
       "      <td>7.995934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.847600</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.819158</td>\n",
       "      <td>0.840574</td>\n",
       "      <td>0.426532</td>\n",
       "      <td>0.996254</td>\n",
       "      <td>0.451479</td>\n",
       "      <td>0.648392</td>\n",
       "      <td>7.959296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.818297</td>\n",
       "      <td>0.870986</td>\n",
       "      <td>0.424954</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>0.452373</td>\n",
       "      <td>0.648848</td>\n",
       "      <td>7.930279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.816047</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.407180</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.439485</td>\n",
       "      <td>0.640965</td>\n",
       "      <td>8.002326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.840600</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.817599</td>\n",
       "      <td>0.852248</td>\n",
       "      <td>0.423934</td>\n",
       "      <td>0.997484</td>\n",
       "      <td>0.447889</td>\n",
       "      <td>0.646155</td>\n",
       "      <td>8.077575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.885504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.817068</td>\n",
       "      <td>0.867393</td>\n",
       "      <td>0.420328</td>\n",
       "      <td>0.998044</td>\n",
       "      <td>0.448305</td>\n",
       "      <td>0.646351</td>\n",
       "      <td>8.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.347013e+00</td>\n",
       "      <td>0.842809</td>\n",
       "      <td>0.767281</td>\n",
       "      <td>0.409359</td>\n",
       "      <td>0.966775</td>\n",
       "      <td>0.531908</td>\n",
       "      <td>0.687379</td>\n",
       "      <td>5.447391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992821</td>\n",
       "      <td>0.995892</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>2.756199e+00</td>\n",
       "      <td>0.844354</td>\n",
       "      <td>0.738856</td>\n",
       "      <td>0.447055</td>\n",
       "      <td>0.957268</td>\n",
       "      <td>0.558036</td>\n",
       "      <td>0.701914</td>\n",
       "      <td>5.390840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.915428</td>\n",
       "      <td>0.994139</td>\n",
       "      <td>0.955889</td>\n",
       "      <td>0.958643</td>\n",
       "      <td>1.934173e+00</td>\n",
       "      <td>0.843699</td>\n",
       "      <td>0.758192</td>\n",
       "      <td>0.428330</td>\n",
       "      <td>0.962174</td>\n",
       "      <td>0.547116</td>\n",
       "      <td>0.694920</td>\n",
       "      <td>5.403624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966400</td>\n",
       "      <td>0.963151</td>\n",
       "      <td>0.982285</td>\n",
       "      <td>0.993283</td>\n",
       "      <td>0.992864</td>\n",
       "      <td>0.991585</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.843735</td>\n",
       "      <td>0.752891</td>\n",
       "      <td>0.430792</td>\n",
       "      <td>0.960843</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.694745</td>\n",
       "      <td>5.403625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.598531e-02</td>\n",
       "      <td>0.844611</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.444101</td>\n",
       "      <td>0.957930</td>\n",
       "      <td>0.556473</td>\n",
       "      <td>0.700659</td>\n",
       "      <td>5.366496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946600</td>\n",
       "      <td>0.987775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.222673e+00</td>\n",
       "      <td>0.842653</td>\n",
       "      <td>0.755188</td>\n",
       "      <td>0.422761</td>\n",
       "      <td>0.962764</td>\n",
       "      <td>0.540838</td>\n",
       "      <td>0.691324</td>\n",
       "      <td>5.437557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.966200</td>\n",
       "      <td>0.977632</td>\n",
       "      <td>0.844687</td>\n",
       "      <td>0.994614</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>0.922669</td>\n",
       "      <td>2.928892e+00</td>\n",
       "      <td>0.843657</td>\n",
       "      <td>0.755408</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>0.962875</td>\n",
       "      <td>0.544035</td>\n",
       "      <td>0.693391</td>\n",
       "      <td>5.427721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.979914</td>\n",
       "      <td>0.975424</td>\n",
       "      <td>0.963200</td>\n",
       "      <td>0.993414</td>\n",
       "      <td>0.980076</td>\n",
       "      <td>0.981193</td>\n",
       "      <td>1.466419e+00</td>\n",
       "      <td>0.843645</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.429885</td>\n",
       "      <td>0.961518</td>\n",
       "      <td>0.546172</td>\n",
       "      <td>0.694904</td>\n",
       "      <td>5.411036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0      aus        tree     1        0.849200         0.800000      0.634995   \n",
       "1      aus        tree     2        0.853400         0.777567      0.864545   \n",
       "2      aus        tree     3        0.842400         0.784884      0.860595   \n",
       "3      aus        tree     4        0.853800         0.823529      0.713906   \n",
       "4      aus        tree     5        0.862200         0.838608      0.879928   \n",
       "5      aus        tree     6        0.856800         0.772182      0.715888   \n",
       "6      aus        tree     7        0.838800         0.775701      0.849228   \n",
       "7      aus        tree   avg        0.850943         0.796067      0.788441   \n",
       "8      aus     log_reg     1        0.853600         0.788591      0.493885   \n",
       "9      aus     log_reg     2        0.854600         0.852665      0.532727   \n",
       "10     aus     log_reg     3        0.851800         0.826568      0.504647   \n",
       "11     aus     log_reg     4        0.851200         0.824607      0.534101   \n",
       "12     aus     log_reg     5        0.852400         0.808333      0.527778   \n",
       "13     aus     log_reg     6        0.853600         0.783607      0.512150   \n",
       "14     aus     log_reg     7        0.847800         0.798635      0.498638   \n",
       "15     aus     log_reg   avg        0.852143         0.811858      0.514846   \n",
       "16     aus  perceptron     1        0.813600         0.576074      0.000000   \n",
       "17     aus  perceptron     2        0.825200         0.704710      1.000000   \n",
       "18     aus  perceptron     3        0.784800         0.000000      0.000000   \n",
       "19     aus  perceptron     4        0.774200         0.000000      0.000000   \n",
       "20     aus  perceptron     5        0.223200         0.000000      0.748208   \n",
       "21     aus  perceptron     6        0.786000         0.214000      0.885047   \n",
       "22     aus  perceptron     7        0.220200         0.220200      0.000000   \n",
       "23     aus  perceptron   avg        0.632457         0.244998      0.376179   \n",
       "24     aus         knn     1        0.848400         0.862745      1.000000   \n",
       "25     aus         knn     2        0.834600         0.938776      1.000000   \n",
       "26     aus         knn     3        0.846200         0.869565      1.000000   \n",
       "27     aus         knn     4        0.847600         0.872549      1.000000   \n",
       "28     aus         knn     5        0.834600         0.910828      1.000000   \n",
       "29     aus         knn     6        0.844000         0.901961      1.000000   \n",
       "30     aus         knn     7        0.840600         0.842105      1.000000   \n",
       "31     aus         knn   avg        0.842286         0.885504      1.000000   \n",
       "32     aus      forest     1        1.000000         0.973298      1.000000   \n",
       "33     aus      forest     2        0.998200         1.000000      1.000000   \n",
       "34     aus      forest     3        0.982000         0.970588      0.915428   \n",
       "35     aus      forest     4        0.966400         0.963151      0.982285   \n",
       "36     aus      forest     5        1.000000         0.955527      1.000000   \n",
       "37     aus      forest     6        0.946600         0.987775      1.000000   \n",
       "38     aus      forest     7        0.966200         0.977632      0.844687   \n",
       "39     aus      forest   avg        0.979914         0.975424      0.963200   \n",
       "\n",
       "    train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0            0.982220  0.577857       0.793885    1.768402e+00       0.832130   \n",
       "1            0.970000  0.595251       0.722949    1.733863e+00       0.829382   \n",
       "2            0.981142  0.559152       0.799772    1.733862e+00       0.828926   \n",
       "3            0.984500  0.623390       0.741199    1.125968e+00       0.828435   \n",
       "4            0.986869  0.703435       0.796881    1.637154e+00       0.829895   \n",
       "5            0.975827  0.656448       0.764614    1.699321e+00       0.823978   \n",
       "6            0.969223  0.697723       0.793170    1.678599e+00       0.833198   \n",
       "7            0.978540  0.630465       0.773210    1.625310e+00       0.829421   \n",
       "8            1.000000  0.592217       0.723448    7.336036e+00       0.844789   \n",
       "9            1.000000  0.614256       0.737902    7.584715e+00       0.842987   \n",
       "10           1.000000  0.594417       0.725820    7.432745e+00       0.841407   \n",
       "11           1.000000  0.618462       0.738892    7.798856e+00       0.843585   \n",
       "12           1.000000  0.615465       0.736984    7.709055e+00       0.843308   \n",
       "13           1.000000  0.606530       0.732029    7.377483e+00       0.843115   \n",
       "14           1.000000  0.590640       0.722517    7.598531e+00       0.843343   \n",
       "15           1.000000  0.604569       0.731085    7.548203e+00       0.843219   \n",
       "16           1.000000  0.515593       0.500000    6.472579e+00       0.808066   \n",
       "17           0.958205  0.417767       0.608648    2.694087e+01       0.819500   \n",
       "18           1.000000  0.000000       0.500000    7.432745e+00       0.780713   \n",
       "19           1.000000  0.000000       0.563072    7.798856e+00       0.781091   \n",
       "20           0.000000  0.552980       0.759433    7.709055e+00       0.219002   \n",
       "21           1.000000  0.352554       0.758681    7.391298e+00       0.780671   \n",
       "22           0.000000  0.507093       0.716482    7.605439e+00       0.219109   \n",
       "23           0.708315  0.335141       0.629474    1.019298e+01       0.629736   \n",
       "24           0.998222  1.000000       1.000000    9.992007e-16       0.815520   \n",
       "25           0.999231  1.000000       1.000000    9.992007e-16       0.817179   \n",
       "26           0.998981  1.000000       1.000000    9.992007e-16       0.815677   \n",
       "27           0.996642  1.000000       1.000000    9.992007e-16       0.819158   \n",
       "28           0.997683  1.000000       1.000000    9.992007e-16       0.818297   \n",
       "29           0.998728  1.000000       1.000000    9.992007e-16       0.816047   \n",
       "30           0.997692  1.000000       1.000000    9.992007e-16       0.817599   \n",
       "31           0.998168  1.000000       1.000000    9.992007e-16       0.817068   \n",
       "32           0.993650  1.000000       1.000000    1.347013e+00       0.842809   \n",
       "33           0.992821  0.995892       0.995455    2.756199e+00       0.844354   \n",
       "34           0.994139  0.955889       0.958643    1.934173e+00       0.843699   \n",
       "35           0.993283  0.992864       0.991585    9.992007e-16       0.843735   \n",
       "36           0.991246  1.000000       1.000000    7.598531e-02       0.844611   \n",
       "37           0.994148  1.000000       1.000000    1.222673e+00       0.842653   \n",
       "38           0.994614  0.915888       0.922669    2.928892e+00       0.843657   \n",
       "39           0.993414  0.980076       0.981193    1.466419e+00       0.843645   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0         0.793374     0.454306          0.981741  0.514792      0.680295   \n",
       "1         0.734551     0.487182          0.965026  0.528443      0.687990   \n",
       "2         0.780864     0.467777          0.978989  0.524279      0.680138   \n",
       "3         0.801478     0.492878          0.983840  0.539103      0.695147   \n",
       "4         0.801005     0.503917          0.983756  0.541967      0.702007   \n",
       "5         0.768040     0.463466          0.976079  0.544421      0.699465   \n",
       "6         0.735950     0.481284          0.962520  0.517844      0.690402   \n",
       "7         0.773609     0.478687          0.975993  0.530121      0.690778   \n",
       "8         0.822835     0.466541          0.999991  0.568289      0.708628   \n",
       "9         0.798050     0.504143          0.999991  0.584528      0.721091   \n",
       "10        0.820193     0.493620          0.999991  0.577177      0.716357   \n",
       "11        0.791807     0.500585          0.999991  0.583539      0.720150   \n",
       "12        0.790676     0.496245          0.999982  0.582311      0.718938   \n",
       "13        0.821836     0.485052          0.999982  0.579321      0.715906   \n",
       "14        0.804531     0.491584          0.999991  0.578968      0.716813   \n",
       "15        0.807133     0.491110          0.999988  0.579162      0.716840   \n",
       "16        0.581878     0.000000          1.000000  0.504020      0.500000   \n",
       "17        0.668720     1.000000          0.951451  0.416190      0.608385   \n",
       "18        0.000000     0.000000          1.000000  0.000000      0.500000   \n",
       "19        0.000000     0.000000          1.000000  0.000000      0.556308   \n",
       "20        0.000000     0.750366          0.000000  0.544798      0.759386   \n",
       "21        0.219329     0.870192          1.000000  0.359754      0.750847   \n",
       "22        0.219109     0.000000          0.000000  0.513731      0.724962   \n",
       "23        0.241291     0.374365          0.707350  0.334070      0.628555   \n",
       "24        0.882158     0.410073          0.998778  0.441787      0.642317   \n",
       "25        0.891667     0.430419          0.998578  0.457014      0.651626   \n",
       "26        0.876491     0.419207          0.998878  0.448108      0.646152   \n",
       "27        0.840574     0.426532          0.996254  0.451479      0.648392   \n",
       "28        0.870986     0.424954          0.997867  0.452373      0.648848   \n",
       "29        0.857627     0.407180          0.998468  0.439485      0.640965   \n",
       "30        0.852248     0.423934          0.997484  0.447889      0.646155   \n",
       "31        0.867393     0.420328          0.998044  0.448305      0.646351   \n",
       "32        0.767281     0.409359          0.966775  0.531908      0.687379   \n",
       "33        0.738856     0.447055          0.957268  0.558036      0.701914   \n",
       "34        0.758192     0.428330          0.962174  0.547116      0.694920   \n",
       "35        0.752891     0.430792          0.960843  0.544797      0.694745   \n",
       "36        0.745518     0.444101          0.957930  0.556473      0.700659   \n",
       "37        0.755188     0.422761          0.962764  0.540838      0.691324   \n",
       "38        0.755408     0.426794          0.962875  0.544035      0.693391   \n",
       "39        0.753333     0.429885          0.961518  0.546172      0.694904   \n",
       "\n",
       "    test_log_loss  \n",
       "0        7.417087  \n",
       "1        7.434552  \n",
       "2        7.590942  \n",
       "3        7.276675  \n",
       "4        7.460127  \n",
       "5        7.465532  \n",
       "6        7.350698  \n",
       "7        7.427945  \n",
       "8        7.570941  \n",
       "9        7.559876  \n",
       "10       7.573892  \n",
       "11       7.549794  \n",
       "12       7.564056  \n",
       "13       7.566023  \n",
       "14       7.562335  \n",
       "15       7.563845  \n",
       "16       6.780639  \n",
       "17      26.971410  \n",
       "18       7.573892  \n",
       "19       7.560859  \n",
       "20       7.564056  \n",
       "21       7.575367  \n",
       "22       7.567744  \n",
       "23      10.227710  \n",
       "24       8.104128  \n",
       "25       7.979461  \n",
       "26       7.995934  \n",
       "27       7.959296  \n",
       "28       7.930279  \n",
       "29       8.002326  \n",
       "30       8.077575  \n",
       "31       8.007000  \n",
       "32       5.447391  \n",
       "33       5.390840  \n",
       "34       5.403624  \n",
       "35       5.403625  \n",
       "36       5.366496  \n",
       "37       5.437557  \n",
       "38       5.427721  \n",
       "39       5.411036  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on Australian rain dataset\n",
    "aus_results_no_svm = perform_trials('aus', models_without_svm, aus_X, aus_y)\n",
    "aus_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857600</td>\n",
       "      <td>0.808743</td>\n",
       "      <td>0.484478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.719694</td>\n",
       "      <td>7.342944</td>\n",
       "      <td>0.845016</td>\n",
       "      <td>0.842434</td>\n",
       "      <td>0.458103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.552106</td>\n",
       "      <td>0.697773</td>\n",
       "      <td>7.577089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.859000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.619383</td>\n",
       "      <td>0.737564</td>\n",
       "      <td>7.598531</td>\n",
       "      <td>0.842510</td>\n",
       "      <td>0.879286</td>\n",
       "      <td>0.472528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.574432</td>\n",
       "      <td>0.713079</td>\n",
       "      <td>7.567990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.853400</td>\n",
       "      <td>0.861272</td>\n",
       "      <td>0.471190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572881</td>\n",
       "      <td>0.711767</td>\n",
       "      <td>7.432745</td>\n",
       "      <td>0.843343</td>\n",
       "      <td>0.860588</td>\n",
       "      <td>0.467550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.561399</td>\n",
       "      <td>0.705952</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>0.895161</td>\n",
       "      <td>0.719221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.851731</td>\n",
       "      <td>7.798856</td>\n",
       "      <td>0.843429</td>\n",
       "      <td>0.869990</td>\n",
       "      <td>0.478763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.561484</td>\n",
       "      <td>0.707630</td>\n",
       "      <td>7.560859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.855200</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.511649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.602321</td>\n",
       "      <td>0.728919</td>\n",
       "      <td>7.709055</td>\n",
       "      <td>0.844867</td>\n",
       "      <td>0.854671</td>\n",
       "      <td>0.480836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569531</td>\n",
       "      <td>0.711297</td>\n",
       "      <td>7.564056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>6</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.490654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.590551</td>\n",
       "      <td>0.722045</td>\n",
       "      <td>7.391298</td>\n",
       "      <td>0.845180</td>\n",
       "      <td>0.902718</td>\n",
       "      <td>0.460610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557750</td>\n",
       "      <td>0.703466</td>\n",
       "      <td>7.575367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>7</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.854460</td>\n",
       "      <td>0.506812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588918</td>\n",
       "      <td>0.723142</td>\n",
       "      <td>7.605439</td>\n",
       "      <td>0.844724</td>\n",
       "      <td>0.844099</td>\n",
       "      <td>0.493956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.574148</td>\n",
       "      <td>0.715173</td>\n",
       "      <td>7.567744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.854943</td>\n",
       "      <td>0.885071</td>\n",
       "      <td>0.554858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.624880</td>\n",
       "      <td>0.742123</td>\n",
       "      <td>7.554124</td>\n",
       "      <td>0.844153</td>\n",
       "      <td>0.864827</td>\n",
       "      <td>0.473192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.564407</td>\n",
       "      <td>0.707767</td>\n",
       "      <td>7.569571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0     aus   svm     1        0.857600         0.808743      0.484478   \n",
       "1     aus   svm     2        0.859000         0.942529      0.700000   \n",
       "2     aus   svm     3        0.853400         0.861272      0.471190   \n",
       "3     aus   svm     4        0.856200         0.895161      0.719221   \n",
       "4     aus   svm     5        0.855200         0.886667      0.511649   \n",
       "5     aus   svm     6        0.856000         0.946667      0.490654   \n",
       "6     aus   svm     7        0.847200         0.854460      0.506812   \n",
       "7     aus   svm   avg        0.854943         0.885071      0.554858   \n",
       "\n",
       "   train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0                1.0  0.588915       0.719694        7.342944       0.845016   \n",
       "1                1.0  0.619383       0.737564        7.598531       0.842510   \n",
       "2                1.0  0.572881       0.711767        7.432745       0.843343   \n",
       "3                1.0  0.811189       0.851731        7.798856       0.843429   \n",
       "4                1.0  0.602321       0.728919        7.709055       0.844867   \n",
       "5                1.0  0.590551       0.722045        7.391298       0.845180   \n",
       "6                1.0  0.588918       0.723142        7.605439       0.844724   \n",
       "7                1.0  0.624880       0.742123        7.554124       0.844153   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0        0.842434     0.458103               1.0  0.552106      0.697773   \n",
       "1        0.879286     0.472528               1.0  0.574432      0.713079   \n",
       "2        0.860588     0.467550               1.0  0.561399      0.705952   \n",
       "3        0.869990     0.478763               1.0  0.561484      0.707630   \n",
       "4        0.854671     0.480836               1.0  0.569531      0.711297   \n",
       "5        0.902718     0.460610               1.0  0.557750      0.703466   \n",
       "6        0.844099     0.493956               1.0  0.574148      0.715173   \n",
       "7        0.864827     0.473192               1.0  0.564407      0.707767   \n",
       "\n",
       "   test_log_loss  \n",
       "0       7.577089  \n",
       "1       7.567990  \n",
       "2       7.573892  \n",
       "3       7.560859  \n",
       "4       7.564056  \n",
       "5       7.575367  \n",
       "6       7.567744  \n",
       "7       7.569571  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running SVM algorithm on Australian rain dataset, generally take longer time to run than other algorithms combined\n",
    "aus_results_svm = perform_trials('aus', models_only_svm, aus_X, aus_y)\n",
    "aus_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results of svm and non-svm algorithms and save as a csv file\n",
    "aus_final_results = aus_results_no_svm.append(aus_results_svm, ignore_index=True)\n",
    "aus_final_results.to_csv('results/aus_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849200</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.634995</td>\n",
       "      <td>0.982220</td>\n",
       "      <td>0.577857</td>\n",
       "      <td>0.793885</td>\n",
       "      <td>1.768402e+00</td>\n",
       "      <td>0.832130</td>\n",
       "      <td>0.793374</td>\n",
       "      <td>0.454306</td>\n",
       "      <td>0.981741</td>\n",
       "      <td>0.514792</td>\n",
       "      <td>0.680295</td>\n",
       "      <td>7.417087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853400</td>\n",
       "      <td>0.777567</td>\n",
       "      <td>0.864545</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.595251</td>\n",
       "      <td>0.722949</td>\n",
       "      <td>1.733863e+00</td>\n",
       "      <td>0.829382</td>\n",
       "      <td>0.734551</td>\n",
       "      <td>0.487182</td>\n",
       "      <td>0.965026</td>\n",
       "      <td>0.528443</td>\n",
       "      <td>0.687990</td>\n",
       "      <td>7.434552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842400</td>\n",
       "      <td>0.784884</td>\n",
       "      <td>0.860595</td>\n",
       "      <td>0.981142</td>\n",
       "      <td>0.559152</td>\n",
       "      <td>0.799772</td>\n",
       "      <td>1.733862e+00</td>\n",
       "      <td>0.828926</td>\n",
       "      <td>0.780864</td>\n",
       "      <td>0.467777</td>\n",
       "      <td>0.978989</td>\n",
       "      <td>0.524279</td>\n",
       "      <td>0.680138</td>\n",
       "      <td>7.590942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.853800</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.713906</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>0.623390</td>\n",
       "      <td>0.741199</td>\n",
       "      <td>1.125968e+00</td>\n",
       "      <td>0.828435</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.492878</td>\n",
       "      <td>0.983840</td>\n",
       "      <td>0.539103</td>\n",
       "      <td>0.695147</td>\n",
       "      <td>7.276675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.862200</td>\n",
       "      <td>0.838608</td>\n",
       "      <td>0.879928</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.703435</td>\n",
       "      <td>0.796881</td>\n",
       "      <td>1.637154e+00</td>\n",
       "      <td>0.829895</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.503917</td>\n",
       "      <td>0.983756</td>\n",
       "      <td>0.541967</td>\n",
       "      <td>0.702007</td>\n",
       "      <td>7.460127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.772182</td>\n",
       "      <td>0.715888</td>\n",
       "      <td>0.975827</td>\n",
       "      <td>0.656448</td>\n",
       "      <td>0.764614</td>\n",
       "      <td>1.699321e+00</td>\n",
       "      <td>0.823978</td>\n",
       "      <td>0.768040</td>\n",
       "      <td>0.463466</td>\n",
       "      <td>0.976079</td>\n",
       "      <td>0.544421</td>\n",
       "      <td>0.699465</td>\n",
       "      <td>7.465532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>0.838800</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.849228</td>\n",
       "      <td>0.969223</td>\n",
       "      <td>0.697723</td>\n",
       "      <td>0.793170</td>\n",
       "      <td>1.678599e+00</td>\n",
       "      <td>0.833198</td>\n",
       "      <td>0.735950</td>\n",
       "      <td>0.481284</td>\n",
       "      <td>0.962520</td>\n",
       "      <td>0.517844</td>\n",
       "      <td>0.690402</td>\n",
       "      <td>7.350698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aus</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.850943</td>\n",
       "      <td>0.796067</td>\n",
       "      <td>0.788441</td>\n",
       "      <td>0.978540</td>\n",
       "      <td>0.630465</td>\n",
       "      <td>0.773210</td>\n",
       "      <td>1.625310e+00</td>\n",
       "      <td>0.829421</td>\n",
       "      <td>0.773609</td>\n",
       "      <td>0.478687</td>\n",
       "      <td>0.975993</td>\n",
       "      <td>0.530121</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>7.427945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853600</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.493885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592217</td>\n",
       "      <td>0.723448</td>\n",
       "      <td>7.336036e+00</td>\n",
       "      <td>0.844789</td>\n",
       "      <td>0.822835</td>\n",
       "      <td>0.466541</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.568289</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>7.570941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854600</td>\n",
       "      <td>0.852665</td>\n",
       "      <td>0.532727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614256</td>\n",
       "      <td>0.737902</td>\n",
       "      <td>7.584715e+00</td>\n",
       "      <td>0.842987</td>\n",
       "      <td>0.798050</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.584528</td>\n",
       "      <td>0.721091</td>\n",
       "      <td>7.559876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.826568</td>\n",
       "      <td>0.504647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.594417</td>\n",
       "      <td>0.725820</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.841407</td>\n",
       "      <td>0.820193</td>\n",
       "      <td>0.493620</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.577177</td>\n",
       "      <td>0.716357</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>0.824607</td>\n",
       "      <td>0.534101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618462</td>\n",
       "      <td>0.738892</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.843585</td>\n",
       "      <td>0.791807</td>\n",
       "      <td>0.500585</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.583539</td>\n",
       "      <td>0.720150</td>\n",
       "      <td>7.549794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.852400</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615465</td>\n",
       "      <td>0.736984</td>\n",
       "      <td>7.709055e+00</td>\n",
       "      <td>0.843308</td>\n",
       "      <td>0.790676</td>\n",
       "      <td>0.496245</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.582311</td>\n",
       "      <td>0.718938</td>\n",
       "      <td>7.564056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>6</td>\n",
       "      <td>0.853600</td>\n",
       "      <td>0.783607</td>\n",
       "      <td>0.512150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606530</td>\n",
       "      <td>0.732029</td>\n",
       "      <td>7.377483e+00</td>\n",
       "      <td>0.843115</td>\n",
       "      <td>0.821836</td>\n",
       "      <td>0.485052</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.579321</td>\n",
       "      <td>0.715906</td>\n",
       "      <td>7.566023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.847800</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.498638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.590640</td>\n",
       "      <td>0.722517</td>\n",
       "      <td>7.598531e+00</td>\n",
       "      <td>0.843343</td>\n",
       "      <td>0.804531</td>\n",
       "      <td>0.491584</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>0.716813</td>\n",
       "      <td>7.562335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aus</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.852143</td>\n",
       "      <td>0.811858</td>\n",
       "      <td>0.514846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604569</td>\n",
       "      <td>0.731085</td>\n",
       "      <td>7.548203e+00</td>\n",
       "      <td>0.843219</td>\n",
       "      <td>0.807133</td>\n",
       "      <td>0.491110</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.579162</td>\n",
       "      <td>0.716840</td>\n",
       "      <td>7.563845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.576074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.515593</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.472579e+00</td>\n",
       "      <td>0.808066</td>\n",
       "      <td>0.581878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504020</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.780639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.825200</td>\n",
       "      <td>0.704710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958205</td>\n",
       "      <td>0.417767</td>\n",
       "      <td>0.608648</td>\n",
       "      <td>2.694087e+01</td>\n",
       "      <td>0.819500</td>\n",
       "      <td>0.668720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951451</td>\n",
       "      <td>0.416190</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>26.971410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.784800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.780713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563072</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.781091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556308</td>\n",
       "      <td>7.560859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552980</td>\n",
       "      <td>0.759433</td>\n",
       "      <td>7.709055e+00</td>\n",
       "      <td>0.219002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544798</td>\n",
       "      <td>0.759386</td>\n",
       "      <td>7.564056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>6</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.885047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.352554</td>\n",
       "      <td>0.758681</td>\n",
       "      <td>7.391298e+00</td>\n",
       "      <td>0.780671</td>\n",
       "      <td>0.219329</td>\n",
       "      <td>0.870192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359754</td>\n",
       "      <td>0.750847</td>\n",
       "      <td>7.575367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>7</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507093</td>\n",
       "      <td>0.716482</td>\n",
       "      <td>7.605439e+00</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513731</td>\n",
       "      <td>0.724962</td>\n",
       "      <td>7.567744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aus</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.632457</td>\n",
       "      <td>0.244998</td>\n",
       "      <td>0.376179</td>\n",
       "      <td>0.708315</td>\n",
       "      <td>0.335141</td>\n",
       "      <td>0.629474</td>\n",
       "      <td>1.019298e+01</td>\n",
       "      <td>0.629736</td>\n",
       "      <td>0.241291</td>\n",
       "      <td>0.374365</td>\n",
       "      <td>0.707350</td>\n",
       "      <td>0.334070</td>\n",
       "      <td>0.628555</td>\n",
       "      <td>10.227710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848400</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.815520</td>\n",
       "      <td>0.882158</td>\n",
       "      <td>0.410073</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.441787</td>\n",
       "      <td>0.642317</td>\n",
       "      <td>8.104128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.817179</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.430419</td>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.457014</td>\n",
       "      <td>0.651626</td>\n",
       "      <td>7.979461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.846200</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.815677</td>\n",
       "      <td>0.876491</td>\n",
       "      <td>0.419207</td>\n",
       "      <td>0.998878</td>\n",
       "      <td>0.448108</td>\n",
       "      <td>0.646152</td>\n",
       "      <td>7.995934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.847600</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.819158</td>\n",
       "      <td>0.840574</td>\n",
       "      <td>0.426532</td>\n",
       "      <td>0.996254</td>\n",
       "      <td>0.451479</td>\n",
       "      <td>0.648392</td>\n",
       "      <td>7.959296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.818297</td>\n",
       "      <td>0.870986</td>\n",
       "      <td>0.424954</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>0.452373</td>\n",
       "      <td>0.648848</td>\n",
       "      <td>7.930279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.816047</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.407180</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.439485</td>\n",
       "      <td>0.640965</td>\n",
       "      <td>8.002326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.840600</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.817599</td>\n",
       "      <td>0.852248</td>\n",
       "      <td>0.423934</td>\n",
       "      <td>0.997484</td>\n",
       "      <td>0.447889</td>\n",
       "      <td>0.646155</td>\n",
       "      <td>8.077575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>aus</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.885504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.817068</td>\n",
       "      <td>0.867393</td>\n",
       "      <td>0.420328</td>\n",
       "      <td>0.998044</td>\n",
       "      <td>0.448305</td>\n",
       "      <td>0.646351</td>\n",
       "      <td>8.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.347013e+00</td>\n",
       "      <td>0.842809</td>\n",
       "      <td>0.767281</td>\n",
       "      <td>0.409359</td>\n",
       "      <td>0.966775</td>\n",
       "      <td>0.531908</td>\n",
       "      <td>0.687379</td>\n",
       "      <td>5.447391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992821</td>\n",
       "      <td>0.995892</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>2.756199e+00</td>\n",
       "      <td>0.844354</td>\n",
       "      <td>0.738856</td>\n",
       "      <td>0.447055</td>\n",
       "      <td>0.957268</td>\n",
       "      <td>0.558036</td>\n",
       "      <td>0.701914</td>\n",
       "      <td>5.390840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.915428</td>\n",
       "      <td>0.994139</td>\n",
       "      <td>0.955889</td>\n",
       "      <td>0.958643</td>\n",
       "      <td>1.934173e+00</td>\n",
       "      <td>0.843699</td>\n",
       "      <td>0.758192</td>\n",
       "      <td>0.428330</td>\n",
       "      <td>0.962174</td>\n",
       "      <td>0.547116</td>\n",
       "      <td>0.694920</td>\n",
       "      <td>5.403624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966400</td>\n",
       "      <td>0.963151</td>\n",
       "      <td>0.982285</td>\n",
       "      <td>0.993283</td>\n",
       "      <td>0.992864</td>\n",
       "      <td>0.991585</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.843735</td>\n",
       "      <td>0.752891</td>\n",
       "      <td>0.430792</td>\n",
       "      <td>0.960843</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.694745</td>\n",
       "      <td>5.403625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.598531e-02</td>\n",
       "      <td>0.844611</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.444101</td>\n",
       "      <td>0.957930</td>\n",
       "      <td>0.556473</td>\n",
       "      <td>0.700659</td>\n",
       "      <td>5.366496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946600</td>\n",
       "      <td>0.987775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.222673e+00</td>\n",
       "      <td>0.842653</td>\n",
       "      <td>0.755188</td>\n",
       "      <td>0.422761</td>\n",
       "      <td>0.962764</td>\n",
       "      <td>0.540838</td>\n",
       "      <td>0.691324</td>\n",
       "      <td>5.437557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.966200</td>\n",
       "      <td>0.977632</td>\n",
       "      <td>0.844687</td>\n",
       "      <td>0.994614</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>0.922669</td>\n",
       "      <td>2.928892e+00</td>\n",
       "      <td>0.843657</td>\n",
       "      <td>0.755408</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>0.962875</td>\n",
       "      <td>0.544035</td>\n",
       "      <td>0.693391</td>\n",
       "      <td>5.427721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>aus</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.979914</td>\n",
       "      <td>0.975424</td>\n",
       "      <td>0.963200</td>\n",
       "      <td>0.993414</td>\n",
       "      <td>0.980076</td>\n",
       "      <td>0.981193</td>\n",
       "      <td>1.466419e+00</td>\n",
       "      <td>0.843645</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.429885</td>\n",
       "      <td>0.961518</td>\n",
       "      <td>0.546172</td>\n",
       "      <td>0.694904</td>\n",
       "      <td>5.411036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857600</td>\n",
       "      <td>0.808743</td>\n",
       "      <td>0.484478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.719694</td>\n",
       "      <td>7.342944e+00</td>\n",
       "      <td>0.845016</td>\n",
       "      <td>0.842434</td>\n",
       "      <td>0.458103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.552106</td>\n",
       "      <td>0.697773</td>\n",
       "      <td>7.577089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.859000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619383</td>\n",
       "      <td>0.737564</td>\n",
       "      <td>7.598531e+00</td>\n",
       "      <td>0.842510</td>\n",
       "      <td>0.879286</td>\n",
       "      <td>0.472528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574432</td>\n",
       "      <td>0.713079</td>\n",
       "      <td>7.567990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.853400</td>\n",
       "      <td>0.861272</td>\n",
       "      <td>0.471190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.572881</td>\n",
       "      <td>0.711767</td>\n",
       "      <td>7.432745e+00</td>\n",
       "      <td>0.843343</td>\n",
       "      <td>0.860588</td>\n",
       "      <td>0.467550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561399</td>\n",
       "      <td>0.705952</td>\n",
       "      <td>7.573892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>0.895161</td>\n",
       "      <td>0.719221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.851731</td>\n",
       "      <td>7.798856e+00</td>\n",
       "      <td>0.843429</td>\n",
       "      <td>0.869990</td>\n",
       "      <td>0.478763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561484</td>\n",
       "      <td>0.707630</td>\n",
       "      <td>7.560859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.855200</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.511649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602321</td>\n",
       "      <td>0.728919</td>\n",
       "      <td>7.709055e+00</td>\n",
       "      <td>0.844867</td>\n",
       "      <td>0.854671</td>\n",
       "      <td>0.480836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.569531</td>\n",
       "      <td>0.711297</td>\n",
       "      <td>7.564056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>6</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.490654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.590551</td>\n",
       "      <td>0.722045</td>\n",
       "      <td>7.391298e+00</td>\n",
       "      <td>0.845180</td>\n",
       "      <td>0.902718</td>\n",
       "      <td>0.460610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557750</td>\n",
       "      <td>0.703466</td>\n",
       "      <td>7.575367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>7</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.854460</td>\n",
       "      <td>0.506812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588918</td>\n",
       "      <td>0.723142</td>\n",
       "      <td>7.605439e+00</td>\n",
       "      <td>0.844724</td>\n",
       "      <td>0.844099</td>\n",
       "      <td>0.493956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574148</td>\n",
       "      <td>0.715173</td>\n",
       "      <td>7.567744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>aus</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.854943</td>\n",
       "      <td>0.885071</td>\n",
       "      <td>0.554858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624880</td>\n",
       "      <td>0.742123</td>\n",
       "      <td>7.554124e+00</td>\n",
       "      <td>0.844153</td>\n",
       "      <td>0.864827</td>\n",
       "      <td>0.473192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564407</td>\n",
       "      <td>0.707767</td>\n",
       "      <td>7.569571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0      aus        tree     1        0.849200         0.800000      0.634995   \n",
       "1      aus        tree     2        0.853400         0.777567      0.864545   \n",
       "2      aus        tree     3        0.842400         0.784884      0.860595   \n",
       "3      aus        tree     4        0.853800         0.823529      0.713906   \n",
       "4      aus        tree     5        0.862200         0.838608      0.879928   \n",
       "5      aus        tree     6        0.856800         0.772182      0.715888   \n",
       "6      aus        tree     7        0.838800         0.775701      0.849228   \n",
       "7      aus        tree   avg        0.850943         0.796067      0.788441   \n",
       "8      aus     log_reg     1        0.853600         0.788591      0.493885   \n",
       "9      aus     log_reg     2        0.854600         0.852665      0.532727   \n",
       "10     aus     log_reg     3        0.851800         0.826568      0.504647   \n",
       "11     aus     log_reg     4        0.851200         0.824607      0.534101   \n",
       "12     aus     log_reg     5        0.852400         0.808333      0.527778   \n",
       "13     aus     log_reg     6        0.853600         0.783607      0.512150   \n",
       "14     aus     log_reg     7        0.847800         0.798635      0.498638   \n",
       "15     aus     log_reg   avg        0.852143         0.811858      0.514846   \n",
       "16     aus  perceptron     1        0.813600         0.576074      0.000000   \n",
       "17     aus  perceptron     2        0.825200         0.704710      1.000000   \n",
       "18     aus  perceptron     3        0.784800         0.000000      0.000000   \n",
       "19     aus  perceptron     4        0.774200         0.000000      0.000000   \n",
       "20     aus  perceptron     5        0.223200         0.000000      0.748208   \n",
       "21     aus  perceptron     6        0.786000         0.214000      0.885047   \n",
       "22     aus  perceptron     7        0.220200         0.220200      0.000000   \n",
       "23     aus  perceptron   avg        0.632457         0.244998      0.376179   \n",
       "24     aus         knn     1        0.848400         0.862745      1.000000   \n",
       "25     aus         knn     2        0.834600         0.938776      1.000000   \n",
       "26     aus         knn     3        0.846200         0.869565      1.000000   \n",
       "27     aus         knn     4        0.847600         0.872549      1.000000   \n",
       "28     aus         knn     5        0.834600         0.910828      1.000000   \n",
       "29     aus         knn     6        0.844000         0.901961      1.000000   \n",
       "30     aus         knn     7        0.840600         0.842105      1.000000   \n",
       "31     aus         knn   avg        0.842286         0.885504      1.000000   \n",
       "32     aus      forest     1        1.000000         0.973298      1.000000   \n",
       "33     aus      forest     2        0.998200         1.000000      1.000000   \n",
       "34     aus      forest     3        0.982000         0.970588      0.915428   \n",
       "35     aus      forest     4        0.966400         0.963151      0.982285   \n",
       "36     aus      forest     5        1.000000         0.955527      1.000000   \n",
       "37     aus      forest     6        0.946600         0.987775      1.000000   \n",
       "38     aus      forest     7        0.966200         0.977632      0.844687   \n",
       "39     aus      forest   avg        0.979914         0.975424      0.963200   \n",
       "40     aus         svm     1        0.857600         0.808743      0.484478   \n",
       "41     aus         svm     2        0.859000         0.942529      0.700000   \n",
       "42     aus         svm     3        0.853400         0.861272      0.471190   \n",
       "43     aus         svm     4        0.856200         0.895161      0.719221   \n",
       "44     aus         svm     5        0.855200         0.886667      0.511649   \n",
       "45     aus         svm     6        0.856000         0.946667      0.490654   \n",
       "46     aus         svm     7        0.847200         0.854460      0.506812   \n",
       "47     aus         svm   avg        0.854943         0.885071      0.554858   \n",
       "\n",
       "    train_specificity  train_f1  train_roc_auc  train_log_loss  test_accuracy  \\\n",
       "0            0.982220  0.577857       0.793885    1.768402e+00       0.832130   \n",
       "1            0.970000  0.595251       0.722949    1.733863e+00       0.829382   \n",
       "2            0.981142  0.559152       0.799772    1.733862e+00       0.828926   \n",
       "3            0.984500  0.623390       0.741199    1.125968e+00       0.828435   \n",
       "4            0.986869  0.703435       0.796881    1.637154e+00       0.829895   \n",
       "5            0.975827  0.656448       0.764614    1.699321e+00       0.823978   \n",
       "6            0.969223  0.697723       0.793170    1.678599e+00       0.833198   \n",
       "7            0.978540  0.630465       0.773210    1.625310e+00       0.829421   \n",
       "8            1.000000  0.592217       0.723448    7.336036e+00       0.844789   \n",
       "9            1.000000  0.614256       0.737902    7.584715e+00       0.842987   \n",
       "10           1.000000  0.594417       0.725820    7.432745e+00       0.841407   \n",
       "11           1.000000  0.618462       0.738892    7.798856e+00       0.843585   \n",
       "12           1.000000  0.615465       0.736984    7.709055e+00       0.843308   \n",
       "13           1.000000  0.606530       0.732029    7.377483e+00       0.843115   \n",
       "14           1.000000  0.590640       0.722517    7.598531e+00       0.843343   \n",
       "15           1.000000  0.604569       0.731085    7.548203e+00       0.843219   \n",
       "16           1.000000  0.515593       0.500000    6.472579e+00       0.808066   \n",
       "17           0.958205  0.417767       0.608648    2.694087e+01       0.819500   \n",
       "18           1.000000  0.000000       0.500000    7.432745e+00       0.780713   \n",
       "19           1.000000  0.000000       0.563072    7.798856e+00       0.781091   \n",
       "20           0.000000  0.552980       0.759433    7.709055e+00       0.219002   \n",
       "21           1.000000  0.352554       0.758681    7.391298e+00       0.780671   \n",
       "22           0.000000  0.507093       0.716482    7.605439e+00       0.219109   \n",
       "23           0.708315  0.335141       0.629474    1.019298e+01       0.629736   \n",
       "24           0.998222  1.000000       1.000000    9.992007e-16       0.815520   \n",
       "25           0.999231  1.000000       1.000000    9.992007e-16       0.817179   \n",
       "26           0.998981  1.000000       1.000000    9.992007e-16       0.815677   \n",
       "27           0.996642  1.000000       1.000000    9.992007e-16       0.819158   \n",
       "28           0.997683  1.000000       1.000000    9.992007e-16       0.818297   \n",
       "29           0.998728  1.000000       1.000000    9.992007e-16       0.816047   \n",
       "30           0.997692  1.000000       1.000000    9.992007e-16       0.817599   \n",
       "31           0.998168  1.000000       1.000000    9.992007e-16       0.817068   \n",
       "32           0.993650  1.000000       1.000000    1.347013e+00       0.842809   \n",
       "33           0.992821  0.995892       0.995455    2.756199e+00       0.844354   \n",
       "34           0.994139  0.955889       0.958643    1.934173e+00       0.843699   \n",
       "35           0.993283  0.992864       0.991585    9.992007e-16       0.843735   \n",
       "36           0.991246  1.000000       1.000000    7.598531e-02       0.844611   \n",
       "37           0.994148  1.000000       1.000000    1.222673e+00       0.842653   \n",
       "38           0.994614  0.915888       0.922669    2.928892e+00       0.843657   \n",
       "39           0.993414  0.980076       0.981193    1.466419e+00       0.843645   \n",
       "40           1.000000  0.588915       0.719694    7.342944e+00       0.845016   \n",
       "41           1.000000  0.619383       0.737564    7.598531e+00       0.842510   \n",
       "42           1.000000  0.572881       0.711767    7.432745e+00       0.843343   \n",
       "43           1.000000  0.811189       0.851731    7.798856e+00       0.843429   \n",
       "44           1.000000  0.602321       0.728919    7.709055e+00       0.844867   \n",
       "45           1.000000  0.590551       0.722045    7.391298e+00       0.845180   \n",
       "46           1.000000  0.588918       0.723142    7.605439e+00       0.844724   \n",
       "47           1.000000  0.624880       0.742123    7.554124e+00       0.844153   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_roc_auc  \\\n",
       "0         0.793374     0.454306          0.981741  0.514792      0.680295   \n",
       "1         0.734551     0.487182          0.965026  0.528443      0.687990   \n",
       "2         0.780864     0.467777          0.978989  0.524279      0.680138   \n",
       "3         0.801478     0.492878          0.983840  0.539103      0.695147   \n",
       "4         0.801005     0.503917          0.983756  0.541967      0.702007   \n",
       "5         0.768040     0.463466          0.976079  0.544421      0.699465   \n",
       "6         0.735950     0.481284          0.962520  0.517844      0.690402   \n",
       "7         0.773609     0.478687          0.975993  0.530121      0.690778   \n",
       "8         0.822835     0.466541          0.999991  0.568289      0.708628   \n",
       "9         0.798050     0.504143          0.999991  0.584528      0.721091   \n",
       "10        0.820193     0.493620          0.999991  0.577177      0.716357   \n",
       "11        0.791807     0.500585          0.999991  0.583539      0.720150   \n",
       "12        0.790676     0.496245          0.999982  0.582311      0.718938   \n",
       "13        0.821836     0.485052          0.999982  0.579321      0.715906   \n",
       "14        0.804531     0.491584          0.999991  0.578968      0.716813   \n",
       "15        0.807133     0.491110          0.999988  0.579162      0.716840   \n",
       "16        0.581878     0.000000          1.000000  0.504020      0.500000   \n",
       "17        0.668720     1.000000          0.951451  0.416190      0.608385   \n",
       "18        0.000000     0.000000          1.000000  0.000000      0.500000   \n",
       "19        0.000000     0.000000          1.000000  0.000000      0.556308   \n",
       "20        0.000000     0.750366          0.000000  0.544798      0.759386   \n",
       "21        0.219329     0.870192          1.000000  0.359754      0.750847   \n",
       "22        0.219109     0.000000          0.000000  0.513731      0.724962   \n",
       "23        0.241291     0.374365          0.707350  0.334070      0.628555   \n",
       "24        0.882158     0.410073          0.998778  0.441787      0.642317   \n",
       "25        0.891667     0.430419          0.998578  0.457014      0.651626   \n",
       "26        0.876491     0.419207          0.998878  0.448108      0.646152   \n",
       "27        0.840574     0.426532          0.996254  0.451479      0.648392   \n",
       "28        0.870986     0.424954          0.997867  0.452373      0.648848   \n",
       "29        0.857627     0.407180          0.998468  0.439485      0.640965   \n",
       "30        0.852248     0.423934          0.997484  0.447889      0.646155   \n",
       "31        0.867393     0.420328          0.998044  0.448305      0.646351   \n",
       "32        0.767281     0.409359          0.966775  0.531908      0.687379   \n",
       "33        0.738856     0.447055          0.957268  0.558036      0.701914   \n",
       "34        0.758192     0.428330          0.962174  0.547116      0.694920   \n",
       "35        0.752891     0.430792          0.960843  0.544797      0.694745   \n",
       "36        0.745518     0.444101          0.957930  0.556473      0.700659   \n",
       "37        0.755188     0.422761          0.962764  0.540838      0.691324   \n",
       "38        0.755408     0.426794          0.962875  0.544035      0.693391   \n",
       "39        0.753333     0.429885          0.961518  0.546172      0.694904   \n",
       "40        0.842434     0.458103          1.000000  0.552106      0.697773   \n",
       "41        0.879286     0.472528          1.000000  0.574432      0.713079   \n",
       "42        0.860588     0.467550          1.000000  0.561399      0.705952   \n",
       "43        0.869990     0.478763          1.000000  0.561484      0.707630   \n",
       "44        0.854671     0.480836          1.000000  0.569531      0.711297   \n",
       "45        0.902718     0.460610          1.000000  0.557750      0.703466   \n",
       "46        0.844099     0.493956          1.000000  0.574148      0.715173   \n",
       "47        0.864827     0.473192          1.000000  0.564407      0.707767   \n",
       "\n",
       "    test_log_loss  \n",
       "0        7.417087  \n",
       "1        7.434552  \n",
       "2        7.590942  \n",
       "3        7.276675  \n",
       "4        7.460127  \n",
       "5        7.465532  \n",
       "6        7.350698  \n",
       "7        7.427945  \n",
       "8        7.570941  \n",
       "9        7.559876  \n",
       "10       7.573892  \n",
       "11       7.549794  \n",
       "12       7.564056  \n",
       "13       7.566023  \n",
       "14       7.562335  \n",
       "15       7.563845  \n",
       "16       6.780639  \n",
       "17      26.971410  \n",
       "18       7.573892  \n",
       "19       7.560859  \n",
       "20       7.564056  \n",
       "21       7.575367  \n",
       "22       7.567744  \n",
       "23      10.227710  \n",
       "24       8.104128  \n",
       "25       7.979461  \n",
       "26       7.995934  \n",
       "27       7.959296  \n",
       "28       7.930279  \n",
       "29       8.002326  \n",
       "30       8.077575  \n",
       "31       8.007000  \n",
       "32       5.447391  \n",
       "33       5.390840  \n",
       "34       5.403624  \n",
       "35       5.403625  \n",
       "36       5.366496  \n",
       "37       5.437557  \n",
       "38       5.427721  \n",
       "39       5.411036  \n",
       "40       7.577089  \n",
       "41       7.567990  \n",
       "42       7.573892  \n",
       "43       7.560859  \n",
       "44       7.564056  \n",
       "45       7.575367  \n",
       "46       7.567744  \n",
       "47       7.569571  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/aus_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of AirBnB Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1936 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2104 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:   13.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 260 | elapsed:    9.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    9.1s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 260 | elapsed:    8.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    8.9s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 260 | elapsed:    8.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    9.1s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    9.8s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 260 | elapsed:    9.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    9.4s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 398 out of 405 | elapsed:   14.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   14.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 398 out of 405 | elapsed:   14.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 398 out of 405 | elapsed:   14.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 398 out of 405 | elapsed:   15.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   56.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   55.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987533</td>\n",
       "      <td>0.987687</td>\n",
       "      <td>4.213731e-01</td>\n",
       "      <td>0.988040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987894</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>4.130962e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990426</td>\n",
       "      <td>0.990517</td>\n",
       "      <td>3.246645e-01</td>\n",
       "      <td>0.987721</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.975849</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.987572</td>\n",
       "      <td>0.987719</td>\n",
       "      <td>4.241123e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.98760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>4.282808e-01</td>\n",
       "      <td>0.989065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988957</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>3.776880e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.98840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988154</td>\n",
       "      <td>0.988292</td>\n",
       "      <td>4.006498e-01</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989618</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>3.548693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98560</td>\n",
       "      <td>0.991857</td>\n",
       "      <td>0.979100</td>\n",
       "      <td>0.992038</td>\n",
       "      <td>0.985437</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>4.973616e-01</td>\n",
       "      <td>0.985853</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.977388</td>\n",
       "      <td>0.994308</td>\n",
       "      <td>0.985724</td>\n",
       "      <td>0.985848</td>\n",
       "      <td>4.886361e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.98800</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.977355</td>\n",
       "      <td>0.998408</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>4.144660e-01</td>\n",
       "      <td>0.988081</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.977384</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.987953</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>4.116804e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84940</td>\n",
       "      <td>0.766873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701546</td>\n",
       "      <td>0.868057</td>\n",
       "      <td>0.850773</td>\n",
       "      <td>5.201660e+00</td>\n",
       "      <td>0.851897</td>\n",
       "      <td>0.771470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703813</td>\n",
       "      <td>0.870994</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>5.115430e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.96988</td>\n",
       "      <td>0.953375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940309</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.970155</td>\n",
       "      <td>1.040332e+00</td>\n",
       "      <td>0.970379</td>\n",
       "      <td>0.954294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940763</td>\n",
       "      <td>0.974199</td>\n",
       "      <td>0.970381</td>\n",
       "      <td>1.023086e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>0.998779</td>\n",
       "      <td>0.990311</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.994527</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>1.865099e-01</td>\n",
       "      <td>0.990318</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.997403</td>\n",
       "      <td>0.990248</td>\n",
       "      <td>0.990317</td>\n",
       "      <td>3.344122e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>0.998373</td>\n",
       "      <td>0.990718</td>\n",
       "      <td>0.998414</td>\n",
       "      <td>0.994531</td>\n",
       "      <td>0.994566</td>\n",
       "      <td>1.865100e-01</td>\n",
       "      <td>0.990819</td>\n",
       "      <td>0.995857</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.990771</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>3.171021e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>0.991425</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>0.994674</td>\n",
       "      <td>0.994733</td>\n",
       "      <td>1.796024e-01</td>\n",
       "      <td>0.991092</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.985619</td>\n",
       "      <td>0.996579</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>0.991099</td>\n",
       "      <td>3.076597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.986677</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.992689</td>\n",
       "      <td>0.992744</td>\n",
       "      <td>2.486797e-01</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>0.998566</td>\n",
       "      <td>0.983368</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>3.115931e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.993137</td>\n",
       "      <td>0.993179</td>\n",
       "      <td>2.348646e-01</td>\n",
       "      <td>0.990090</td>\n",
       "      <td>0.997041</td>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.997086</td>\n",
       "      <td>0.990014</td>\n",
       "      <td>0.990086</td>\n",
       "      <td>3.422809e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.998288</td>\n",
       "      <td>0.989576</td>\n",
       "      <td>0.998337</td>\n",
       "      <td>0.993912</td>\n",
       "      <td>0.993956</td>\n",
       "      <td>2.072333e-01</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.984209</td>\n",
       "      <td>0.997111</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>3.226096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.573700e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>3.147400e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   airbnb        tree     1         1.00000         1.000000      1.000000   \n",
       "1   airbnb        tree     2         1.00000         1.000000      1.000000   \n",
       "2   airbnb        tree     3         1.00000         1.000000      1.000000   \n",
       "3   airbnb        tree     4         1.00000         1.000000      1.000000   \n",
       "4   airbnb        tree     5         1.00000         1.000000      1.000000   \n",
       "5   airbnb        tree   avg         1.00000         1.000000      1.000000   \n",
       "6   airbnb     log_reg     1         0.98780         1.000000      0.975373   \n",
       "7   airbnb     log_reg     2         0.99060         1.000000      0.981033   \n",
       "8   airbnb     log_reg     3         0.98760         1.000000      0.974684   \n",
       "9   airbnb     log_reg     4         0.98840         1.000000      0.976585   \n",
       "10  airbnb     log_reg     5         0.98560         0.991857      0.979100   \n",
       "11  airbnb     log_reg   avg         0.98800         0.998371      0.977355   \n",
       "12  airbnb  perceptron     1         1.00000         1.000000      1.000000   \n",
       "13  airbnb  perceptron     2         1.00000         1.000000      1.000000   \n",
       "14  airbnb  perceptron     3         1.00000         1.000000      1.000000   \n",
       "15  airbnb  perceptron     4         0.84940         0.766873      1.000000   \n",
       "16  airbnb  perceptron     5         1.00000         1.000000      1.000000   \n",
       "17  airbnb  perceptron   avg         0.96988         0.953375      1.000000   \n",
       "18  airbnb         knn     1         0.99460         0.998779      0.990311   \n",
       "19  airbnb         knn     2         0.99460         0.998373      0.990718   \n",
       "20  airbnb         knn     3         0.99480         0.997945      0.991425   \n",
       "21  airbnb         knn     4         0.99280         0.998774      0.986677   \n",
       "22  airbnb         knn     5         0.99320         0.997567      0.988746   \n",
       "23  airbnb         knn   avg         0.99400         0.998288      0.989576   \n",
       "24  airbnb      forest     1         1.00000         1.000000      1.000000   \n",
       "25  airbnb      forest     2         1.00000         1.000000      1.000000   \n",
       "26  airbnb      forest     3         1.00000         1.000000      1.000000   \n",
       "27  airbnb      forest     4         1.00000         1.000000      1.000000   \n",
       "28  airbnb      forest     5         1.00000         1.000000      1.000000   \n",
       "29  airbnb      forest   avg         1.00000         1.000000      1.000000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "1            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "2            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "3            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "4            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "5            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "6            1.000000  0.987533   0.987687   4.213731e-01       0.988040   \n",
       "7            1.000000  0.990426   0.990517   3.246645e-01       0.987721   \n",
       "8            1.000000  0.987179   0.987342   4.282808e-01       0.989065   \n",
       "9            1.000000  0.988154   0.988292   4.006498e-01       0.989725   \n",
       "10           0.992038  0.985437   0.985569   4.973616e-01       0.985853   \n",
       "11           0.998408  0.987746   0.987881   4.144660e-01       0.988081   \n",
       "12           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "13           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "14           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "15           0.701546  0.868057   0.850773   5.201660e+00       0.851897   \n",
       "16           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "17           0.940309  0.973611   0.970155   1.040332e+00       0.970379   \n",
       "18           0.998811  0.994527   0.994561   1.865099e-01       0.990318   \n",
       "19           0.998414  0.994531   0.994566   1.865100e-01       0.990819   \n",
       "20           0.998040  0.994674   0.994733   1.796024e-01       0.991092   \n",
       "21           0.998811  0.992689   0.992744   2.486797e-01       0.990978   \n",
       "22           0.997611  0.993137   0.993179   2.348646e-01       0.990090   \n",
       "23           0.998337  0.993912   0.993956   2.072333e-01       0.990660   \n",
       "24           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "25           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "26           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "27           1.000000  1.000000   1.000000   9.992007e-16       0.999954   \n",
       "28           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "29           1.000000  1.000000   1.000000   9.992007e-16       0.999991   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "1         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "2         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "3         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "4         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "5         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "6         1.000000     0.976078          1.000000  0.987894  0.988039   \n",
       "7         0.999580     0.975849          0.999590  0.987572  0.987719   \n",
       "8         1.000000     0.978156          1.000000  0.988957  0.989078   \n",
       "9         1.000000     0.979450          1.000000  0.989618  0.989725   \n",
       "10        0.994203     0.977388          0.994308  0.985724  0.985848   \n",
       "11        0.998757     0.977384          0.998780  0.987953  0.988082   \n",
       "12        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "13        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "14        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "15        0.771470     1.000000          0.703813  0.870994  0.851907   \n",
       "16        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "17        0.954294     1.000000          0.940763  0.974199  0.970381   \n",
       "18        0.997365     0.983232          0.997403  0.990248  0.990317   \n",
       "19        0.995857     0.985737          0.995900  0.990771  0.990818   \n",
       "20        0.996549     0.985619          0.996579  0.991054  0.991099   \n",
       "21        0.998566     0.983368          0.998588  0.990909  0.990978   \n",
       "22        0.997041     0.983086          0.997086  0.990014  0.990086   \n",
       "23        0.997076     0.984209          0.997111  0.990599  0.990660   \n",
       "24        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "25        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "26        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "27        1.000000     0.999909          1.000000  0.999954  0.999954   \n",
       "28        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "29        1.000000     0.999982          1.000000  0.999991  0.999991   \n",
       "\n",
       "    test_logloss  \n",
       "0   9.992007e-16  \n",
       "1   9.992007e-16  \n",
       "2   9.992007e-16  \n",
       "3   9.992007e-16  \n",
       "4   9.992007e-16  \n",
       "5   9.992007e-16  \n",
       "6   4.130962e-01  \n",
       "7   4.241123e-01  \n",
       "8   3.776880e-01  \n",
       "9   3.548693e-01  \n",
       "10  4.886361e-01  \n",
       "11  4.116804e-01  \n",
       "12  9.992007e-16  \n",
       "13  9.992007e-16  \n",
       "14  9.992007e-16  \n",
       "15  5.115430e+00  \n",
       "16  9.992007e-16  \n",
       "17  1.023086e+00  \n",
       "18  3.344122e-01  \n",
       "19  3.171021e-01  \n",
       "20  3.076597e-01  \n",
       "21  3.115931e-01  \n",
       "22  3.422809e-01  \n",
       "23  3.226096e-01  \n",
       "24  9.992007e-16  \n",
       "25  9.992007e-16  \n",
       "26  9.992007e-16  \n",
       "27  1.573700e-03  \n",
       "28  9.992007e-16  \n",
       "29  3.147400e-04  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on airbnb dataset\n",
    "airbnb_results_no_svm = perform_trials('airbnb', models_without_svm, airbnb_X, airbnb_y)\n",
    "airbnb_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   27.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   25.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   26.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.010229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.998777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.999412</td>\n",
       "      <td>2.072375e-02</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998540</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>0.999270</td>\n",
       "      <td>0.025180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.004721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.001574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>4.144749e-03</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.009757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  airbnb   svm     1         1.00000         1.000000           1.0   \n",
       "1  airbnb   svm     2         1.00000         1.000000           1.0   \n",
       "2  airbnb   svm     3         0.99940         0.998777           1.0   \n",
       "3  airbnb   svm     4         1.00000         1.000000           1.0   \n",
       "4  airbnb   svm     5         1.00000         1.000000           1.0   \n",
       "5  airbnb   svm   avg         0.99988         0.999755           1.0   \n",
       "\n",
       "   train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0           1.000000  1.000000   1.000000   9.992007e-16       0.999795   \n",
       "1           1.000000  1.000000   1.000000   9.992007e-16       0.999704   \n",
       "2           0.998824  0.999388   0.999412   2.072375e-02       0.999271   \n",
       "3           1.000000  1.000000   1.000000   9.992007e-16       0.999863   \n",
       "4           1.000000  1.000000   1.000000   9.992007e-16       0.999954   \n",
       "5           0.999765  0.999878   0.999882   4.144749e-03       0.999718   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0        0.999727     0.999863          0.999727  0.999795  0.999795   \n",
       "1        0.999408     1.000000          0.999408  0.999704  0.999704   \n",
       "2        0.998546     1.000000          0.998540  0.999272  0.999270   \n",
       "3        0.999863     0.999863          0.999863  0.999863  0.999863   \n",
       "4        1.000000     0.999909          1.000000  0.999954  0.999954   \n",
       "5        0.999509     0.999927          0.999508  0.999718  0.999717   \n",
       "\n",
       "   test_logloss  \n",
       "0      0.007082  \n",
       "1      0.010229  \n",
       "2      0.025180  \n",
       "3      0.004721  \n",
       "4      0.001574  \n",
       "5      0.009757  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_results_svm = perform_trials('airbnb', models_only_svm, airbnb_X, airbnb_y)\n",
    "airbnb_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_final_results = airbnb_results_no_svm.append(airbnb_results_svm, ignore_index=True)\n",
    "airbnb_final_results.to_csv('results/airbnb_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987533</td>\n",
       "      <td>0.987687</td>\n",
       "      <td>4.213731e-01</td>\n",
       "      <td>0.988040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987894</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>4.130962e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990426</td>\n",
       "      <td>0.990517</td>\n",
       "      <td>3.246645e-01</td>\n",
       "      <td>0.987721</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.975849</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.987572</td>\n",
       "      <td>0.987719</td>\n",
       "      <td>4.241123e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.98760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>4.282808e-01</td>\n",
       "      <td>0.989065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988957</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>3.776880e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.98840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988154</td>\n",
       "      <td>0.988292</td>\n",
       "      <td>4.006498e-01</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989618</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>3.548693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98560</td>\n",
       "      <td>0.991857</td>\n",
       "      <td>0.979100</td>\n",
       "      <td>0.992038</td>\n",
       "      <td>0.985437</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>4.973616e-01</td>\n",
       "      <td>0.985853</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.977388</td>\n",
       "      <td>0.994308</td>\n",
       "      <td>0.985724</td>\n",
       "      <td>0.985848</td>\n",
       "      <td>4.886361e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.98800</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.977355</td>\n",
       "      <td>0.998408</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>4.144660e-01</td>\n",
       "      <td>0.988081</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.977384</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.987953</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>4.116804e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84940</td>\n",
       "      <td>0.766873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701546</td>\n",
       "      <td>0.868057</td>\n",
       "      <td>0.850773</td>\n",
       "      <td>5.201660e+00</td>\n",
       "      <td>0.851897</td>\n",
       "      <td>0.771470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703813</td>\n",
       "      <td>0.870994</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>5.115430e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.96988</td>\n",
       "      <td>0.953375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940309</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.970155</td>\n",
       "      <td>1.040332e+00</td>\n",
       "      <td>0.970379</td>\n",
       "      <td>0.954294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940763</td>\n",
       "      <td>0.974199</td>\n",
       "      <td>0.970381</td>\n",
       "      <td>1.023086e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>0.998779</td>\n",
       "      <td>0.990311</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.994527</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>1.865099e-01</td>\n",
       "      <td>0.990318</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.997403</td>\n",
       "      <td>0.990248</td>\n",
       "      <td>0.990317</td>\n",
       "      <td>3.344122e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>0.998373</td>\n",
       "      <td>0.990718</td>\n",
       "      <td>0.998414</td>\n",
       "      <td>0.994531</td>\n",
       "      <td>0.994566</td>\n",
       "      <td>1.865100e-01</td>\n",
       "      <td>0.990819</td>\n",
       "      <td>0.995857</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.990771</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>3.171021e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>0.991425</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>0.994674</td>\n",
       "      <td>0.994733</td>\n",
       "      <td>1.796024e-01</td>\n",
       "      <td>0.991092</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.985619</td>\n",
       "      <td>0.996579</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>0.991099</td>\n",
       "      <td>3.076597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.986677</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.992689</td>\n",
       "      <td>0.992744</td>\n",
       "      <td>2.486797e-01</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>0.998566</td>\n",
       "      <td>0.983368</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>3.115931e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.993137</td>\n",
       "      <td>0.993179</td>\n",
       "      <td>2.348646e-01</td>\n",
       "      <td>0.990090</td>\n",
       "      <td>0.997041</td>\n",
       "      <td>0.983086</td>\n",
       "      <td>0.997086</td>\n",
       "      <td>0.990014</td>\n",
       "      <td>0.990086</td>\n",
       "      <td>3.422809e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.998288</td>\n",
       "      <td>0.989576</td>\n",
       "      <td>0.998337</td>\n",
       "      <td>0.993912</td>\n",
       "      <td>0.993956</td>\n",
       "      <td>2.072333e-01</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.984209</td>\n",
       "      <td>0.997111</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>3.226096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.573700e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>3.147400e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>7.081758e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>1.022929e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.998777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.999412</td>\n",
       "      <td>2.072375e-02</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998540</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>0.999270</td>\n",
       "      <td>2.517978e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>4.721154e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.573700e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>airbnb</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>4.144749e-03</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>9.757136e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   airbnb        tree     1         1.00000         1.000000      1.000000   \n",
       "1   airbnb        tree     2         1.00000         1.000000      1.000000   \n",
       "2   airbnb        tree     3         1.00000         1.000000      1.000000   \n",
       "3   airbnb        tree     4         1.00000         1.000000      1.000000   \n",
       "4   airbnb        tree     5         1.00000         1.000000      1.000000   \n",
       "5   airbnb        tree   avg         1.00000         1.000000      1.000000   \n",
       "6   airbnb     log_reg     1         0.98780         1.000000      0.975373   \n",
       "7   airbnb     log_reg     2         0.99060         1.000000      0.981033   \n",
       "8   airbnb     log_reg     3         0.98760         1.000000      0.974684   \n",
       "9   airbnb     log_reg     4         0.98840         1.000000      0.976585   \n",
       "10  airbnb     log_reg     5         0.98560         0.991857      0.979100   \n",
       "11  airbnb     log_reg   avg         0.98800         0.998371      0.977355   \n",
       "12  airbnb  perceptron     1         1.00000         1.000000      1.000000   \n",
       "13  airbnb  perceptron     2         1.00000         1.000000      1.000000   \n",
       "14  airbnb  perceptron     3         1.00000         1.000000      1.000000   \n",
       "15  airbnb  perceptron     4         0.84940         0.766873      1.000000   \n",
       "16  airbnb  perceptron     5         1.00000         1.000000      1.000000   \n",
       "17  airbnb  perceptron   avg         0.96988         0.953375      1.000000   \n",
       "18  airbnb         knn     1         0.99460         0.998779      0.990311   \n",
       "19  airbnb         knn     2         0.99460         0.998373      0.990718   \n",
       "20  airbnb         knn     3         0.99480         0.997945      0.991425   \n",
       "21  airbnb         knn     4         0.99280         0.998774      0.986677   \n",
       "22  airbnb         knn     5         0.99320         0.997567      0.988746   \n",
       "23  airbnb         knn   avg         0.99400         0.998288      0.989576   \n",
       "24  airbnb      forest     1         1.00000         1.000000      1.000000   \n",
       "25  airbnb      forest     2         1.00000         1.000000      1.000000   \n",
       "26  airbnb      forest     3         1.00000         1.000000      1.000000   \n",
       "27  airbnb      forest     4         1.00000         1.000000      1.000000   \n",
       "28  airbnb      forest     5         1.00000         1.000000      1.000000   \n",
       "29  airbnb      forest   avg         1.00000         1.000000      1.000000   \n",
       "30  airbnb         svm     1         1.00000         1.000000      1.000000   \n",
       "31  airbnb         svm     2         1.00000         1.000000      1.000000   \n",
       "32  airbnb         svm     3         0.99940         0.998777      1.000000   \n",
       "33  airbnb         svm     4         1.00000         1.000000      1.000000   \n",
       "34  airbnb         svm     5         1.00000         1.000000      1.000000   \n",
       "35  airbnb         svm   avg         0.99988         0.999755      1.000000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "1            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "2            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "3            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "4            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "5            1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "6            1.000000  0.987533   0.987687   4.213731e-01       0.988040   \n",
       "7            1.000000  0.990426   0.990517   3.246645e-01       0.987721   \n",
       "8            1.000000  0.987179   0.987342   4.282808e-01       0.989065   \n",
       "9            1.000000  0.988154   0.988292   4.006498e-01       0.989725   \n",
       "10           0.992038  0.985437   0.985569   4.973616e-01       0.985853   \n",
       "11           0.998408  0.987746   0.987881   4.144660e-01       0.988081   \n",
       "12           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "13           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "14           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "15           0.701546  0.868057   0.850773   5.201660e+00       0.851897   \n",
       "16           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "17           0.940309  0.973611   0.970155   1.040332e+00       0.970379   \n",
       "18           0.998811  0.994527   0.994561   1.865099e-01       0.990318   \n",
       "19           0.998414  0.994531   0.994566   1.865100e-01       0.990819   \n",
       "20           0.998040  0.994674   0.994733   1.796024e-01       0.991092   \n",
       "21           0.998811  0.992689   0.992744   2.486797e-01       0.990978   \n",
       "22           0.997611  0.993137   0.993179   2.348646e-01       0.990090   \n",
       "23           0.998337  0.993912   0.993956   2.072333e-01       0.990660   \n",
       "24           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "25           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "26           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "27           1.000000  1.000000   1.000000   9.992007e-16       0.999954   \n",
       "28           1.000000  1.000000   1.000000   9.992007e-16       1.000000   \n",
       "29           1.000000  1.000000   1.000000   9.992007e-16       0.999991   \n",
       "30           1.000000  1.000000   1.000000   9.992007e-16       0.999795   \n",
       "31           1.000000  1.000000   1.000000   9.992007e-16       0.999704   \n",
       "32           0.998824  0.999388   0.999412   2.072375e-02       0.999271   \n",
       "33           1.000000  1.000000   1.000000   9.992007e-16       0.999863   \n",
       "34           1.000000  1.000000   1.000000   9.992007e-16       0.999954   \n",
       "35           0.999765  0.999878   0.999882   4.144749e-03       0.999718   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "1         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "2         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "3         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "4         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "5         1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "6         1.000000     0.976078          1.000000  0.987894  0.988039   \n",
       "7         0.999580     0.975849          0.999590  0.987572  0.987719   \n",
       "8         1.000000     0.978156          1.000000  0.988957  0.989078   \n",
       "9         1.000000     0.979450          1.000000  0.989618  0.989725   \n",
       "10        0.994203     0.977388          0.994308  0.985724  0.985848   \n",
       "11        0.998757     0.977384          0.998780  0.987953  0.988082   \n",
       "12        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "13        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "14        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "15        0.771470     1.000000          0.703813  0.870994  0.851907   \n",
       "16        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "17        0.954294     1.000000          0.940763  0.974199  0.970381   \n",
       "18        0.997365     0.983232          0.997403  0.990248  0.990317   \n",
       "19        0.995857     0.985737          0.995900  0.990771  0.990818   \n",
       "20        0.996549     0.985619          0.996579  0.991054  0.991099   \n",
       "21        0.998566     0.983368          0.998588  0.990909  0.990978   \n",
       "22        0.997041     0.983086          0.997086  0.990014  0.990086   \n",
       "23        0.997076     0.984209          0.997111  0.990599  0.990660   \n",
       "24        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "25        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "26        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "27        1.000000     0.999909          1.000000  0.999954  0.999954   \n",
       "28        1.000000     1.000000          1.000000  1.000000  1.000000   \n",
       "29        1.000000     0.999982          1.000000  0.999991  0.999991   \n",
       "30        0.999727     0.999863          0.999727  0.999795  0.999795   \n",
       "31        0.999408     1.000000          0.999408  0.999704  0.999704   \n",
       "32        0.998546     1.000000          0.998540  0.999272  0.999270   \n",
       "33        0.999863     0.999863          0.999863  0.999863  0.999863   \n",
       "34        1.000000     0.999909          1.000000  0.999954  0.999954   \n",
       "35        0.999509     0.999927          0.999508  0.999718  0.999717   \n",
       "\n",
       "    test_logloss  \n",
       "0   9.992007e-16  \n",
       "1   9.992007e-16  \n",
       "2   9.992007e-16  \n",
       "3   9.992007e-16  \n",
       "4   9.992007e-16  \n",
       "5   9.992007e-16  \n",
       "6   4.130962e-01  \n",
       "7   4.241123e-01  \n",
       "8   3.776880e-01  \n",
       "9   3.548693e-01  \n",
       "10  4.886361e-01  \n",
       "11  4.116804e-01  \n",
       "12  9.992007e-16  \n",
       "13  9.992007e-16  \n",
       "14  9.992007e-16  \n",
       "15  5.115430e+00  \n",
       "16  9.992007e-16  \n",
       "17  1.023086e+00  \n",
       "18  3.344122e-01  \n",
       "19  3.171021e-01  \n",
       "20  3.076597e-01  \n",
       "21  3.115931e-01  \n",
       "22  3.422809e-01  \n",
       "23  3.226096e-01  \n",
       "24  9.992007e-16  \n",
       "25  9.992007e-16  \n",
       "26  9.992007e-16  \n",
       "27  1.573700e-03  \n",
       "28  9.992007e-16  \n",
       "29  3.147400e-04  \n",
       "30  7.081758e-03  \n",
       "31  1.022929e-02  \n",
       "32  2.517978e-02  \n",
       "33  4.721154e-03  \n",
       "34  1.573700e-03  \n",
       "35  9.757136e-03  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/airbnb_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Olympic Gold Medal Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1892 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2180 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2450 out of 2450 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95220</td>\n",
       "      <td>0.954655</td>\n",
       "      <td>0.997053</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>0.546719</td>\n",
       "      <td>1.650989</td>\n",
       "      <td>0.949827</td>\n",
       "      <td>0.953788</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>0.069974</td>\n",
       "      <td>0.974177</td>\n",
       "      <td>0.532715</td>\n",
       "      <td>1.732942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95680</td>\n",
       "      <td>0.958232</td>\n",
       "      <td>0.998108</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.977764</td>\n",
       "      <td>0.571368</td>\n",
       "      <td>1.492108</td>\n",
       "      <td>0.950081</td>\n",
       "      <td>0.954340</td>\n",
       "      <td>0.995100</td>\n",
       "      <td>0.082620</td>\n",
       "      <td>0.974294</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>1.724185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95400</td>\n",
       "      <td>0.954911</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.551368</td>\n",
       "      <td>1.588820</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.953734</td>\n",
       "      <td>0.996816</td>\n",
       "      <td>0.067460</td>\n",
       "      <td>0.974799</td>\n",
       "      <td>0.532138</td>\n",
       "      <td>1.692422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.952678</td>\n",
       "      <td>0.996839</td>\n",
       "      <td>0.074803</td>\n",
       "      <td>0.974259</td>\n",
       "      <td>0.535821</td>\n",
       "      <td>1.726976</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.952527</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.042469</td>\n",
       "      <td>0.973699</td>\n",
       "      <td>0.519151</td>\n",
       "      <td>1.766595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96040</td>\n",
       "      <td>0.961701</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.979671</td>\n",
       "      <td>0.569299</td>\n",
       "      <td>1.367766</td>\n",
       "      <td>0.950568</td>\n",
       "      <td>0.953834</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.072994</td>\n",
       "      <td>0.974563</td>\n",
       "      <td>0.534604</td>\n",
       "      <td>1.707359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95468</td>\n",
       "      <td>0.956436</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0.112018</td>\n",
       "      <td>0.976684</td>\n",
       "      <td>0.554915</td>\n",
       "      <td>1.565332</td>\n",
       "      <td>0.950066</td>\n",
       "      <td>0.953645</td>\n",
       "      <td>0.995884</td>\n",
       "      <td>0.067103</td>\n",
       "      <td>0.974306</td>\n",
       "      <td>0.531494</td>\n",
       "      <td>1.724701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.726979</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>0.951360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.680005</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.703894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.818745</td>\n",
       "      <td>0.049303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.835918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.92880</td>\n",
       "      <td>0.955694</td>\n",
       "      <td>0.970156</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.962870</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>2.459195</td>\n",
       "      <td>0.927110</td>\n",
       "      <td>0.954348</td>\n",
       "      <td>0.969713</td>\n",
       "      <td>0.106196</td>\n",
       "      <td>0.961970</td>\n",
       "      <td>0.537955</td>\n",
       "      <td>2.517581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.811838</td>\n",
       "      <td>0.049298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.836089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950712</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974733</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>1.702383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.58672</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.594031</td>\n",
       "      <td>0.423140</td>\n",
       "      <td>0.582842</td>\n",
       "      <td>0.508586</td>\n",
       "      <td>14.274208</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.571126</td>\n",
       "      <td>0.593941</td>\n",
       "      <td>0.421239</td>\n",
       "      <td>0.582271</td>\n",
       "      <td>0.507590</td>\n",
       "      <td>14.319935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95180</td>\n",
       "      <td>0.951790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.975300</td>\n",
       "      <td>0.502066</td>\n",
       "      <td>1.664808</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.950657</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.499943</td>\n",
       "      <td>1.710968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95180</td>\n",
       "      <td>0.951894</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.975254</td>\n",
       "      <td>0.519895</td>\n",
       "      <td>1.664807</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.997757</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.973748</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>1.766596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950518</td>\n",
       "      <td>0.950556</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974631</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>1.709079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95176</td>\n",
       "      <td>0.951777</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.975271</td>\n",
       "      <td>0.504392</td>\n",
       "      <td>1.666189</td>\n",
       "      <td>0.950251</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.974489</td>\n",
       "      <td>0.500335</td>\n",
       "      <td>1.718316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.959604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196787</td>\n",
       "      <td>0.979386</td>\n",
       "      <td>0.598394</td>\n",
       "      <td>1.381583</td>\n",
       "      <td>0.951115</td>\n",
       "      <td>0.952174</td>\n",
       "      <td>0.998745</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>0.974904</td>\n",
       "      <td>0.515706</td>\n",
       "      <td>1.688475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95940</td>\n",
       "      <td>0.959081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.979113</td>\n",
       "      <td>0.580579</td>\n",
       "      <td>1.402307</td>\n",
       "      <td>0.951696</td>\n",
       "      <td>0.952394</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.037683</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.518407</td>\n",
       "      <td>1.668386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.97060</td>\n",
       "      <td>0.969982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>1.015464</td>\n",
       "      <td>0.951353</td>\n",
       "      <td>0.952849</td>\n",
       "      <td>0.998227</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.975010</td>\n",
       "      <td>0.522810</td>\n",
       "      <td>1.680233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988189</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.994094</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.949226</td>\n",
       "      <td>0.953053</td>\n",
       "      <td>0.995639</td>\n",
       "      <td>0.053768</td>\n",
       "      <td>0.973881</td>\n",
       "      <td>0.524704</td>\n",
       "      <td>1.753717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96180</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.980404</td>\n",
       "      <td>0.570031</td>\n",
       "      <td>1.319412</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.951803</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>0.975112</td>\n",
       "      <td>0.513219</td>\n",
       "      <td>1.675255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.97024</td>\n",
       "      <td>0.969958</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.379681</td>\n",
       "      <td>0.984670</td>\n",
       "      <td>0.689820</td>\n",
       "      <td>1.027898</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>0.952454</td>\n",
       "      <td>0.998267</td>\n",
       "      <td>0.039671</td>\n",
       "      <td>0.974822</td>\n",
       "      <td>0.518969</td>\n",
       "      <td>1.693213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   olympic        tree     1         0.95220         0.954655      0.997053   \n",
       "1   olympic        tree     2         0.95680         0.958232      0.998108   \n",
       "2   olympic        tree     3         0.95400         0.954911      0.998737   \n",
       "3   olympic        tree     4         0.95000         0.952678      0.996839   \n",
       "4   olympic        tree     5         0.96040         0.961701      0.998326   \n",
       "5   olympic        tree   avg         0.95468         0.956436      0.997813   \n",
       "6   olympic     log_reg     1         0.95020         0.950200      1.000000   \n",
       "7   olympic     log_reg     2         0.95160         0.951600      1.000000   \n",
       "8   olympic     log_reg     3         0.95000         0.950000      1.000000   \n",
       "9   olympic     log_reg     4         0.94920         0.949200      1.000000   \n",
       "10  olympic     log_reg     5         0.95580         0.955800      1.000000   \n",
       "11  olympic     log_reg   avg         0.95136         0.951360      1.000000   \n",
       "12  olympic  perceptron     1         0.04980         0.000000      0.000000   \n",
       "13  olympic  perceptron     2         0.92880         0.955694      0.970156   \n",
       "14  olympic  perceptron     3         0.05000         0.000000      0.000000   \n",
       "15  olympic  perceptron     4         0.94920         0.949200      1.000000   \n",
       "16  olympic  perceptron     5         0.95580         0.955800      1.000000   \n",
       "17  olympic  perceptron   avg         0.58672         0.572139      0.594031   \n",
       "18  olympic         knn     1         0.95020         0.950200      1.000000   \n",
       "19  olympic         knn     2         0.95180         0.951790      1.000000   \n",
       "20  olympic         knn     3         0.95180         0.951894      0.999789   \n",
       "21  olympic         knn     4         0.94920         0.949200      1.000000   \n",
       "22  olympic         knn     5         0.95580         0.955800      1.000000   \n",
       "23  olympic         knn   avg         0.95176         0.951777      0.999958   \n",
       "24  olympic      forest     1         0.96000         0.959604      1.000000   \n",
       "25  olympic      forest     2         0.95940         0.959081      1.000000   \n",
       "26  olympic      forest     3         0.97060         0.969982      1.000000   \n",
       "27  olympic      forest     4         0.99940         0.999368      1.000000   \n",
       "28  olympic      forest     5         0.96180         0.961755      0.999791   \n",
       "29  olympic      forest   avg         0.97024         0.969958      0.999958   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.096386  0.975394   0.546719       1.650989       0.949827   \n",
       "1            0.144628  0.977764   0.571368       1.492108       0.950081   \n",
       "2            0.104000  0.976333   0.551368       1.588820       0.951000   \n",
       "3            0.074803  0.974259   0.535821       1.726976       0.948853   \n",
       "4            0.140271  0.979671   0.569299       1.367766       0.950568   \n",
       "5            0.112018  0.976684   0.554915       1.565332       0.950066   \n",
       "6            0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "7            0.000000  0.975200   0.500000       1.671715       0.950662   \n",
       "8            0.000000  0.974359   0.500000       1.726979       0.950702   \n",
       "9            0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "10           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "11           0.000000  0.975072   0.500000       1.680005       0.950668   \n",
       "12           1.000000  0.000000   0.500000      32.818745       0.049303   \n",
       "13           0.115702  0.962870   0.542929       2.459195       0.927110   \n",
       "14           1.000000  0.000000   0.500000      32.811838       0.049298   \n",
       "15           0.000000  0.973938   0.500000       1.754610       0.950712   \n",
       "16           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "17           0.423140  0.582842   0.508586      14.274208       0.585396   \n",
       "18           0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "19           0.004132  0.975300   0.502066       1.664808       0.950464   \n",
       "20           0.040000  0.975254   0.519895       1.664807       0.948853   \n",
       "21           0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "22           0.000000  0.977401   0.500000       1.526649       0.950518   \n",
       "23           0.008826  0.975271   0.504392       1.666189       0.950251   \n",
       "24           0.196787  0.979386   0.598394       1.381583       0.951115   \n",
       "25           0.161157  0.979113   0.580579       1.402307       0.951696   \n",
       "26           0.412000  0.984762   0.706000       1.015464       0.951353   \n",
       "27           0.988189  0.999684   0.994094       0.020724       0.949226   \n",
       "28           0.140271  0.980404   0.570031       1.319412       0.951498   \n",
       "29           0.379681  0.984670   0.689820       1.027898       0.950978   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.953788     0.995456          0.069974  0.974177  0.532715   \n",
       "1         0.954340     0.995100          0.082620  0.974294  0.538860   \n",
       "2         0.953734     0.996816          0.067460  0.974799  0.532138   \n",
       "3         0.952527     0.995833          0.042469  0.973699  0.519151   \n",
       "4         0.953834     0.996214          0.072994  0.974563  0.534604   \n",
       "5         0.953645     0.995884          0.067103  0.974306  0.531494   \n",
       "6         0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "7         0.950662     1.000000          0.000000  0.974707  0.500000   \n",
       "8         0.950702     1.000000          0.000000  0.974728  0.500000   \n",
       "9         0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "10        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "11        0.950668     1.000000          0.000000  0.974710  0.500000   \n",
       "12        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "13        0.954348     0.969713          0.106196  0.961970  0.537955   \n",
       "14        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "15        0.950722     0.999990          0.000000  0.974733  0.499995   \n",
       "16        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "17        0.571126     0.593941          0.421239  0.582271  0.507590   \n",
       "18        0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "19        0.950657     0.999786          0.000101  0.974603  0.499943   \n",
       "20        0.950867     0.997757          0.005748  0.973748  0.501752   \n",
       "21        0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "22        0.950556     0.999958          0.000000  0.974631  0.499979   \n",
       "23        0.950700     0.999500          0.001170  0.974489  0.500335   \n",
       "24        0.952174     0.998745          0.032668  0.974904  0.515706   \n",
       "25        0.952394     0.999132          0.037683  0.975203  0.518407   \n",
       "26        0.952849     0.998227          0.047393  0.975010  0.522810   \n",
       "27        0.953053     0.995639          0.053768  0.973881  0.524704   \n",
       "28        0.951803     0.999592          0.026845  0.975112  0.513219   \n",
       "29        0.952454     0.998267          0.039671  0.974822  0.518969   \n",
       "\n",
       "    test_logloss  \n",
       "0       1.732942  \n",
       "1       1.724185  \n",
       "2       1.692422  \n",
       "3       1.766595  \n",
       "4       1.707359  \n",
       "5       1.724701  \n",
       "6       1.702898  \n",
       "7       1.704100  \n",
       "8       1.702726  \n",
       "9       1.702040  \n",
       "10      1.707706  \n",
       "11      1.703894  \n",
       "12     32.835918  \n",
       "13      2.517581  \n",
       "14     32.836089  \n",
       "15      1.702383  \n",
       "16      1.707706  \n",
       "17     14.319935  \n",
       "18      1.702898  \n",
       "19      1.710968  \n",
       "20      1.766596  \n",
       "21      1.702040  \n",
       "22      1.709079  \n",
       "23      1.718316  \n",
       "24      1.688475  \n",
       "25      1.668386  \n",
       "26      1.680233  \n",
       "27      1.753717  \n",
       "28      1.675255  \n",
       "29      1.693213  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running algorithms except SVM on Olympic dataset\n",
    "olympic_results_no_svm = perform_trials('olympic', models_without_svm, olympic_X, olympic_y)\n",
    "olympic_results_no_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   17.4s\n",
      "/Users/melchisedec/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.726979</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.702726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.680005</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.703894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  olympic   svm     1         0.95020          0.95020           1.0   \n",
       "1  olympic   svm     2         0.95160          0.95160           1.0   \n",
       "2  olympic   svm     3         0.95000          0.95000           1.0   \n",
       "3  olympic   svm     4         0.94920          0.94920           1.0   \n",
       "4  olympic   svm     5         0.95580          0.95580           1.0   \n",
       "5  olympic   svm   avg         0.95136          0.95136           1.0   \n",
       "\n",
       "   train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0                0.0  0.974464        0.5       1.720071       0.950697   \n",
       "1                0.0  0.975200        0.5       1.671715       0.950662   \n",
       "2                0.0  0.974359        0.5       1.726979       0.950702   \n",
       "3                0.0  0.973938        0.5       1.754610       0.950722   \n",
       "4                0.0  0.977401        0.5       1.526649       0.950558   \n",
       "5                0.0  0.975072        0.5       1.680005       0.950668   \n",
       "\n",
       "   test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0        0.950697          1.0               0.0  0.974726       0.5   \n",
       "1        0.950662          1.0               0.0  0.974707       0.5   \n",
       "2        0.950702          1.0               0.0  0.974728       0.5   \n",
       "3        0.950722          1.0               0.0  0.974739       0.5   \n",
       "4        0.950558          1.0               0.0  0.974652       0.5   \n",
       "5        0.950668          1.0               0.0  0.974710       0.5   \n",
       "\n",
       "   test_logloss  \n",
       "0      1.702898  \n",
       "1      1.704100  \n",
       "2      1.702726  \n",
       "3      1.702040  \n",
       "4      1.707706  \n",
       "5      1.703894  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympic_results_svm = perform_trials('olympic', models_only_svm, olympic_X, olympic_y)\n",
    "olympic_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_final_results = olympic_results_no_svm.append(olympic_results_svm, ignore_index=True)\n",
    "olympic_final_results.to_csv('results/olympic_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95220</td>\n",
       "      <td>0.954655</td>\n",
       "      <td>0.997053</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>0.546719</td>\n",
       "      <td>1.650989</td>\n",
       "      <td>0.949827</td>\n",
       "      <td>0.953788</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>0.069974</td>\n",
       "      <td>0.974177</td>\n",
       "      <td>0.532715</td>\n",
       "      <td>1.732942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95680</td>\n",
       "      <td>0.958232</td>\n",
       "      <td>0.998108</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.977764</td>\n",
       "      <td>0.571368</td>\n",
       "      <td>1.492108</td>\n",
       "      <td>0.950081</td>\n",
       "      <td>0.954340</td>\n",
       "      <td>0.995100</td>\n",
       "      <td>0.082620</td>\n",
       "      <td>0.974294</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>1.724185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95400</td>\n",
       "      <td>0.954911</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.551368</td>\n",
       "      <td>1.588820</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.953734</td>\n",
       "      <td>0.996816</td>\n",
       "      <td>0.067460</td>\n",
       "      <td>0.974799</td>\n",
       "      <td>0.532138</td>\n",
       "      <td>1.692422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.952678</td>\n",
       "      <td>0.996839</td>\n",
       "      <td>0.074803</td>\n",
       "      <td>0.974259</td>\n",
       "      <td>0.535821</td>\n",
       "      <td>1.726976</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.952527</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.042469</td>\n",
       "      <td>0.973699</td>\n",
       "      <td>0.519151</td>\n",
       "      <td>1.766595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96040</td>\n",
       "      <td>0.961701</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.979671</td>\n",
       "      <td>0.569299</td>\n",
       "      <td>1.367766</td>\n",
       "      <td>0.950568</td>\n",
       "      <td>0.953834</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.072994</td>\n",
       "      <td>0.974563</td>\n",
       "      <td>0.534604</td>\n",
       "      <td>1.707359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>olympic</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95468</td>\n",
       "      <td>0.956436</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0.112018</td>\n",
       "      <td>0.976684</td>\n",
       "      <td>0.554915</td>\n",
       "      <td>1.565332</td>\n",
       "      <td>0.950066</td>\n",
       "      <td>0.953645</td>\n",
       "      <td>0.995884</td>\n",
       "      <td>0.067103</td>\n",
       "      <td>0.974306</td>\n",
       "      <td>0.531494</td>\n",
       "      <td>1.724701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.726979</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>olympic</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>0.951360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.680005</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.703894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.818745</td>\n",
       "      <td>0.049303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.835918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>2</td>\n",
       "      <td>0.92880</td>\n",
       "      <td>0.955694</td>\n",
       "      <td>0.970156</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.962870</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>2.459195</td>\n",
       "      <td>0.927110</td>\n",
       "      <td>0.954348</td>\n",
       "      <td>0.969713</td>\n",
       "      <td>0.106196</td>\n",
       "      <td>0.961970</td>\n",
       "      <td>0.537955</td>\n",
       "      <td>2.517581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.811838</td>\n",
       "      <td>0.049298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.836089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950712</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974733</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>1.702383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>olympic</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.58672</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.594031</td>\n",
       "      <td>0.423140</td>\n",
       "      <td>0.582842</td>\n",
       "      <td>0.508586</td>\n",
       "      <td>14.274208</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.571126</td>\n",
       "      <td>0.593941</td>\n",
       "      <td>0.421239</td>\n",
       "      <td>0.582271</td>\n",
       "      <td>0.507590</td>\n",
       "      <td>14.319935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95180</td>\n",
       "      <td>0.951790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.975300</td>\n",
       "      <td>0.502066</td>\n",
       "      <td>1.664808</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.950657</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.499943</td>\n",
       "      <td>1.710968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95180</td>\n",
       "      <td>0.951894</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.975254</td>\n",
       "      <td>0.519895</td>\n",
       "      <td>1.664807</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.997757</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.973748</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>1.766596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950518</td>\n",
       "      <td>0.950556</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974631</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>1.709079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>olympic</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95176</td>\n",
       "      <td>0.951777</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.975271</td>\n",
       "      <td>0.504392</td>\n",
       "      <td>1.666189</td>\n",
       "      <td>0.950251</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.974489</td>\n",
       "      <td>0.500335</td>\n",
       "      <td>1.718316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.959604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196787</td>\n",
       "      <td>0.979386</td>\n",
       "      <td>0.598394</td>\n",
       "      <td>1.381583</td>\n",
       "      <td>0.951115</td>\n",
       "      <td>0.952174</td>\n",
       "      <td>0.998745</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>0.974904</td>\n",
       "      <td>0.515706</td>\n",
       "      <td>1.688475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95940</td>\n",
       "      <td>0.959081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.979113</td>\n",
       "      <td>0.580579</td>\n",
       "      <td>1.402307</td>\n",
       "      <td>0.951696</td>\n",
       "      <td>0.952394</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.037683</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.518407</td>\n",
       "      <td>1.668386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.97060</td>\n",
       "      <td>0.969982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>1.015464</td>\n",
       "      <td>0.951353</td>\n",
       "      <td>0.952849</td>\n",
       "      <td>0.998227</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.975010</td>\n",
       "      <td>0.522810</td>\n",
       "      <td>1.680233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988189</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.994094</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.949226</td>\n",
       "      <td>0.953053</td>\n",
       "      <td>0.995639</td>\n",
       "      <td>0.053768</td>\n",
       "      <td>0.973881</td>\n",
       "      <td>0.524704</td>\n",
       "      <td>1.753717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96180</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.140271</td>\n",
       "      <td>0.980404</td>\n",
       "      <td>0.570031</td>\n",
       "      <td>1.319412</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.951803</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>0.975112</td>\n",
       "      <td>0.513219</td>\n",
       "      <td>1.675255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>olympic</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.97024</td>\n",
       "      <td>0.969958</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.379681</td>\n",
       "      <td>0.984670</td>\n",
       "      <td>0.689820</td>\n",
       "      <td>1.027898</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>0.952454</td>\n",
       "      <td>0.998267</td>\n",
       "      <td>0.039671</td>\n",
       "      <td>0.974822</td>\n",
       "      <td>0.518969</td>\n",
       "      <td>1.693213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95020</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974464</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.720071</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.671715</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>0.950662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.726979</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94920</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754610</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>0.950722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.702040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95580</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.526649</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>0.950558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.707706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>olympic</td>\n",
       "      <td>svm</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.95136</td>\n",
       "      <td>0.951360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.680005</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>0.950668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.703894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0   olympic        tree     1         0.95220         0.954655      0.997053   \n",
       "1   olympic        tree     2         0.95680         0.958232      0.998108   \n",
       "2   olympic        tree     3         0.95400         0.954911      0.998737   \n",
       "3   olympic        tree     4         0.95000         0.952678      0.996839   \n",
       "4   olympic        tree     5         0.96040         0.961701      0.998326   \n",
       "5   olympic        tree   avg         0.95468         0.956436      0.997813   \n",
       "6   olympic     log_reg     1         0.95020         0.950200      1.000000   \n",
       "7   olympic     log_reg     2         0.95160         0.951600      1.000000   \n",
       "8   olympic     log_reg     3         0.95000         0.950000      1.000000   \n",
       "9   olympic     log_reg     4         0.94920         0.949200      1.000000   \n",
       "10  olympic     log_reg     5         0.95580         0.955800      1.000000   \n",
       "11  olympic     log_reg   avg         0.95136         0.951360      1.000000   \n",
       "12  olympic  perceptron     1         0.04980         0.000000      0.000000   \n",
       "13  olympic  perceptron     2         0.92880         0.955694      0.970156   \n",
       "14  olympic  perceptron     3         0.05000         0.000000      0.000000   \n",
       "15  olympic  perceptron     4         0.94920         0.949200      1.000000   \n",
       "16  olympic  perceptron     5         0.95580         0.955800      1.000000   \n",
       "17  olympic  perceptron   avg         0.58672         0.572139      0.594031   \n",
       "18  olympic         knn     1         0.95020         0.950200      1.000000   \n",
       "19  olympic         knn     2         0.95180         0.951790      1.000000   \n",
       "20  olympic         knn     3         0.95180         0.951894      0.999789   \n",
       "21  olympic         knn     4         0.94920         0.949200      1.000000   \n",
       "22  olympic         knn     5         0.95580         0.955800      1.000000   \n",
       "23  olympic         knn   avg         0.95176         0.951777      0.999958   \n",
       "24  olympic      forest     1         0.96000         0.959604      1.000000   \n",
       "25  olympic      forest     2         0.95940         0.959081      1.000000   \n",
       "26  olympic      forest     3         0.97060         0.969982      1.000000   \n",
       "27  olympic      forest     4         0.99940         0.999368      1.000000   \n",
       "28  olympic      forest     5         0.96180         0.961755      0.999791   \n",
       "29  olympic      forest   avg         0.97024         0.969958      0.999958   \n",
       "30  olympic         svm     1         0.95020         0.950200      1.000000   \n",
       "31  olympic         svm     2         0.95160         0.951600      1.000000   \n",
       "32  olympic         svm     3         0.95000         0.950000      1.000000   \n",
       "33  olympic         svm     4         0.94920         0.949200      1.000000   \n",
       "34  olympic         svm     5         0.95580         0.955800      1.000000   \n",
       "35  olympic         svm   avg         0.95136         0.951360      1.000000   \n",
       "\n",
       "    train_specificity  train_f1  train_auc  train_logloss  test_accuracy  \\\n",
       "0            0.096386  0.975394   0.546719       1.650989       0.949827   \n",
       "1            0.144628  0.977764   0.571368       1.492108       0.950081   \n",
       "2            0.104000  0.976333   0.551368       1.588820       0.951000   \n",
       "3            0.074803  0.974259   0.535821       1.726976       0.948853   \n",
       "4            0.140271  0.979671   0.569299       1.367766       0.950568   \n",
       "5            0.112018  0.976684   0.554915       1.565332       0.950066   \n",
       "6            0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "7            0.000000  0.975200   0.500000       1.671715       0.950662   \n",
       "8            0.000000  0.974359   0.500000       1.726979       0.950702   \n",
       "9            0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "10           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "11           0.000000  0.975072   0.500000       1.680005       0.950668   \n",
       "12           1.000000  0.000000   0.500000      32.818745       0.049303   \n",
       "13           0.115702  0.962870   0.542929       2.459195       0.927110   \n",
       "14           1.000000  0.000000   0.500000      32.811838       0.049298   \n",
       "15           0.000000  0.973938   0.500000       1.754610       0.950712   \n",
       "16           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "17           0.423140  0.582842   0.508586      14.274208       0.585396   \n",
       "18           0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "19           0.004132  0.975300   0.502066       1.664808       0.950464   \n",
       "20           0.040000  0.975254   0.519895       1.664807       0.948853   \n",
       "21           0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "22           0.000000  0.977401   0.500000       1.526649       0.950518   \n",
       "23           0.008826  0.975271   0.504392       1.666189       0.950251   \n",
       "24           0.196787  0.979386   0.598394       1.381583       0.951115   \n",
       "25           0.161157  0.979113   0.580579       1.402307       0.951696   \n",
       "26           0.412000  0.984762   0.706000       1.015464       0.951353   \n",
       "27           0.988189  0.999684   0.994094       0.020724       0.949226   \n",
       "28           0.140271  0.980404   0.570031       1.319412       0.951498   \n",
       "29           0.379681  0.984670   0.689820       1.027898       0.950978   \n",
       "30           0.000000  0.974464   0.500000       1.720071       0.950697   \n",
       "31           0.000000  0.975200   0.500000       1.671715       0.950662   \n",
       "32           0.000000  0.974359   0.500000       1.726979       0.950702   \n",
       "33           0.000000  0.973938   0.500000       1.754610       0.950722   \n",
       "34           0.000000  0.977401   0.500000       1.526649       0.950558   \n",
       "35           0.000000  0.975072   0.500000       1.680005       0.950668   \n",
       "\n",
       "    test_precision  test_recall  test_specificity   test_f1  test_auc  \\\n",
       "0         0.953788     0.995456          0.069974  0.974177  0.532715   \n",
       "1         0.954340     0.995100          0.082620  0.974294  0.538860   \n",
       "2         0.953734     0.996816          0.067460  0.974799  0.532138   \n",
       "3         0.952527     0.995833          0.042469  0.973699  0.519151   \n",
       "4         0.953834     0.996214          0.072994  0.974563  0.534604   \n",
       "5         0.953645     0.995884          0.067103  0.974306  0.531494   \n",
       "6         0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "7         0.950662     1.000000          0.000000  0.974707  0.500000   \n",
       "8         0.950702     1.000000          0.000000  0.974728  0.500000   \n",
       "9         0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "10        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "11        0.950668     1.000000          0.000000  0.974710  0.500000   \n",
       "12        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "13        0.954348     0.969713          0.106196  0.961970  0.537955   \n",
       "14        0.000000     0.000000          1.000000  0.000000  0.500000   \n",
       "15        0.950722     0.999990          0.000000  0.974733  0.499995   \n",
       "16        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "17        0.571126     0.593941          0.421239  0.582271  0.507590   \n",
       "18        0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "19        0.950657     0.999786          0.000101  0.974603  0.499943   \n",
       "20        0.950867     0.997757          0.005748  0.973748  0.501752   \n",
       "21        0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "22        0.950556     0.999958          0.000000  0.974631  0.499979   \n",
       "23        0.950700     0.999500          0.001170  0.974489  0.500335   \n",
       "24        0.952174     0.998745          0.032668  0.974904  0.515706   \n",
       "25        0.952394     0.999132          0.037683  0.975203  0.518407   \n",
       "26        0.952849     0.998227          0.047393  0.975010  0.522810   \n",
       "27        0.953053     0.995639          0.053768  0.973881  0.524704   \n",
       "28        0.951803     0.999592          0.026845  0.975112  0.513219   \n",
       "29        0.952454     0.998267          0.039671  0.974822  0.518969   \n",
       "30        0.950697     1.000000          0.000000  0.974726  0.500000   \n",
       "31        0.950662     1.000000          0.000000  0.974707  0.500000   \n",
       "32        0.950702     1.000000          0.000000  0.974728  0.500000   \n",
       "33        0.950722     1.000000          0.000000  0.974739  0.500000   \n",
       "34        0.950558     1.000000          0.000000  0.974652  0.500000   \n",
       "35        0.950668     1.000000          0.000000  0.974710  0.500000   \n",
       "\n",
       "    test_logloss  \n",
       "0       1.732942  \n",
       "1       1.724185  \n",
       "2       1.692422  \n",
       "3       1.766595  \n",
       "4       1.707359  \n",
       "5       1.724701  \n",
       "6       1.702898  \n",
       "7       1.704100  \n",
       "8       1.702726  \n",
       "9       1.702040  \n",
       "10      1.707706  \n",
       "11      1.703894  \n",
       "12     32.835918  \n",
       "13      2.517581  \n",
       "14     32.836089  \n",
       "15      1.702383  \n",
       "16      1.707706  \n",
       "17     14.319935  \n",
       "18      1.702898  \n",
       "19      1.710968  \n",
       "20      1.766596  \n",
       "21      1.702040  \n",
       "22      1.709079  \n",
       "23      1.718316  \n",
       "24      1.688475  \n",
       "25      1.668386  \n",
       "26      1.680233  \n",
       "27      1.753717  \n",
       "28      1.675255  \n",
       "29      1.693213  \n",
       "30      1.702898  \n",
       "31      1.704100  \n",
       "32      1.702726  \n",
       "33      1.702040  \n",
       "34      1.707706  \n",
       "35      1.703894  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display performance\n",
    "pd.read_csv('results/olympic_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine datasets\n",
    "cardio_results = pd.read_csv('results/cardio_results.csv')\n",
    "olympic_results = pd.read_csv('results/olympic_results.csv')\n",
    "olympic_results.columns = cardio_results.columns\n",
    "airbnb_results = pd.read_csv('results/airbnb_results.csv')\n",
    "airbnb_results.columns = cardio_results.columns\n",
    "aus_results = pd.read_csv('results/aus_results.csv')\n",
    "results = cardio_results.append([olympic_results, airbnb_results, aus_results], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = [\"train_\" + x for x in list(scoring.keys())]\n",
    "test_metrics = [\"test_\" + x for x in list(scoring.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_avg_results = results.loc[results['trial'] == 'avg', ['dataset', 'model', 'trial'] + test_metrics]\n",
    "test_avg_results = test_avg_results.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = results.loc[results['trial'] != 'avg', ['dataset', 'model', 'trial'] + test_metrics]\n",
    "test_results = test_results.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avg_results = results.loc[results['trial'] == 'avg', ['dataset', 'model', 'trial'] + train_metrics]\n",
    "train_avg_results = train_avg_results.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = results.loc[results['trial'] != 'avg', ['dataset', 'model', 'trial'] + train_metrics]\n",
    "train_results = train_results.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_avg_results['dataset'].unique().tolist() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forest</td>\n",
       "      <td>0.880654</td>\n",
       "      <td>0.860870</td>\n",
       "      <td>0.784385</td>\n",
       "      <td>0.687425</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>0.735518</td>\n",
       "      <td>0.793297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.855209</td>\n",
       "      <td>0.874959</td>\n",
       "      <td>0.755615</td>\n",
       "      <td>0.681039</td>\n",
       "      <td>0.764354</td>\n",
       "      <td>0.700043</td>\n",
       "      <td>0.771870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.869327</td>\n",
       "      <td>0.867512</td>\n",
       "      <td>0.807338</td>\n",
       "      <td>0.698772</td>\n",
       "      <td>0.785246</td>\n",
       "      <td>0.725060</td>\n",
       "      <td>0.792209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perceptron</td>\n",
       "      <td>0.697309</td>\n",
       "      <td>0.640654</td>\n",
       "      <td>0.646051</td>\n",
       "      <td>0.714123</td>\n",
       "      <td>0.604598</td>\n",
       "      <td>0.677625</td>\n",
       "      <td>0.663393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.880415</td>\n",
       "      <td>0.898352</td>\n",
       "      <td>0.854467</td>\n",
       "      <td>0.719719</td>\n",
       "      <td>0.813168</td>\n",
       "      <td>0.733645</td>\n",
       "      <td>0.816628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.875719</td>\n",
       "      <td>0.874998</td>\n",
       "      <td>0.791059</td>\n",
       "      <td>0.714752</td>\n",
       "      <td>0.803575</td>\n",
       "      <td>0.736421</td>\n",
       "      <td>0.799421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  test_accuracy  test_precision  test_recall  test_specificity  \\\n",
       "0      forest       0.880654        0.860870     0.784385          0.687425   \n",
       "1         knn       0.855209        0.874959     0.755615          0.681039   \n",
       "2     log_reg       0.869327        0.867512     0.807338          0.698772   \n",
       "3  perceptron       0.697309        0.640654     0.646051          0.714123   \n",
       "4         svm       0.880415        0.898352     0.854467          0.719719   \n",
       "5        tree       0.875719        0.874998     0.791059          0.714752   \n",
       "\n",
       "    test_f1  test_roc_auc      mean  \n",
       "0  0.810930      0.735518  0.793297  \n",
       "1  0.764354      0.700043  0.771870  \n",
       "2  0.785246      0.725060  0.792209  \n",
       "3  0.604598      0.677625  0.663393  \n",
       "4  0.813168      0.733645  0.816628  \n",
       "5  0.803575      0.736421  0.799421  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2 = test_avg_results.groupby(by='model').mean()\n",
    "table2['mean'] = table2.apply(np.mean, axis = 1)\n",
    "table2 = table2.reset_index()\n",
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 2 p value appendix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = table2.set_index('model').idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl2_pvals = pd.DataFrame(columns = ['model'] + test_metrics)\n",
    "tl2_pvals['model'] = table2['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.149951</td>\n",
       "      <td>0.247245</td>\n",
       "      <td>0.714857</td>\n",
       "      <td>0.961355</td>\n",
       "      <td>0.999837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.408413</td>\n",
       "      <td>0.387342</td>\n",
       "      <td>0.114356</td>\n",
       "      <td>0.696504</td>\n",
       "      <td>0.359515</td>\n",
       "      <td>0.410973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.709716</td>\n",
       "      <td>0.238554</td>\n",
       "      <td>0.487489</td>\n",
       "      <td>0.834681</td>\n",
       "      <td>0.611499</td>\n",
       "      <td>0.836367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perceptron</td>\n",
       "      <td>0.00721976</td>\n",
       "      <td>0.00190464</td>\n",
       "      <td>0.0532257</td>\n",
       "      <td>0.751263</td>\n",
       "      <td>0.0171629</td>\n",
       "      <td>0.200692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.994095</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.85645</td>\n",
       "      <td>0.331502</td>\n",
       "      <td>0.278635</td>\n",
       "      <td>0.9184</td>\n",
       "      <td>0.840714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model test_accuracy test_precision test_recall test_specificity  \\\n",
       "0      forest             1       0.149951    0.247245         0.714857   \n",
       "1         knn      0.408413       0.387342    0.114356         0.696504   \n",
       "2     log_reg      0.709716       0.238554    0.487489         0.834681   \n",
       "3  perceptron    0.00721976     0.00190464   0.0532257         0.751263   \n",
       "4         svm      0.994095              1           1                1   \n",
       "5        tree       0.85645       0.331502    0.278635           0.9184   \n",
       "\n",
       "     test_f1 test_roc_auc  \n",
       "0   0.961355     0.999837  \n",
       "1   0.359515     0.410973  \n",
       "2   0.611499     0.836367  \n",
       "3  0.0171629     0.200692  \n",
       "4          1     0.989963  \n",
       "5   0.840714            1  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for metric in test_metrics:\n",
    "    best_model = best_models[metric]\n",
    "    grp = test_results.groupby(by='model')\n",
    "    for model in models:\n",
    "        pval = stats.ttest_ind(grp.get_group(best_model)[metric].tolist(), grp.get_group(model)[metric].tolist()).pvalue\n",
    "        tl2_pvals.loc[tl2_pvals['model'] == model, metric] = pval\n",
    "tl2_pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tree', 'log_reg', 'perceptron', 'knn', 'forest', 'svm']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cardio</th>\n",
       "      <th>olympic</th>\n",
       "      <th>airbnb</th>\n",
       "      <th>aus</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, cardio, olympic, airbnb, aus, mean]\n",
       "Index: []"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3 = pd.DataFrame(columns = ['model'] + dataset + ['mean'])\n",
    "table3['model'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>trial</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>tree</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.733429</td>\n",
       "      <td>0.783695</td>\n",
       "      <td>0.725277</td>\n",
       "      <td>0.823829</td>\n",
       "      <td>0.730977</td>\n",
       "      <td>0.733553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.695571</td>\n",
       "      <td>0.718427</td>\n",
       "      <td>0.758997</td>\n",
       "      <td>0.800589</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.695531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardio</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.604514</td>\n",
       "      <td>0.797079</td>\n",
       "      <td>0.617288</td>\n",
       "      <td>0.791935</td>\n",
       "      <td>0.523746</td>\n",
       "      <td>0.602200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio</td>\n",
       "      <td>knn</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.679857</td>\n",
       "      <td>0.699976</td>\n",
       "      <td>0.662977</td>\n",
       "      <td>0.737672</td>\n",
       "      <td>0.667303</td>\n",
       "      <td>0.679873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio</td>\n",
       "      <td>forest</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>0.833526</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>0.839613</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.825942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset       model trial  train_accuracy  train_precision  train_recall  \\\n",
       "0  cardio        tree   avg        0.733429         0.783695      0.725277   \n",
       "1  cardio     log_reg   avg        0.695571         0.718427      0.758997   \n",
       "2  cardio  perceptron   avg        0.604514         0.797079      0.617288   \n",
       "3  cardio         knn   avg        0.679857         0.699976      0.662977   \n",
       "4  cardio      forest   avg        0.826057         0.833526      0.882582   \n",
       "\n",
       "   train_specificity  train_f1  train_roc_auc  \n",
       "0           0.823829  0.730977       0.733553  \n",
       "1           0.800589  0.599160       0.695531  \n",
       "2           0.791935  0.523746       0.602200  \n",
       "3           0.737672  0.667303       0.679873  \n",
       "4           0.839613  0.822529       0.825942  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_avg_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     0.739165\n",
       "15    0.710081\n",
       "23    0.655749\n",
       "31    0.666772\n",
       "39    0.729092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['trial'] == 'avg', test_metrics].apply(np.mean, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forest</td>\n",
       "      <td>0.944053</td>\n",
       "      <td>0.944727</td>\n",
       "      <td>0.961435</td>\n",
       "      <td>0.803177</td>\n",
       "      <td>0.946819</td>\n",
       "      <td>0.874239</td>\n",
       "      <td>0.912408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.866976</td>\n",
       "      <td>0.883886</td>\n",
       "      <td>0.913128</td>\n",
       "      <td>0.685751</td>\n",
       "      <td>0.909122</td>\n",
       "      <td>0.794556</td>\n",
       "      <td>0.842236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.871769</td>\n",
       "      <td>0.870004</td>\n",
       "      <td>0.812800</td>\n",
       "      <td>0.699749</td>\n",
       "      <td>0.791637</td>\n",
       "      <td>0.728624</td>\n",
       "      <td>0.795764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perceptron</td>\n",
       "      <td>0.698393</td>\n",
       "      <td>0.641897</td>\n",
       "      <td>0.646874</td>\n",
       "      <td>0.715925</td>\n",
       "      <td>0.603835</td>\n",
       "      <td>0.677603</td>\n",
       "      <td>0.664088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.885253</td>\n",
       "      <td>0.907903</td>\n",
       "      <td>0.875704</td>\n",
       "      <td>0.721004</td>\n",
       "      <td>0.831216</td>\n",
       "      <td>0.744220</td>\n",
       "      <td>0.827550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.884763</td>\n",
       "      <td>0.884049</td>\n",
       "      <td>0.877883</td>\n",
       "      <td>0.728597</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>0.765419</td>\n",
       "      <td>0.829207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  train_accuracy  train_precision  train_recall  \\\n",
       "0      forest        0.944053         0.944727      0.961435   \n",
       "1         knn        0.866976         0.883886      0.913128   \n",
       "2     log_reg        0.871769         0.870004      0.812800   \n",
       "3  perceptron        0.698393         0.641897      0.646874   \n",
       "4         svm        0.885253         0.907903      0.875704   \n",
       "5        tree        0.884763         0.884049      0.877883   \n",
       "\n",
       "   train_specificity  train_f1  train_roc_auc      mean  \n",
       "0           0.803177  0.946819       0.874239  0.912408  \n",
       "1           0.685751  0.909122       0.794556  0.842236  \n",
       "2           0.699749  0.791637       0.728624  0.795764  \n",
       "3           0.715925  0.603835       0.677603  0.664088  \n",
       "4           0.721004  0.831216       0.744220  0.827550  \n",
       "5           0.728597  0.834532       0.765419  0.829207  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appendix1 = results.loc[results['trial'] == 'avg', ['dataset', 'model', 'trial'] + train_metrics]\n",
    "appendix1 = appendix1.reset_index(drop = True)\n",
    "appendix1 = appendix1.groupby(by='model').mean()\n",
    "appendix1['mean'] = appendix1.apply(np.mean, axis = 1)\n",
    "appendix1 = appendix1.reset_index()\n",
    "appendix1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix 1 p value appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_specificity</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.0049323</td>\n",
       "      <td>0.0179431</td>\n",
       "      <td>0.117362</td>\n",
       "      <td>0.285982</td>\n",
       "      <td>0.225815</td>\n",
       "      <td>0.14457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.00636608</td>\n",
       "      <td>0.00342604</td>\n",
       "      <td>0.00508212</td>\n",
       "      <td>0.379869</td>\n",
       "      <td>0.000899723</td>\n",
       "      <td>0.00125152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perceptron</td>\n",
       "      <td>0.000200617</td>\n",
       "      <td>0.000261449</td>\n",
       "      <td>0.000980005</td>\n",
       "      <td>0.315693</td>\n",
       "      <td>2.20055e-05</td>\n",
       "      <td>5.46066e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.0136206</td>\n",
       "      <td>0.0747235</td>\n",
       "      <td>0.0320331</td>\n",
       "      <td>0.52745</td>\n",
       "      <td>0.000937803</td>\n",
       "      <td>0.00415101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.0133099</td>\n",
       "      <td>0.0068008</td>\n",
       "      <td>0.00302404</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.000966603</td>\n",
       "      <td>0.00889826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model train_accuracy train_precision train_recall train_specificity  \\\n",
       "0      forest              1               1            1                 1   \n",
       "1         knn      0.0049323       0.0179431     0.117362          0.285982   \n",
       "2     log_reg     0.00636608      0.00342604   0.00508212          0.379869   \n",
       "3  perceptron    0.000200617     0.000261449  0.000980005          0.315693   \n",
       "4         svm      0.0136206       0.0747235    0.0320331           0.52745   \n",
       "5        tree      0.0133099       0.0068008   0.00302404          0.482672   \n",
       "\n",
       "      train_f1 train_roc_auc  \n",
       "0            1             1  \n",
       "1     0.225815       0.14457  \n",
       "2  0.000899723    0.00125152  \n",
       "3  2.20055e-05   5.46066e-05  \n",
       "4  0.000937803    0.00415101  \n",
       "5  0.000966603    0.00889826  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = appendix1.set_index('model').idxmax()\n",
    "\n",
    "train_results = results.loc[results['trial'] != 'avg', ['dataset', 'model', 'trial'] + train_metrics]\n",
    "train_results = train_results.reset_index(drop=True)\n",
    "\n",
    "appendix1_pvals = pd.DataFrame(columns = ['model'] + train_metrics)\n",
    "appendix1_pvals['model'] = appendix1['model']\n",
    "\n",
    "for metric in train_metrics:\n",
    "    best_model = best_models[metric]\n",
    "    grp = train_results.groupby(by='model')\n",
    "    for model in models:\n",
    "        pval = stats.ttest_ind(grp.get_group(best_model)[metric].tolist(), grp.get_group(model)[metric].tolist()).pvalue\n",
    "        appendix1_pvals.loc[appendix1_pvals['model'] == model, metric] = pval\n",
    "appendix1_pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
